[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blog/resources/csabounds/NEWS.html",
    "href": "blog/resources/csabounds/NEWS.html",
    "title": "csabounds 1.0.0",
    "section": "",
    "text": "csabounds 1.0.0\n\nThe first version of the package csabounds is available\nAdded methods csabounds (the main method in the package)\nmethod attcpo (for computing the average treatment effect conditional on the previous outcome\nmethods ggcsabounds and ggattcpo for plotting the results"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html",
    "href": "blog/drafts/transfinite/transfinite.html",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "",
    "text": "We have defined our underlying model (either from bottom up or through backwards conversion) but need to define PSA distributions for model parameters.\nModel draws on literature-based parameters that are reported as means, standard deviations, interquartile ranges, 95% confidence intervals, etc."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#a-common-issue",
    "href": "blog/drafts/transfinite/transfinite.html#a-common-issue",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "",
    "text": "We have defined our underlying model (either from bottom up or through backwards conversion) but need to define PSA distributions for model parameters.\nModel draws on literature-based parameters that are reported as means, standard deviations, interquartile ranges, 95% confidence intervals, etc."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#a-common-issue-1",
    "href": "blog/drafts/transfinite/transfinite.html#a-common-issue-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "A Common Issue",
    "text": "A Common Issue\n\nStraightforward to obtain base case values from literature.\nBut how can we define PSA distributions based on limited information?"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#psa-distributions",
    "href": "blog/drafts/transfinite/transfinite.html#psa-distributions",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "PSA Distributions",
    "text": "PSA Distributions\n\n\n\nParameter Type\nDistribution\n\n\n\n\nProbability\nbeta\n\n\nRate\ngamma\n\n\nUtility weight\nbeta\n\n\nRight skew (e.g., cost)\ngamma, lognormal\n\n\nRelative risks or hazard ratios\nlognormal\n\n\nOdds Ratio\nlogistic"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#example",
    "href": "blog/drafts/transfinite/transfinite.html#example",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Example",
    "text": "Example\n\nCost parameter reported in literature has interquartile range of $300-$750.\nWhat are the parameters of a PSA distribution such that the 25th percentile is $300 and the 75th percentile is $750?"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#some-options",
    "href": "blog/drafts/transfinite/transfinite.html#some-options",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Some Options",
    "text": "Some Options\n\nAnalytic formulas for some distributions (normal, gamma, beta).\nFormulas take as their inputs the two values (\\(x_1\\), \\(x_2\\)) and their associated quantiles (\\(p_1\\),\\(p_2\\)).\nFormulas return the PSA distribution parameters that match up to these values."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#some-options-1",
    "href": "blog/drafts/transfinite/transfinite.html#some-options-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Some Options",
    "text": "Some Options\n\nParameterSolver implemented in Windows, Link\nSee Cook (2010) and Vasco Grilo’s blog post for more.\nThe next few slides provide you with nearly all the tools you’ll need, however."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#example-cost-psa-distribution",
    "href": "blog/drafts/transfinite/transfinite.html#example-cost-psa-distribution",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Example: Cost PSA Distribution",
    "text": "Example: Cost PSA Distribution\n\nSuppose the interquartile range for a key cost variable is [300,750]\nWe may have obtained this from the literature, from tabulating cost data, or from expert opinions."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#example-cost-psa-distribution-1",
    "href": "blog/drafts/transfinite/transfinite.html#example-cost-psa-distribution-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Example: Cost PSA Distribution",
    "text": "Example: Cost PSA Distribution\n\n\nSuppose the interquartile range for a key cost variable is [300,750]\nWe may have obtained this from the literature, from tabulating cost data, or from expert opinions.\n\n\n\nx1 = 300\np1 = 0.25\n\nx2 = 750\np2 = 0.75"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Uniform PSA",
    "text": "Analytic Solution: Uniform PSA\nFor a uniform distribution with minimum \\(a\\) and maximum \\(b\\)\n\\[\na = \\frac{p_2x_1 - p_1x_2}{p_2-p_1}\n\\] \\[\nb = \\frac{(1-p_1)x_2-(1-p_2)x_1}{p_2-p_1}\n\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa-1",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Uniform PSA",
    "text": "Analytic Solution: Uniform PSA\n\na = ((p2*x1) - (p1 * x2)) / (p2 - p1)\na\n\n[1] 75\n\nb = ((1 - p1)*x2 - (1 - p2)*x1) / (p2 - p1)\nb\n\n[1] 975"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa-2",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Uniform PSA",
    "text": "Analytic Solution: Uniform PSA\n\nqunif(0.25, min = 75, max = 975)\n\n[1] 300\n\nqunif(0.75, min = 75, max = 975)\n\n[1] 750"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Normal PSA",
    "text": "Analytic Solution: Normal PSA\n\\[\n\\sigma = \\frac{x_2 - x_1}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]\n\\[\n\\mu = \\frac{x_1\\Phi^{-1}(p_2)-x_2\\Phi^{-1}(p_1)}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa-1",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Normal PSA",
    "text": "Analytic Solution: Normal PSA\n\nmu = (qnorm(p2)*x1 - qnorm(p1)*x2) / (qnorm(p2)-qnorm(p1))\nmu\n\n[1] 525\n\nsigma = (x2 - x1) / (qnorm(p2) - qnorm(p1))\nsigma\n\n[1] 333.5855"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa-2",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Normal PSA",
    "text": "Analytic Solution: Normal PSA\n\nqnorm(0.25, mean = 525, sd = 333.59)\n\n[1] 299.997\n\nqnorm(0.75, mean = 525, sd = 333.59)\n\n[1] 750.003"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Lognormal PSA",
    "text": "Analytic Solution: Lognormal PSA\n\nJust take log of \\(x_1\\) and \\(x_2\\)\n\n\\[\n\\sigma = \\frac{\\ln(x_2) - \\ln(x_1)}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]\n\\[\n\\mu = \\frac{\\ln(x_1)\\Phi^{-1}(p_2)-\\ln(x_2)\\Phi^{-1}(p_1)}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa-1",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Lognormal PSA",
    "text": "Analytic Solution: Lognormal PSA\n\nmu = (qnorm(p2)*log(x1) - qnorm(p1)*log(x2)) / (qnorm(p2)-qnorm(p1))\nmu\n\n[1] 6.161928\n\nsigma = (log(x2) - log(x1)) / (qnorm(p2) - qnorm(p1))\nsigma\n\n[1] 0.6792473"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa-2",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Lognormal PSA",
    "text": "Analytic Solution: Lognormal PSA\n\nqlnorm(0.25, mean = 6.1619, sd = 0.67925)\n\n[1] 299.9911\n\nqlnorm(0.75, mean = 6.1619, sd = 0.67925)\n\n[1] 749.9805"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\nA bit more involved as it involves finding the root of a function."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-1",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\n\nA bit more involved as it involves finding the root of a function.\n\n\n\ngamma_fn &lt;- function(alpha) {\n    x1*qgamma(p2,shape = alpha, scale =1) - x2 * qgamma(p1, shape = alpha, scale = 1)\n}\ncurve(gamma_fn, xlim = c(1,10), col = \"blue\", lwd = 1.5, lty=2)\nabline(a=0,b=0)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-2",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\n\nRoot (i.e., point where the function crosses the zero line) seems to be between 2 and 4.\n\n\n\ngamma_fn &lt;- function(alpha) {\n    x1*qgamma(p2,shape = alpha, scale =1) - x2 * qgamma(p1, shape = alpha, scale = 1)\n}\ncurve(gamma_fn, xlim = c(1,10), col = \"blue\", lwd = 1.5, lty=2)\nabline(a=0,b=0)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-3",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-3",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\n\nWe’ll search in this range for our \\(\\alpha\\) value.\n\n\n\ngamma_fn &lt;- function(alpha) {\n    x1*qgamma(p2,shape = alpha, scale =1) - x2 * qgamma(p1, shape = alpha, scale = 1)\n}\ncurve(gamma_fn, xlim = c(1,10), col = \"blue\", lwd = 1.5, lty=2)\nabline(a=0,b=0)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-4",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-4",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\nalpha_ &lt;- uniroot(gamma_fn,c(2,4))$root\nalpha_\n\n[1] 2.455801\n\ncalc_beta &lt;- function(x1,p1,alpha) {\n    x1 / qgamma(p1,alpha,1)\n}\n\nbeta_ &lt;- calc_beta(x1 = x1,  p1 = p1, alpha = alpha_)\nbeta_\n\n[1] 230.1627"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-5",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-5",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\nqgamma(0.25,shape = 2.4558, scale = 230.16)\n\n[1] 299.9963\n\nqgamma(0.75,shape = 2.4558, scale = 230.16)\n\n[1] 749.9956"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#alternative-optimization",
    "href": "blog/drafts/transfinite/transfinite.html#alternative-optimization",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Alternative: Optimization",
    "text": "Alternative: Optimization\n\n\nGeneral solution that can be used to solve for parameters of many common PSA distributions (e.g., beta, gamma, etc.).\n\n\n\\[\\min_{\\vec{\\theta} \\in R}\\,\\, (F(x_1|\\vec{\\theta})-p_1)^2+(F(x_2|\\vec{\\theta})-p_2)^2\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#alternative-optimization-1",
    "href": "blog/drafts/transfinite/transfinite.html#alternative-optimization-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Alternative: Optimization",
    "text": "Alternative: Optimization\n\nRequires cumulative distribution function (CDF), \\(F\\).\nSee Hans W Borchers’ great slides for tips on optimization in R."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#some-advice",
    "href": "blog/drafts/transfinite/transfinite.html#some-advice",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Some Advice",
    "text": "Some Advice\n\nWe have found that while analytically correct, this optimization formula is not numerically stable.\nTransfinite scaling of the probabilities from CDFs \\(F(.)\\) stabilizes optimization."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#some-advice-1",
    "href": "blog/drafts/transfinite/transfinite.html#some-advice-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Some Advice",
    "text": "Some Advice\n\n\nWe have found that while analytically correct, this optimization formula is not numerically stable.\nTransfinite scaling of the probabilities from CDFs \\(F(.)\\) stabilizes optimization.\n\\(g(F(.))\\) vs. \\(F(.)\\)\n\n\n\\[\\min_{\\vec{\\theta} \\in R}\\,\\, (g(F(x_1|\\vec{\\theta}))-p_1)^2+(g(F(x_2|\\vec{\\theta}))-p_2)^2\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#stable-optimization",
    "href": "blog/drafts/transfinite/transfinite.html#stable-optimization",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Stable Optimization",
    "text": "Stable Optimization\n\nFor probabilities, this is the \\(\\text{logit}(p)=\\log \\frac{p}{1-p}=\\log p - \\log (1-p)\\).\nTweaking parameters to converge can still happen.\nExample of theory versus practice."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#stable-optimization-1",
    "href": "blog/drafts/transfinite/transfinite.html#stable-optimization-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Stable Optimization",
    "text": "Stable Optimization\n\n\nFor probabilities, this is the \\(\\text{logit}(p)=\\log \\frac{p}{1-p}=\\log p - \\log (1-p)\\).\nTweaking parameters to converge can still happen.\nExample of theory versus practice.\n\n\n\\[\\min_{\\vec{\\theta} \\in R} \\sum_{i \\in 1,2}\\,\\, (\\text{logit} (F(x_i|\\vec{\\theta}))-\\text{logit} (p_i))^2\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#transfinite-example-part-1",
    "href": "blog/drafts/transfinite/transfinite.html#transfinite-example-part-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Transfinite Example, Part 1",
    "text": "Transfinite Example, Part 1\n\n# Transfinite scaling\nTf &lt;- function(x, shape, rate)\n    pgamma(x,shape,rate,log=TRUE) - \n    pgamma(x,shape,rate,log=TRUE, lower.tail = FALSE)\n\n# Function to minimize\nnorm &lt;- function(x1, p1, x2, p2, shape,rate)\n    (Tf(x1, shape, rate)-(log(p1)-log(1-p1)) )^2 +\n    (Tf(x2, shape, rate)-(log(p2)-log(1-p2)) )^2\n\n# Bundle it all together into a single function.\nfn &lt;- function(x) norm(x1, p1, x2, p2, x[1], x[2])"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#transfinite-example-part-2",
    "href": "blog/drafts/transfinite/transfinite.html#transfinite-example-part-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Transfinite Example, Part 2",
    "text": "Transfinite Example, Part 2\n\n# Run general-purpose optimization on the function.\ngamma_optim &lt;- \n  optim(c(0.5, 0.1), # initial parameter guesses\n    fn,\n    gr = function(x) pracma::grad(fn, x),\n    lower=c(-Inf, 1e-5),\n    method = \"L-BFGS-B\",\n    control=list(factr=1e-10, maxit=100))$par\n\n# Note: gamma_optim$par[2] is 1/beta\ngamma_optim\n\n[1] 2.455855553 0.004344879"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#transfinite-example",
    "href": "blog/drafts/transfinite/transfinite.html#transfinite-example",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Transfinite Example",
    "text": "Transfinite Example\n\n\nOptimization returns \\(\\alpha\\) and \\(1/\\beta\\) for the gamma distribution example.\n\n\n\n# Analytic formula\nalpha_\n\n[1] 2.455801\n\n# Optimization\ngamma_optim[[1]]\n\n[1] 2.455856\n\n\n\n# Analytic formula\nbeta_\n\n[1] 230.1627\n\n# Optimization\n1/gamma_optim[[2]]\n\n[1] 230.156"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions",
    "href": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Optimization for Other Distributions",
    "text": "Optimization for Other Distributions\n\nJust swap in the distribution function for the distribution you want to match to (e.g., pbeta rather than pgamma).\nAlso make sure the supplied parameter names match the distribution you’re aiming for."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions-1",
    "href": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Optimization for Other Distributions",
    "text": "Optimization for Other Distributions\n\n\nJust swap in the distribution function for the distribution you want to match to (e.g., pbeta rather than pgamma).\nAlso make sure the supplied parameter names match the distribution you’re aiming for.\n\n\n\nTf &lt;- function(x, shape, rate)\n    pgamma(x,shape,rate,log=TRUE) - \n    pgamma(x,shape,rate,log=TRUE, lower.tail = FALSE)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions-2",
    "href": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Optimization for Other Distributions",
    "text": "Optimization for Other Distributions\n\n\nJust swap in the distribution function for the distribution you want to match to (e.g., pbeta rather than pgamma).\nAlso make sure the supplied parameter names match the distribution you’re aiming for.\n\n\n\nTf &lt;- function(x, shape, rate)\n    pgamma(x,shape,rate,log=TRUE) - \n    pgamma(x,shape,rate,log=TRUE, lower.tail = FALSE)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#a-web-based-shiny-tool",
    "href": "blog/drafts/transfinite/transfinite.html#a-web-based-shiny-tool",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "A Web-Based Shiny Tool",
    "text": "A Web-Based Shiny Tool\nhttps://yuhanxuan.shinyapps.io/shiny4dist/\nAuthor: Hanxuan (Astrid) Yu"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#summary-on-distribution-fitting",
    "href": "blog/drafts/transfinite/transfinite.html#summary-on-distribution-fitting",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Summary on Distribution Fitting",
    "text": "Summary on Distribution Fitting\n\nUse analytical formulas if they exist.\nOptimize on \\(\\text{logit}\\) scale.\nAgain, avoid \\(\\log\\) on probabilities, use log=TRUE.\nPlot results for visual check."
  },
  {
    "objectID": "blog/drafts/quasi-demeaning/quasi-demeaning.html",
    "href": "blog/drafts/quasi-demeaning/quasi-demeaning.html",
    "title": "Quasi-Demeaning: The Relationship Between Fixed and Random Effects",
    "section": "",
    "text": "Assume the following data generation process:\n\\[\nY_{it} = \\mathbf{X}_{i}'\\beta + \\tau D_{it} + U_i +\\epsilon_{it}\n\\] where \\(i\\) indexes individual units and \\(t\\) indexes time, \\(\\mathbf{X}_i\\) are unit-level attributes, \\(D_{it}\\) is a treatment indicator (set to 1 if the observation is treated and in the post-treatment period). Finally, \\(U_i\\) captures unobserved unit-level heterogeneity.\n\n\n\nRandom effects uses an approach called “quasi-demeaning” or “partial pooling.”\nThe random effects model can be represented as:\n\n\\[\n\\begin{align}\n(Y_{it}-\\theta \\bar{Y_i}) = (\\mathbf{X}_{it}-\\theta \\bar{\\mathbf{X}_i})'\\beta + \\tau (D_{it}-\\theta \\bar{D_i})  + (\\epsilon_{it} - \\theta \\bar{\\epsilon_i}) \\quad \\quad \\quad\n\\end{align}\n\\]\nwhere\n\\[\n\\theta = 1 - \\bigg [\\frac{\\sigma^2_\\epsilon}{(\\sigma^2_\\epsilon + T\\sigma^2_u)}\\bigg ]^{1/2}\n\\]\nIn the above, \\(\\sigma_u\\) is the variance of unit-level heterogeneity, and \\(\\sigma_{\\epsilon}\\) is the variance of \\(\\epsilon_{it}\\). And recall \\(T\\) is the total number of repeated unit-level observations in our panel (e.g., the total number of time periods, the total number of patients for a given physician, etc.)\n\nWhen \\(\\theta = 0\\), it just reduces pooled regression.\nWhen \\(\\theta = 1\\), it is equivalent to fixed effects regression. This only isolates variation within units to estimate the regression coefficients (i.e., units are only compared to themselves, which is why the unobserved heterogeneity is accounted for).\nEssentially, when you fit a random effects regression, Stata estimates \\(\\theta\\) and then plugs that estimate it into the above model.\n(When you fit a fixed effects regression, Stata uses the demeaning approach–unless, of course, you manually fit a dummy variable model)\nOften \\(0 &lt; \\theta &lt; 1\\), hence the term “partial-pooling.” That is, the regression draws on both variation “within” units and variation “between” units.\nThe degree to which within and between variation is used depends on the data context.\nRemember, when \\(\\theta=0\\) the random effects regression reduces to pooled OLS. When is this the case?\n\nIf the term \\(T\\sigma^2_u\\) is 0, i.e., \\(\\sigma^2_u=0\\) or there is no variation in individual heterogeneity.\n\nRemember, when \\(\\theta=1\\) the random effects regression reduces to fixed effects. When is this the case?\n\nIf the term \\(T\\sigma^2_u\\) gets super large (more formally, it would need to blast off towards infinity…).\nIf we have a very “large” panel of observations on each unit (i.e., large \\(T\\)) there is sufficient “within” variation and we really don’t need to do any pooling across units."
  },
  {
    "objectID": "blog/drafts/quasi-demeaning/quasi-demeaning.html#estimation-random-vs.-fixed-effects",
    "href": "blog/drafts/quasi-demeaning/quasi-demeaning.html#estimation-random-vs.-fixed-effects",
    "title": "Quasi-Demeaning: The Relationship Between Fixed and Random Effects",
    "section": "",
    "text": "Random effects uses an approach called “quasi-demeaning” or “partial pooling.”\nThe random effects model can be represented as:\n\n\\[\n\\begin{align}\n(Y_{it}-\\theta \\bar{Y_i}) = (\\mathbf{X}_{it}-\\theta \\bar{\\mathbf{X}_i})'\\beta + \\tau (D_{it}-\\theta \\bar{D_i})  + (\\epsilon_{it} - \\theta \\bar{\\epsilon_i}) \\quad \\quad \\quad\n\\end{align}\n\\]\nwhere\n\\[\n\\theta = 1 - \\bigg [\\frac{\\sigma^2_\\epsilon}{(\\sigma^2_\\epsilon + T\\sigma^2_u)}\\bigg ]^{1/2}\n\\]\nIn the above, \\(\\sigma_u\\) is the variance of unit-level heterogeneity, and \\(\\sigma_{\\epsilon}\\) is the variance of \\(\\epsilon_{it}\\). And recall \\(T\\) is the total number of repeated unit-level observations in our panel (e.g., the total number of time periods, the total number of patients for a given physician, etc.)\n\nWhen \\(\\theta = 0\\), it just reduces pooled regression.\nWhen \\(\\theta = 1\\), it is equivalent to fixed effects regression. This only isolates variation within units to estimate the regression coefficients (i.e., units are only compared to themselves, which is why the unobserved heterogeneity is accounted for).\nEssentially, when you fit a random effects regression, Stata estimates \\(\\theta\\) and then plugs that estimate it into the above model.\n(When you fit a fixed effects regression, Stata uses the demeaning approach–unless, of course, you manually fit a dummy variable model)\nOften \\(0 &lt; \\theta &lt; 1\\), hence the term “partial-pooling.” That is, the regression draws on both variation “within” units and variation “between” units.\nThe degree to which within and between variation is used depends on the data context.\nRemember, when \\(\\theta=0\\) the random effects regression reduces to pooled OLS. When is this the case?\n\nIf the term \\(T\\sigma^2_u\\) is 0, i.e., \\(\\sigma^2_u=0\\) or there is no variation in individual heterogeneity.\n\nRemember, when \\(\\theta=1\\) the random effects regression reduces to fixed effects. When is this the case?\n\nIf the term \\(T\\sigma^2_u\\) gets super large (more formally, it would need to blast off towards infinity…).\nIf we have a very “large” panel of observations on each unit (i.e., large \\(T\\)) there is sufficient “within” variation and we really don’t need to do any pooling across units."
  },
  {
    "objectID": "blog/drafts/power-simulation/power-simulation.html",
    "href": "blog/drafts/power-simulation/power-simulation.html",
    "title": "Using Simulation to Calculate Power and Minimum Detectable Effects",
    "section": "",
    "text": "This posting will walk through the steps to perform power and minimum detectable effect calculations via simulation.\nlibrary(mcreplicate)\nlibrary(tidyverse)\nlibrary(tictoc)\nlibrary(CVXR)"
  },
  {
    "objectID": "blog/drafts/power-simulation/power-simulation.html#power",
    "href": "blog/drafts/power-simulation/power-simulation.html#power",
    "title": "Using Simulation to Calculate Power and Minimum Detectable Effects",
    "section": "Power",
    "text": "Power\n\nB = 1000\npower =\n    seq(100,1000,100) %&gt;%\n    map(~(mc_replicate(B,est_power(modifyList(params,list(beta = .1,n=.x))),mc.cores=10))) %&gt;%\n    map_dbl(~(mean(.x)))  %&gt;%\n    data.frame(row.names = seq(100,1000,100)) %&gt;%\n    rownames_to_column(var = \"N\") %&gt;%\n    set_names(c(\"N\",\"power\")) %&gt;%\n    as_tibble() %&gt;%\n    mutate(N = as.numeric(paste0(N)))\npower %&gt;% knitr::kable()\n\n\n\n\nN\npower\n\n\n\n\n100\n0.150\n\n\n200\n0.297\n\n\n300\n0.433\n\n\n400\n0.512\n\n\n500\n0.603\n\n\n600\n0.681\n\n\n700\n0.758\n\n\n800\n0.793\n\n\n900\n0.852\n\n\n1000\n0.876\n\n\n\n\npower %&gt;%\n    ggplot(aes(x = N , y = power)) + geom_line() +\n    ggthemes::theme_few()"
  },
  {
    "objectID": "blog/posts/power-mde/power-and-minimum-detectible-effects.html",
    "href": "blog/posts/power-mde/power-and-minimum-detectible-effects.html",
    "title": "Using Simulation to Calculate Power and Minimum Detectable Effects",
    "section": "",
    "text": "This posting will walk through the steps to perform power and minimum detectable effect calculations via simulation.\nlibrary(mcreplicate)\nlibrary(tidyverse)\nlibrary(tictoc)\nlibrary(CVXR)"
  },
  {
    "objectID": "blog/posts/power-mde/power-and-minimum-detectible-effects.html#power",
    "href": "blog/posts/power-mde/power-and-minimum-detectible-effects.html#power",
    "title": "Using Simulation to Calculate Power and Minimum Detectable Effects",
    "section": "Power",
    "text": "Power\n\nB = 1000\npower =\n    seq(100,1000,100) %&gt;%\n    map(~(mc_replicate(B,est_power(modifyList(params,list(beta = .1,n=.x))),mc.cores=10))) %&gt;%\n    map_dbl(~(mean(.x)))  %&gt;%\n    data.frame(row.names = seq(100,1000,100)) %&gt;%\n    rownames_to_column(var = \"N\") %&gt;%\n    set_names(c(\"N\",\"power\")) %&gt;%\n    as_tibble() %&gt;%\n    mutate(N = as.numeric(paste0(N)))\npower %&gt;% knitr::kable()\n\n\n\n\nN\npower\n\n\n\n\n100\n0.151\n\n\n200\n0.298\n\n\n300\n0.407\n\n\n400\n0.510\n\n\n500\n0.612\n\n\n600\n0.695\n\n\n700\n0.748\n\n\n800\n0.805\n\n\n900\n0.865\n\n\n1000\n0.885\n\n\n\n\npower %&gt;%\n    ggplot(aes(x = N , y = power)) + geom_line() +\n    ggthemes::theme_few()"
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "",
    "text": "Part one in a three-part series on how the tools of welfare analysis and decision science can be used to inform the direction, scope, and design of research and decision-making."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#introduction",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#introduction",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "Introduction",
    "text": "Introduction\nSuppose a policymaker is considering strategies to reduce poverty. For the sake of simplicity, let’s assume the policymaker is weighing the tradeoffs of creating or expanding an in-kind benefit transfer, such as a job training program.\nImplementing the program has a measurable impact on welfare-relevant outcomes (e.g., education, lifetime earnings, health, etc.). However, the program also imposes costs on society. These costs reflect both the budgetary cost (i.e., the total sum of program expenditures), as well as other changes in behavior, expenditures, or tax revenues that either bolster or drag on social welfare.\nBefore we proceed, it is useful to formalize the above and define summary measures of policy benefits \\(W(\\mathbf{\\pi},\\alpha)\\) and costs \\(C(\\mathbf{\\pi},\\alpha)\\). The vector \\(\\mathbf{\\pi}\\) captures welfare-relevant parameters such as the average willingness-to-pay for the policy, program costs, and any fiscal externalities (FEs) that occur as a consequence of the policy.1 We define and measure welfare benefits and costs for each of \\(D\\) total policy strategies \\(\\boldsymbol{\\alpha} = (\\alpha_1, \\cdots , \\alpha_D)\\).\n1 For example, these fiscal externalities might include changes to government tax revenues stemming from changes in participation in the labor force and/or other social programs.In a series of influential papers, Hendren and colleagues define the Marginal Value of Public Funds (MVPF) as the ratio of benefits to costs (Finkelstein and Hendren 2020; Hendren and Sprung-Keyser 2022, 2022; Hendren 2016):\n\\[\nMVPF(\\mathbf{\\pi},\\alpha) = \\frac{W(\\mathbf{\\pi},\\alpha)}{C(\\mathbf{\\pi},\\alpha)}\n\\tag{1}\\]\nThe MVPF measures the marginal value of an additional dollar spent on a policy. That is, the MVPF quantifies how the welfare benefits accrued by implementing a policy compare to the costs of adopting it.\nWhile we will leave the theoretical details to the aforementioned citations, we can summarize the MVPF of an in-kind benefit transfer as:\n\\[\nMVPF^{\\text{inkind}}(\\mathbf{\\pi},\\alpha) = \\frac{W(\\mathbf{\\pi},\\alpha)}{1+FE(\\mathbf{\\pi},\\alpha)}\n\\tag{2}\\] where \\(FE(\\mathbf{\\pi},\\alpha)\\) is the fiscal externality associated with the policy, and \\(W(\\mathbf{\\pi},\\alpha)\\) is the willingness to pay among infra-marginal recipients of the program.\nIn this example, we are comparing a single policy strategy (in-kind benefit program) to an alternative strategy of doing nothing. However, in principle we could think of alternative (competing) strategies to achieve the same objective—each with its own welfare cost and benefit estimates—that might be under consideration."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-state-of-current-knowledge",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-state-of-current-knowledge",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "The State of Current Knowledge",
    "text": "The State of Current Knowledge\nSuppose that previous research has quantified the welfare benefits and costs—such that the hypothetical policymaker has at her disposal some information that can guide her decision on which policy (if any) to pursue.\nThe state of current information is summarized in Table 1.\n\n\n\n\nTable 1: Summary of Current Knowledge\n\n\n\n\n\n\n\nMVPF [95% interval]\nBenefits [95% Interval]\nCosts [95% Interval]\n\n\n\n\ninkind\n0.89 [0.73,1.08]\n1.21 [0.99,1.46]\n1.35 [0.31,0.39]"
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#mvpf-as-a-decision-tool",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#mvpf-as-a-decision-tool",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "MVPF as a Decision Tool",
    "text": "MVPF as a Decision Tool\nTable 1 highlights that the policymaker’s decision is fraught with uncertainty. Based on current information, the estimated MVPF of the in-kind benefit is 0.894. However, the 95% interval shows that current knowledge is consistent with the policy more than paying for itself (i.e., an MVPF above 1), and with the policy resulting in some redistribution (i.e., an MVPF below 1).\nIn short, based on current evidence, it is hard to say for sure whether the policy should be adopted.\nOur policymaker’s decision problem actually goes one step further. The MVPF summarizes the private benefits that accrue from the in-kind benefit transfer; it may be that social preferences are such that, from a societal perspective, a policy with an MVPF below 1.0 is not worth pursuing.\nWe can formalize this idea by defining an additional parameter \\(\\lambda\\) summarizing societal willigness-to-pay (WTP). This threshold value could simply be based on an MVPF of one (i.e., the benefit must be at least as great as the cost). Or, if society values some redistributive consequence of the policy, \\(\\lambda\\) could be set based on a value less than one.2\n2 For example, Finkelstein, Hendren, and Shepard (2019) make comparative assessments of health insurance subsidization policies by specifying a social welfare function over Constant Relative Risk Aversion (CRRA) utility and a defined coefficient of risk aversion (\\(\\sigma = 3\\)). This results in \\(\\lambda = 0.2\\). But researchers do not necessarily have to specify the structure of the social welfare function to define a decision-making benchmark. A value tied to an existing policy with strong social support could also suffice. For instance, Finkelstein, Hendren, and Shepard (2017) also consider a benchmark (\\(\\lambda = 0.88\\)) based on the MVPF of the Earned Income Tax Credit (EITC)—a popular means-tested cash transfer program. Finally, Hendren (2020) argues for the use of efficient welfare weights that project the welfare costs and benefits of any specific policy into the MVPF of a tax transfer between the affected populations.3 For the sake of this example, welfare benefits are drawn from a lognormal distribution with mean \\(\\log(1.2)\\) and standard deviation \\(0.1\\). Welfare costs are based on Equation 2 and a fiscal externality that is normally distributed with mean \\(0.35\\) and standard deviation \\(0.2\\).Figure 1 visualizes this uncertainty for 1,000 draws from the uncertainty distributions of \\(W^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\) and \\(C^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\) in Table 1.3 In addition, for three hypothetical values of \\(\\lambda\\), each point is shaded based on whether the implied MVPF is above or below \\(\\lambda\\).\nThe dotted lines show a ray from the origin with slope \\(1/\\lambda\\); values that fall under and to the right of the line are those where the MVPF\\(\\geq \\lambda\\) and those that fall up and to the left of the line are those where MVPF\\(&lt;\\lambda\\). Finally, the green diamonds plot the average welfare benefit and cost values as summarized in Table 1.\n\n\n\n\n\n\n\n\n\n\n\n(a) lambda = 1.0\n\n\n\n\n\n\n\n\n\n\n\n(b) lambda = 0.90\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) lambda = 0.5\n\n\n\n\n\n\n\nFigure 1: Welfare Cost and Benefits Overlaid With Decision Rules Based on \\(\\lambda\\)\n\n\n\nFigure 1 (a) highlights that when \\(\\lambda=1\\), the MVPF of the in-kind benefit strategy rarely exceeds the societal willingness-to-pay threshold. In other words, there are few points in the joint uncertainty distribution where the value falls below and to the right of the dotted line. Thus, there is some—but not much—uncertainty in the decision to not implement the policy under this decision criterion.\nBy comparison, Figure 1 (c) shows that when \\(\\lambda=0.5\\), there is no decision uncertainty; our policymaker would conclude that the the in-kind benefit should be adopted—and this decision is consistent across all values in the uncertainty ranges."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-opportunity-cost-of-imperfect-information",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-opportunity-cost-of-imperfect-information",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "The Opportunity Cost of Imperfect Information",
    "text": "The Opportunity Cost of Imperfect Information\nThe above discussion highlights that depending on social preferences, policy decisions based on current information may carry an opportunity cost of making the wrong decision. This is most evident in Figure 1 (b), where based on the average welfare cost estimates in Table 1 (plotted as a green dot in Figure 1 (b)), the policymaker might elect to pursue an in-kind benefit program. In other words, the implied average MPVF basd on these values is 0.894. If \\(\\lambda = 0.9\\), this value is below the WTP threshold—so the policy would appear to pass a societal cost-benefit test.\nHowever, Figure 1 (b) also makes clear the available information is also consistent with the “true” MVPF falling above \\(\\lambda\\). That is, roughly half of the points are shaded gold (i.e., the policy does not pass our defined societal cost-benefit test) and half are shaded black (i.e., MVPF\\(&lt;\\lambda\\)). If the true MVPF is below \\(\\lambda\\), then society would incur a net welfare loss from implementing the policy.\nContrast this with the scenario in Figure 1 (c), which is based on \\(\\lambda = 0.5\\). In that scenario, there is uncertainty in the underlying welfare estimates but no uncertainty in policy adoption decisions. The same decision (to implement the in-kind benefit program) occurs across the entire uncertainty range, so there is no opportunity cost to making the “wrong” decision."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#net-welfare-benefit",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#net-welfare-benefit",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "Net Welfare Benefit",
    "text": "Net Welfare Benefit\nLet’s now formalize the above observations by defining the net welfare benefit as the benefits of a given policy minus \\(\\lambda\\) multiplied by the costs:\n\\[\nNWB(\\boldsymbol{\\pi},\\alpha,\\lambda) = W(\\boldsymbol{\\pi},\\alpha) - \\lambda \\cdot C(\\boldsymbol{\\pi},\\alpha)\n\\tag{3}\\]\nIntuitively, policies where \\(NWB \\geq 0\\) indicate situations where the MVPF is equal to or greater than \\(\\lambda\\). Put simply, when the NWB is positive, the policy passes the societal cost-benefit test; when it is negative, it does not.\nWith the NWB defined, it is useful to think about uncertainty along two distinct but related dimensions:\n\nVariation in the NWB that derives from sampling/structural/modeling uncertainty in estimates of \\(W^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\) and \\(C^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\).\nVariation in optimal decisions, which occurs when variation from (1) causes frequent sign changes in the NWB.\n\nIn other words, depending on the value of \\(\\lambda\\), variation in welfare outcomes (costs and benefits) does not necessarily imply variation in optimal decisions; it may be \\(\\lambda\\) is sufficiently low (or high) that policy decisions do not vary across the uncertainty distribution.4\n4 This is the scenario depicted in Figure 1 (c)."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#from-net-welfare-benefit-to-value-of-information",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#from-net-welfare-benefit-to-value-of-information",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "From Net Welfare Benefit to Value of Information",
    "text": "From Net Welfare Benefit to Value of Information\nThe idea that decisions based on current information may carry a welfare-valued opportunity cost underlies decision theoretic concepts of the value of information (VOI).\nBefore we define various VOI concepts and measures, let’s lay out the practical questions a VOI-based approach to welfare analysis based on the MVPF can answer:\n\nWhich strategies are cost-effective given social preferences and based on current evidence? To answer this question, we can assess whether current knowledge–cast against a summary measure of social preferences such as \\(\\lambda\\)—is sufficient to confidently make policy decisions. Because we may not want to make a stance on the particular value of \\(\\lambda\\), we can vary these assessments over a plausible range of values and estimate the expected welfare loss of making the wrong decision at a given value of \\(\\lambda\\).\nShould we invest more resources to reduce uncertainty in our decisions? If so, it will be important to isolate which sources of uncertainty we should focus on. Furthermore, we want to think about the most efficient way to sample the population to improve our knowledge on these dimensions."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-welfare-loss-from-imperfect-information",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-welfare-loss-from-imperfect-information",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "The Welfare Loss from Imperfect Information",
    "text": "The Welfare Loss from Imperfect Information\nTo answer the first question, we need a summary measure of the expected welfare loss from making the wrong decision.\nDefine the optimal strategy as\n\\[\n\\alpha^* =\\arg\\max E_{\\boldsymbol{\\pi}} \\big [ NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ]\n\\] so that \\(NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\\) is the net welfare benefit evaluated at the optimal strategy, i.e.,\n\\[\nNWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda) = \\max_{\\boldsymbol{\\alpha}} E_{\\boldsymbol{\\pi}} \\big [  NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ]\n\\]\nNext, define a welfare loss function\n\\[\nL_{\\alpha} = \\max_{\\boldsymbol{\\alpha}} NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) - NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda)\n\\tag{4}\\]\nThe loss function evaluated at \\(\\alpha^*\\) is\n\\[\nL_{\\alpha^*} = \\max_{\\boldsymbol{\\alpha}} NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) - NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\n\\tag{5}\\]\nAnd its expected value is given by\n\\[\nE_{\\boldsymbol{\\pi}} \\big [ L_{\\alpha^*} \\big ]  = E_{\\boldsymbol{\\pi}} \\big [ \\max_{\\boldsymbol{\\alpha}} NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ] - NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\n\\tag{6}\\]\nThe expected welfare loss in Equation 6 is also known as the expected value of perfect information (Jackson et al. 2022; Wilson 2015):\n\\[\nE_{\\boldsymbol{\\pi}} \\big [ L_{\\alpha^*} \\big ]  = EVPI(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda)\n\\]\n\nEstimating the Expected Welfare Loss\nThe code below calcualtes the EVPI for the MVPF of the in-kind benefit transfer above, for a particular value of \\(\\lambda\\):\n\nset.seed(23)\nn &lt;- 1e5   # Number of uncertainty distribution draws\nw &lt;- rlnorm(n, log(1.2),0.1)   # welfare benefit is lognormal(ln(1.2),0.1)\nfe &lt;- rnorm(n, 0.35,.02)  # fiscal externality is norm(0.35,0.02)\nc &lt;- 1+fe  # cost is denominator of MVPF\n\nlambda &lt;- 0.9  # set a societal WTP value\nnwb &lt;- w - lambda * c  # calculate the net welfare benefit\nevpi &lt;-mean(pmax(0,nwb))-max(0,mean(nwb))  # expected value of perfect information\nevpi\n\n[1] 0.04441101\n\n\nThe estimated EVPI (0.044) is non-zero, indicating that there is overall value in reducing uncertainty in the policymaker’s decision to implement the in-kind benefit transfer. However, note that the EVPI varies over different values of \\(\\lambda\\). If \\(\\lambda\\) were instead 0.5, we would make the same decision (to implement the policy) across the entire uncertainty range—so there is no value in obtaining new information on uncertain inputs into the MVPF estimate. This can be seen in the code below:\n\nlambda &lt;- 0.5 # set a societal WTP value\nnwb_alt &lt;- w - lambda * c  # calculate the net welfare benefit\nevpi_alt &lt;-mean(pmax(0,nwb_alt))-max(0,mean(nwb_alt))  # expected value of perfect information\nevpi_alt\n\n[1] 0\n\n\nFigure 2 is based on repeating the above exercise across a variety of \\(\\lambda\\) values (x-axis) and plotting the resulting EVPI estimate for each (y-axis):\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Expected Value of Reducing Decision Uncertainty Through Future Research, by Societal Willingness-to-Pay Value (lambda)"
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#summary-and-next-steps",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#summary-and-next-steps",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "Summary and Next Steps",
    "text": "Summary and Next Steps\nFigure 2 tells us that based on existing evidence, we have an answer to our first question: if the societal willigness-to-pay value (\\(\\lambda\\)) is in the neighborhood of 0.75-1.15, then there is high information value in future research to reduce uncertainty in \\(W(\\mathbf{\\pi},\\alpha)\\) and \\(C(\\mathbf{\\pi},\\alpha)\\).\nWith this information in mind—and so long as pursuing more information has value—we can move on to the second question and start to ask (a) which specific sources of uncertainty (i.e., individual parameters or sets of parmeters in \\(W(\\mathbf{\\pi},\\alpha)\\) and \\(C(\\mathbf{\\pi},\\alpha)\\)) drive the overall EVPI estimate? And how can we prospectively design a clinical trial or randomized evaluation in such a way as to most efficiently reduce information uncertainty to a point where a better decision can be made? Answering these questions is the focus of part two in this series."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vanderbilt Center for Health Economic Modeling",
    "section": "",
    "text": "Using Simulation to Calculate Power and Minimum Detectable Effects\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2023\n\n\nJohn Graves\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Decision Theory\n\n\nPart One: Net Welfare Benefit and the Value of Information\n\n\n\n\n\n\n\n\nNov 1, 2023\n\n\nJohn Graves\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Research Prioritization\n\n\nPart Two: Using the MVPF to Inform the Direction of Future Research\n\n\n\n\n\n\n\n\nNov 1, 2023\n\n\nJohn Graves\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Study Design\n\n\nPart Three: Using the MVPF to Inform the Design of a Randomized Experiment\n\n\n\n\n\n\n\n\nNov 1, 2023\n\n\nJohn Graves\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Center Blog"
    ]
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html",
    "title": "Welfare Analysis Meets Study Design",
    "section": "",
    "text": "Part three in a three-part series on how the tools of comparative welfare analysis can be used to refine and design prospective randomized evaluations.\nReference"
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html#what-is-the-expected-value-of-sample-information",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html#what-is-the-expected-value-of-sample-information",
    "title": "Welfare Analysis Meets Study Design",
    "section": "What is the Expected Value of Sample Information?",
    "text": "What is the Expected Value of Sample Information?\nTo build an intuitive foundation for what follows, suppose we decide to design a randomized experiment that will improve our knowledge of MVPF parameter(s) \\(\\pi_z\\).3\n3 Note that all other remaining MVPF parameters in \\(\\mathbf{\\pi}\\) are captured in \\(\\mathbf{\\pi_{-z}}\\), such that \\(\\mathbf{\\pi} = (\\mathbf{\\pi_{z}},\\mathbf{\\pi_{-z}})\\).We traditionally think about the design of randomized experiments in terms of their statistical power—that is, the probability that a statistical test will detect a difference between treated and untreated groups, when such a difference exists.\nAnother way to state the above is that we want to avoid Type II error. But there are often practical (often resource-based) limits to how far we are willing to go on this.\nOne way to minimize Type II error is simply to enroll thousands or even millions of study units (e.g., people, households, clinics, etc.). But while that would yield a trial with power at or near 100%, our trial would be costly, time-consuming, and resource intensive—and we may well incur an additional loss in social welfare if an efficacious policy is (randomly) withheld from a large fraction of the overall population.\nConsequently, it is common to think of trial design in terms of enrolling enough study units so that a comparison of outcomes between treated and treated units has least 80% power to detect an effect. There is a vast statistical literature specifying analytic formulas and simulation-based exercises to optimize this (statistical) dimension of experimental design.\nA useful way to think about the EVSI is as the social welfare analog to power. That is, we want to avoid implementing a policy that results in a sub-optimal level of social welfare. It may be that doing nothing (or implementing some alternative policy option) would be the welfare-optimizing choice–but the available (uncertain) evidence leads us down the wrong decision path. To avoid this, we can leverage the EVSI to guide our study design so that we can optimize societal payoff of both the research itself, and the resulting policy decision.\nFrom a design perspective, the EVPPI for our parameter(s) of interest (\\(\\pi_z\\)) provides an upper bound on the information value that would accrue from obtaining perfect information on the “true” value(s) of \\(\\pi_z\\). In that sense, designing a trial that enrolls enough people or units to obtain an EVSI that is very close to the EVPPI is like designing a trial with statistical power at or near 100%.\nBy the same token, we can also think about designing a smaller-scale experiment that provides some new information value, but not (near) perfect information. But just as we want to avoid an under-powered trial, we also want to avoid a situation where the information value we obtain from our study is not enough to inform the policymaker’s decision.\nCalculating the EVSI for different trial sizes (and designs) allows us to do just this."
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html#expected-value-of-perfect-information",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html#expected-value-of-perfect-information",
    "title": "Welfare Analysis Meets Study Design",
    "section": "Expected Value of Perfect Information",
    "text": "Expected Value of Perfect Information\nOur first guidepost is to make sure that any future research would help inform our policymaker’s decision.6 To assess this, we estimate the EVPI for various societal willingness-to-pay parameter (\\(\\lambda\\)) values. Figure 1 summarizes this exercise.\n6 We covered the EVPI in detail in part one of this series, however both the formulas and code are provided here for the example at hand.\n\n\n\n\n\nEVPI Equations and Notation (click to expand)\n\n\n\n\n\nPolicy benefits are summarized by \\(W(\\mathbf{\\pi},\\alpha)\\), and costs by \\(C(\\mathbf{\\pi},\\alpha)\\). The vector \\(\\mathbf{\\pi}\\) captures welfare-relevant parameters such as the average willingness-to-pay for the policy, program costs, and any fiscal externalities (FEs) that occur as a consequence of the policy.\nWe define and measure welfare benefits and costs for each of \\(D\\) total policy strategies \\(\\boldsymbol{\\alpha} = (\\alpha_1, \\cdots , \\alpha_D)\\).\nFinally, \\(\\lambda\\) summarizes societal willigness-to-pay (WTP), i.e., a policy with MVPF greater than or equal to \\(\\lambda\\) passes a societal cost-benefit test. This threshold value could simply be based on an MVPF of one (i.e., the benefit must be at least as great as the cost). Or, if society values some redistribution, \\(\\lambda\\) could be set based on a value less than one.\nThe net welfare benefit (NWB) is defined as:\n\\[\nNWB(\\boldsymbol{\\pi},\\alpha,\\lambda) = W(\\boldsymbol{\\pi},\\alpha) - \\lambda \\cdot C(\\boldsymbol{\\pi},\\alpha)\n\\tag{1}\\]\nand we define the optimal strategy as\n\\[\n\\alpha^* =\\arg\\max E_{\\boldsymbol{\\pi}} \\big [ NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ]\n\\]\nwhere \\(E_{\\pi}\\) is the expectation over the joint uncertainty distribution of current knowledge. Thus, \\(NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\\) captures the net welfare benefit evaluated at the optimal strategy.\nThe Expected Value of Perfect Information (EVPI) is given by:\n\\[\nEVPI(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) = E_{\\boldsymbol{\\pi}} \\big [ \\max_{\\boldsymbol{\\alpha}} NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ] - NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\n\\tag{2}\\]\n\n\n\n\n\nCode\ncalc_nwb &lt;- function(B,C,lambda) {\n    B - lambda * C\n}\n\ncalc_evpi &lt;- function(B,      # Benefits\n                      C,      # Net Costs\n                      lambda  # Societal willingness-to-pay \n                     ) {\n    nwb_ &lt;- calc_nwb(B = B, C = C, lambda = lambda)\n    evpi &lt;- mean(pmax(0,nwb_))-max(0,mean(nwb_)) \n    return(tibble(lambda = lambda, evpi = evpi))\n}\n\nevpi_data &lt;- \n    lambdas %&gt;% \n    map_df(~(calc_evpi(B = delta_W, C = (delta_E - delta_C), lambda = .x)))\n\nxlab &lt;- expression(paste(\"MVPF Value of Societal Willingness-to-Pay (\",lambda,\")\"))\n  \np &lt;- \n    evpi_data %&gt;% \n    ggplot(aes(x = lambda, y = evpi)) + \n    geom_point(size = 4) + geom_line(linewidth=1.25) + \n    theme_hc() + \n    theme(text = element_text(family = 'Arial')) +\n    labs(x = xlab, y = \"Value of Information\\nEVPI\")\n    #labs(x = \"Societal WTP Value (lambda)\", y = \"Value of Information (EVPI, EVPPI)\")\np\n\n\n\n\n\n\n\n\nFigure 1: Expected Value of Perfect Information by Societal Willingness to Pay Value\n\n\n\n\n\nFigure 1 shows that there is overall value in reducing information uncertainty in the policy decision—and this information value is maximized near a \\(\\lambda\\) value of 0.85.7\n7 To provide some context for this value, Hendren (2016) estimates that the the MVPF for the Earned Income Tax Credit (EITC)—a popular means-tested cash transfer program—is around 0.9. It is worth noting, however, that later updates center the EITC MVPF estimate at 1.12."
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html#expected-value-of-partial-perfect-information",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html#expected-value-of-partial-perfect-information",
    "title": "Welfare Analysis Meets Study Design",
    "section": "Expected Value of Partial Perfect Information",
    "text": "Expected Value of Partial Perfect Information\nOur next task is to prioritize future research around efforts to obtain information on parameter(s) with high information value. To do this, we will take probabilistic draws from the joint uncertainty distribution of the MVPF paramters in Table 1 and fit flexible metamodels for each parameter, with the calculated net welfare benefit as the outcome.8\n8 Details on how to do this are provided in part two.\n\n\n\n\n\nEVPPI Equations and Notation\n\n\n\n\n\nSuppose we could obtain perfect information on some subset (\\(\\boldsymbol{\\pi}_z\\)) of the parameter(s) that determine the MVPF; we do not pursue additional research on the remaining uncertain parameters \\(\\boldsymbol{\\pi}_{-z}\\).\nThe expected value of partial perfect information (EVPPI) is defined as:\n\\[\nEVPPI(\\boldsymbol{\\pi}_z,\\lambda) = E_{\\boldsymbol{\\pi_z}} \\big [  \\max_{\\boldsymbol{\\alpha}} E_{\\boldsymbol{\\pi_{-z}}|\\boldsymbol{\\pi_z}}NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi}_z,\\boldsymbol{\\pi}_{-z},\\lambda) \\big ] -\n\\max E_{\\boldsymbol{\\pi}} \\big [ NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ]\n\\tag{3}\\]\n\n\n\nBased on this exercise, we can calculate and plot the EVPPI value for each MVPF parameter for various \\(\\lambda\\) values:\n\n\nCode\nest_evppi &lt;- function(B ,C,pi,lambda) {\n    nwb_ &lt;- calc_nwb(B = B, C = C, lambda = lambda)\n    \n    evppi_2 &lt;- pmax(0,mean(nwb_))\n    \n    evppi &lt;- list()\n    \n    names(pi) %&gt;% \n        map(~{\n            z &lt;- pi[[.x]]\n            mm.fit &lt;- gam(nwb_ ~ te(z))\n            evppi_inner &lt;- pmax(0, mm.fit$fitted)\n            evppi_1 &lt;- mean(evppi_inner)\n            evppi[[.x]] &lt;- evppi_1 - evppi_2\n        }) %&gt;% \n        set_names(names(pi)) %&gt;% \n        unlist()\n\n}\n\nevppi_lambdas &lt;- \n    lambdas %&gt;% \n    map(~(est_evppi(B = delta_W, C = (delta_E - delta_C), pi = pi, lambda = .x))) %&gt;% \n    bind_rows() %&gt;% \n    mutate(lambda = lambdas)\ncolnames(evppi_lambdas) &lt;- gsub(\"delta_\",\"\",colnames(evppi_lambdas))\n\np2 &lt;- \n    evppi_lambdas %&gt;% \n    gather(z,value,-lambda) %&gt;% \n    mutate(z = gsub(\"delta_\",\"\",z)) %&gt;% \n    ggplot() + geom_line(aes(x = lambda, y = value, colour = z )) + \n    ggsci::scale_color_d3() + \n    theme_hc() + \n    theme(text = element_text(family = 'Arial')) +\n    labs(x = xlab, y = \"Value of Information (EVPI, EVPPI)\")\n\ndirect.label(p2,list(method = \"top.bumponce\" , fontface=\"bold\", fontfamily ='Arial'))\n\n\n\n\n\n\n\n\nFigure 2: Expected Value of Partial Perfect Information by Societal Willingness to Pay Value\n\n\n\n\n\nFigure 2 shows that for \\(\\lambda\\) values near 0.85, the parameter summarizing the welfare benefit of the policy has the highest (partial) information value—though the taxpayer benefit parameter (\\(C\\)) also has high information value, especially for higher \\(\\lambda\\) values."
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html#what-happens-with-different-lambda-values",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html#what-happens-with-different-lambda-values",
    "title": "Welfare Analysis Meets Study Design",
    "section": "What Happens with Different \\(\\lambda\\) values?",
    "text": "What Happens with Different \\(\\lambda\\) values?\nThe exercise above was carried out with a single societal willingness-to-pay parameter value in mind (\\(\\lambda=0.85\\)) but it is straightforward to carry out same exercise for different \\(\\lambda\\) values.\n\n\nCode\np_evsi2 &lt;- \n    evsi %&gt;%\n    bind_rows(evsi2) %&gt;% \n  mutate(evppi = ifelse(lambda ==0.85, evppi_w, evppi_w2)) %&gt;% \n  mutate(lab = glue::glue(\".  {n} ({round(100*value/evppi,1)}%)\")) %&gt;% \n    ggplot(aes(x = n, y = value, colour = factor(lambda))) + geom_point() + geom_line() + theme_hc() + \n    ggsci::scale_color_d3()+\n    geom_hline(aes(yintercept = evppi_w), colour = \"darkred\") + geom_text(aes(label = lab,hjust=0)) + \n    geom_hline(aes(yintercept = evppi_w2), colour = \"darkred\") +\n    theme(legend.position = \"none\") +\n    labs(x = \"Experimental Sample Size\", y = \"Expected value of Sample Information (EVSI)\") + \n    annotate(\"text\",x = 0, y = evppi_w, label = glue::glue(\"EVPPI (lambda = 0.85): {round(evppi_w,2)}\"),vjust=-1,hjust=0, colour= \"darkred\") +\n   annotate(\"text\",x = 0, y = evppi_w2, label = glue::glue(\"EVPPI (lambda = 1.0): {round(evppi_w2,2)}\"),vjust=-1,hjust=-1, colour= \"darkred\") +\n    scale_y_continuous(expand = c(.25,0)) + theme(text = element_text(family = 'Arial')) +\n  scale_x_continuous(expand=expansion(mult = c(0, .35)),breaks = c(100,250, 500, 1000,2000, 5000, 10000),guide = guide_axis(n.dodge=3))\np_evsi2\n\n\n\n\n\n\n\n\nFigure 4: Expected Value of Sample Information (% of EVPPI) by Societal Willingness to Pay Value"
  },
  {
    "objectID": "blog/posts/mvpf-evppi/mvpf-evppi.html",
    "href": "blog/posts/mvpf-evppi/mvpf-evppi.html",
    "title": "Welfare Analysis Meets Research Prioritization",
    "section": "",
    "text": "Part two in a three-part series on how the tools of comparative welfare analysis can be used to refine and design prospective randomized evaluations."
  },
  {
    "objectID": "blog/posts/mvpf-evppi/mvpf-evppi.html#estimating-the-expected-value-of-partial-perfect-information",
    "href": "blog/posts/mvpf-evppi/mvpf-evppi.html#estimating-the-expected-value-of-partial-perfect-information",
    "title": "Welfare Analysis Meets Research Prioritization",
    "section": "Estimating the Expected Value of Partial Perfect Information",
    "text": "Estimating the Expected Value of Partial Perfect Information\nWe can estimate the EVPPI by drawing values from the joint uncertainty distributions of \\(W^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\) and \\(C^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\).\nSpecifically, suppose we construct a \\(K\\)-sized sample of model outputs from a Monte Carlo-based exercise. That is, we draw sets of parameters \\(\\boldsymbol{\\pi}^{(1)},\\ldots,\\boldsymbol{\\pi}^{(K)}\\) and generate a \\(K\\)-sized vector of net welfare benefits for a given \\(\\lambda\\) value.\nThe code below samples the constituent pieces for the MVPF and NWB for \\(\\lambda=0.88\\):\n\nset.seed(23)\nK &lt;- 1e5\nlambda = 0.88\nw_inkind = rlnorm(K, log(1.2),0.1)\nfe_inkind = rnorm(K, 0.35,.02)\nc_inkind = 1+fe_inkind\nnwb_inkind = w_inkind - lambda * c_inkind\n\n\n\n\n\nAt \\(\\lambda = 0.88\\) the in-kind benefit passes the societal cost-benefit test, so implementation of the in-kind benefit (as compared with doing nothing) is the optimal strategy based on current information. Therefore, the second term in Equation 3 (i.e., \\(E_{\\boldsymbol{\\pi}}[NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)]\\)) is simply the average NWB of the in-kind benefit:\n\nevppi_2 &lt;- pmax(0,mean(nwb_inkind))\nevppi_2\n\n[1] 0.01831933\n\n\nEstimation of the conditional expectation in the first term in equation Equation 3 is less straightforward. Borrowing from the approach in Strong, Oakley, and Brennan (2014), we can express the NWB outcome as the sum of a conditional expectation plus a mean-zero error term:\n\\[\nNWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi^{(k)}},\\lambda)  =  E_{\\boldsymbol{\\pi_{-z}}|\\boldsymbol{\\pi_z}=\\boldsymbol{\\pi_z}^{(k)}}NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi}_z^{(k)},\\boldsymbol{\\pi}_{-z},\\lambda)  + \\epsilon^{(k)}\n\\tag{4}\\]\nIn addition, the expectation in equation Equation 4 can be thought of in terms of an unknown function \\(g(\\cdot)\\) of \\(\\boldsymbol{\\pi_z}\\):\n\\[\nNWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi^{(k)}},\\lambda)  = g(\\boldsymbol{\\alpha},\\boldsymbol{\\pi}_z^{(k)},\\lambda) + \\epsilon^{(k)}\n\\tag{5}\\]\nBased on equation Equation 5, one option is to estimate the conditional expectation using a “metamodel,” or a regression model predicting how the net welfare benefit for a particular policy varies with unknown parameters of interest \\(\\boldsymbol{\\pi}_z\\). For example, a metamodel might specify the function \\(g(\\cdot)\\) as a standard linear regression. Alternatively, we might not wish to impose a functional form and instead estimate \\(g(\\cdot)\\) nonparametrically.3\n3 If we suspect the underlying relationships have important nonlinearities in the parameters of interest, we could also appeal to machine learning methods to estimate \\(g(\\cdot)\\).4 In our running example, we have a scalar value for welfare benefits and costs, so the metamodels end up being quite simple in structure. In principle, however, multiple parameters might inform the overall welfare cost or benefit values—in which case we could think of estimating metamodels separately for each, or combine them all into a single metamodel with interaction terms, etc. to capture dependencies or nonlinearities among them in determining the overall welfare benefit or cost value.The code below estimates basic metamodels separately for welfare benefits and costs using a generalized additive model:4\n\n# Metamodel for welfare benefits\ngam.w &lt;- gam(nwb_inkind ~ w_inkind)\n\n# Metamodel for welfare costs\ngam.c &lt;- gam(nwb_inkind ~ c_inkind)\n\nBecause we are comparing the in-kind benefit policy to doing nothing (i.e., a policy with zero-valued welfare costs and benefits), the inner (square bracketed) term of the first term in Equation 3 can be estimated by taking the maximum of 0 and the predicted values from the metamodels:\n\nevppi_w_inner &lt;-pmax(0,gam.w$fitted)\nevppi_c_inner &lt;-pmax(0,gam.c$fitted)\n\nThe outer expectation of the first term in Equation 3 is estimated using the average across the \\(K\\) probabilistic draws:\n\nevppi_w_1 = mean(evppi_w_inner)\nevppi_c_1 = mean(evppi_c_inner)\n\nAnd finally, the EVPPI for welfare costs and benefits is estimated by the difference:\n\nevppi_w = evppi_w_1 - evppi_2\nevppi_c = evppi_c_1 - evppi_2\n\nc(\"EVPPI_W\" = evppi_w, \n  \"EVPPI_C\" = evppi_c)\n\n    EVPPI_W     EVPPI_C \n0.038941735 0.001417349 \n\n\nFrom these estimates of the EVPPI we would conclude that the component of \\(\\mathbf{\\pi}\\) with the highest information value is \\(W(\\boldsymbol{\\pi},\\alpha)\\)."
  },
  {
    "objectID": "blog/posts/mvpf-evppi/mvpf-evppi.html#next-steps",
    "href": "blog/posts/mvpf-evppi/mvpf-evppi.html#next-steps",
    "title": "Welfare Analysis Meets Research Prioritization",
    "section": "Next Steps",
    "text": "Next Steps\nA this point we have:\n\nExplored the range of current knowledge to ascertain whether future research could help a policymaker’s decision to pursue an in-kind benfefit transfer program.\nDecomposed the value of information to identify the parameters with highest decision leverage.\n\nAs mentioned above, however, our estimates of the value of information are based on a theoretical exercise under which we obtain perfect information on uncertain parameters. In practice, however, we do not have unlimited resources to reduce information uncertainty to zero; we must weigh the costs and benefits of sampling the population—perhaps by carrying out a randomized evaluation of the in-kind benefit transfer—to obtain better, but not perfect, information.\nThe next post in this series will explore different study designs so that we can optimally design a randomized evaluation in such a way as to efficiently gain information to inform the decision."
  },
  {
    "objectID": "blog/drafts/dalys/modeling-dalys.html",
    "href": "blog/drafts/dalys/modeling-dalys.html",
    "title": "Disability-Adjusted Life Years for Policy and Decision Analysis",
    "section": "",
    "text": "Introduction\nSources: Caswell and Zarulli (2018) and Caswell and Daalen (2021)\n\n\nProgressive Disease Model\n\n\n\nSetup\n\nlibrary(tidyverse)\nlibrary(MASS)\nlibrary(expm)\nlibrary(knitr)\nlibrary(kableExtra)\noptions(scipen = 5) \nselect &lt;- dplyr::select\noptions(knitr.kable.NA = '')\n\n\n\nParameterize\n\n\nApproach 1: Markov Trace\n\n\n\n\n\n\nHealthy\nSick\nSicker\nDeadBG\nDeadDisease\n\n\n\n\n1.000\n0.000\n0.000\n0.000\n0.000\n\n\n0.861\n0.041\n0.002\n0.095\n0.001\n\n\n0.741\n0.066\n0.008\n0.181\n0.004\n\n\n0.638\n0.080\n0.015\n0.258\n0.009\n\n\n0.549\n0.087\n0.022\n0.328\n0.015\n\n\n0.472\n0.089\n0.028\n0.390\n0.021\n\n\n0.407\n0.087\n0.033\n0.446\n0.028\n\n\n0.350\n0.083\n0.037\n0.496\n0.035\n\n\n0.301\n0.077\n0.040\n0.540\n0.042\n\n\n0.259\n0.071\n0.041\n0.579\n0.049\n\n\n\n\n\n\n\n\n\n\n\n\nApproach\nScenario\nLife Expectancy\nYLDs\nYLLs\nDALYs\n\n\n\n\nMarkov Trace\nnatural_history\n8.733\n0.150\n2.616\n2.766\n\n\nMarkov Trace\nprevention\n8.915\n0.127\n2.213\n2.340\n\n\nMarkov Trace\ntreatment\n9.017\n0.154\n1.980\n2.134\n\n\n\n\n\n\n\n\n\nApproach 2: Transition States\n\n\n\n\n\n\nApproach\nLife Expectancy\nYLDs\nYLLs\nDALYs\n\n\n\n\nnatural_history\n\n\nMarkov Trace\n8.733\n0.150\n2.616\n2.766\n\n\nTransition States\n8.733\n0.150\n2.616\n2.766\n\n\nprevention\n\n\nMarkov Trace\n8.915\n0.127\n2.213\n2.340\n\n\nTransition States\n8.915\n0.127\n2.213\n2.340\n\n\ntreatment\n\n\nMarkov Trace\n9.017\n0.154\n1.980\n2.134\n\n\nTransition States\n9.017\n0.154\n1.980\n2.134\n\n\n\n\n\n\n\n\n\nApproach 3: Markov Chains With Rewards\n\nNote that this strategy essentially uses a half-cycle correction (more accurately, it assumes events happen half-way through the cycle)\nIt also cannot incorporate discounting at the moment.\nNotation/Objects to Define\n\n\\(\\mathbf{D}\\)\n\\(\\mathbf{V}\\)\n\\(\\mathbf{R}\\)\n\\(\\mathbf{Q}\\) and \\(\\mathbf{\\tilde Q}\\)\n\\(\\mathbf{P}\\)\n\\(\\mathbf{U}\\)\n\\(\\mathbf{M}\\)\n\n\n\\[\n\\mathbf{P}=\\left(\\begin{array}{c|c}\n\\mathbf{U} & \\mathbf{0} \\\\\n\\hline \\mathbf{M} & \\mathbf{I}\n\\end{array}\\right)\n\\]\n\\[\n\\mathbf{Q}=\\left(\\begin{array}{c|c}\n\\mathbf{V} & \\mathbf{0} \\\\\n\\hline \\mathbf{S} & \\mathbf{0}\n\\end{array}\\right)\n\\]\n\\[\n\\mathbf{P}=e^{\\mathbf{Q} \\Delta t}\n\\]\n\\[\n\\mathbf{D}_j=\\left(\\begin{array}{ccc}\n0 & 0 & 0 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & {[1]}\n\\end{array}\\right) \\quad j=1, \\ldots, \\tau\n\\]\n\\[\n\\mathbb{U}=\\left(\\begin{array}{c|c|c}\n\\mathbf{U}_1 & \\cdots & \\mathbf{0} \\\\\n\\hline & \\ddots & \\\\\n\\hline \\mathbf{0} & \\cdots & \\mathbf{U}_\\omega\n\\end{array}\\right)\n\\]\n\\[\n\\mathbb{D}=\\left(\\begin{array}{c|c|c}\n\\mathbf{D}_1 & \\cdots & \\mathbf{0} \\\\\n\\hline & \\ddots & \\\\\n\\hline \\mathbf{0} & \\cdots & \\mathbf{D}_\\tau\n\\end{array}\\right)\n\\]\n\\[\n\\tilde{\\mathbf{U}}=\\mathbf{K}^{\\top} \\mathbb{D} \\mathbf{K} \\mathbb{U} \\quad \\tau \\omega \\times \\tau \\omega\n\\]\n\\[\n\\tilde{\\mathbf{M}}=\\left(\\begin{array}{lll}\n\\mathbf{M}_1 & \\cdots & \\mathbf{M}_\\omega\n\\end{array}\\right) \\quad \\alpha \\times \\tau \\omega\n\\]\n\\[\n\\tilde{\\mathbf{P}}=\\left(\\begin{array}{c|c}\n\\tilde{\\mathbf{U}} & \\mathbf{0}_{\\tau \\omega \\times \\alpha} \\\\\n\\hline \\tilde{\\mathbf{M}} & \\mathbf{I}_{\\alpha \\times \\alpha}\n\\end{array}\\right) \\quad(\\tau \\omega+\\alpha) \\times(\\tau \\omega+\\alpha)\n\\]\n\n\n\n\n\nApproach\nLife Expectancy\nYLDs\nYLLs\nDALYs\n\n\n\n\nnatural_history\n\n\nMarkov Trace\n8.733\n0.150\n2.616\n2.766\n\n\nTransition States\n8.733\n0.150\n2.616\n2.766\n\n\nHealthy Longevity\n8.733\n0.138\n2.696\n2.834\n\n\nprevention\n\n\nMarkov Trace\n8.915\n0.127\n2.213\n2.340\n\n\nTransition States\n8.915\n0.127\n2.213\n2.340\n\n\nHealthy Longevity\n8.915\n0.117\n2.281\n2.398\n\n\ntreatment\n\n\nMarkov Trace\n9.017\n0.154\n1.980\n2.134\n\n\nTransition States\n9.017\n0.154\n1.980\n2.134\n\n\nHealthy Longevity\n9.005\n0.143\n2.553\n2.696\n\n\n\n\n\n\n\n\n\n\n\n\nApproach\nDALY (ref.)\nincDALY Prevention\nincDALY Treatment\n\n\n\n\nHealthy Longevity\n2.834\n-0.436\n-0.138\n\n\nMarkov Trace\n2.766\n-0.426\n-0.632\n\n\nTransition States\n2.766\n-0.426\n-0.632\n\n\n\n\n\n\n\n\n\nApproach 4: QALY-Like DALY\n\n\n\n\n\nApproach\nLife Expectancy\nYLDs\nYLLs\nDALYs\nQALY-like DALY\n\n\n\n\nnatural_history\n\n\nMarkov Trace\n8.733\n0.150\n2.616\n2.766\n\n\n\nTransition States\n8.733\n0.150\n2.616\n2.766\n\n\n\nHealthy Longevity\n8.733\n0.138\n2.696\n2.834\n\n\n\nQALY-like DALY\n\n\n\n\n1.299\n\n\nprevention\n\n\nMarkov Trace\n8.915\n0.127\n2.213\n2.340\n\n\n\nTransition States\n8.915\n0.127\n2.213\n2.340\n\n\n\nHealthy Longevity\n8.915\n0.117\n2.281\n2.398\n\n\n\nQALY-like DALY\n\n\n\n\n1.100\n\n\ntreatment\n\n\nMarkov Trace\n9.017\n0.154\n1.980\n2.134\n\n\n\nTransition States\n9.017\n0.154\n1.980\n2.134\n\n\n\nHealthy Longevity\n9.005\n0.143\n2.553\n2.696\n\n\n\nQALY-like DALY\n\n\n\n\n1.459\n\n\n\n\n\n\n\n\n\n\n\n\nApproach\nDALY (ref.)\nincDALY Prevention\nincDALY Treatment\n\n\n\n\nHealthy Longevity\n2.834\n-0.436\n-0.138\n\n\nMarkov Trace\n2.766\n-0.426\n-0.632\n\n\nQALY-like DALY\n1.299\n-0.198\n0.160\n\n\nTransition States\n2.766\n-0.426\n-0.632\n\n\n\n\n\n\n\n\n\nDebugging\n\nThe fundamental matrix gives you expected occupancy without any cycle correction. So it’s not great for plugging in endogenous life table values; you’d really want to just solve for life expectancy using rewards and use those values.\n\nSee 1. vs. 2 for this (with no discounting, no sickness transitions, and a reasonably high background death transition)\n\nOnce you add the reward matrices (3 vs. 4) you essentially get the same answer whether or not you use the cycle correction. This is because the cycle correction is just a way of accounting for the fact that transitions don’t happen at the beginning or end of each cycle. But the reward matrix approach is already accounting for that. So you don’t need to do both.\nWe can also use basic math and an exponential death rate to get the same answer as above (see 3. vs. 4 vs. 5)\n6 and 7 use partial rewards and are similar to the above. Markov trace with half-cycle correction, and reward matrix, both yield nearly identical answers.\n8 vs. 9 shows that transition rewards (for YLLs) are also hte same using a markov trace diff(deaths) approach and the matrix with rewards approach.\n\n\n\n\n\n\nReferences\n\nCaswell, Hal, and Silke van Daalen. 2021. “Healthy Longevity from Incidence-Based Models: More Kinds of Health Than Stars in the Sky.” Demographic Research 45 (July): 397–452. https://doi.org/10.4054/demres.2021.45.13.\n\n\nCaswell, Hal, and Virginia Zarulli. 2018. “Matrix Methods in Health Demography: A New Approach to the Stochastic Analysis of Healthy Longevity and DALYs.” Population Health Metrics 16 (1). https://doi.org/10.1186/s12963-018-0165-5."
  },
  {
    "objectID": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html",
    "href": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html",
    "title": "Bounds Under Exogenous Treatment Assignment",
    "section": "",
    "text": "Code\nparams &lt;- \n  list(\n    N = 2e3,\n    sigma_sq_X = 1.0,\n    sigma_sq_epsilon = 0.3,\n    delta = 0.5\n  )\nparams &lt;- with(params,\n               modifyList(params,list(\n                 r_squared = 1 - sigma_sq_epsilon,\n                 beta = sqrt(1 - sigma_sq_epsilon),\n                 Sigma = matrix(c(sigma_sq_X,0,0,sigma_sq_epsilon),\n                                byrow=TRUE, nrow = 2, ncol = 2))))\n\ngen_data &lt;- function(params) {\n  with(params, \n       mvrnorm(n = N, mu = c(0,0), Sigma = Sigma)) %&gt;% \n    data.frame() %&gt;% \n    as_tibble() %&gt;% \n    set_names(c(\"X\",\"epsilon\")) %&gt;% \n    mutate(Y_i0 = params$beta * X + epsilon) %&gt;% \n    mutate(Y_i1 = Y_i0 + params$delta) %&gt;% \n    mutate(random = runif(nrow(.))) %&gt;% \n    mutate(D = as.integer(row_number()&lt;=(params$N)/2)) %&gt;% \n    arrange(random) %&gt;% \n    select(-random) %&gt;% \n    mutate(Y = D * Y_i1 + (1 - D) * Y_i0) %&gt;% \n    select(Y,D,X)\n}\n\nset.seed(123)\ndf &lt;- params %&gt;% gen_data()\n\ndf %&gt;% head(n=10) %&gt;% kable() %&gt;% \n    kable_styling()\n\n\n\n\nTable 1: First 10 rows of data\n\n\n\n\n\n\nY\nD\nX\n\n\n\n\n0.636525\n0\n1.136893\n\n\n-1.017545\n0\n-1.143835\n\n\n-2.660006\n0\n-1.769366\n\n\n-0.234232\n0\n-1.314321\n\n\n-1.052531\n1\n-1.236676\n\n\n-0.082499\n0\n-1.321069\n\n\n1.284970\n1\n1.516068\n\n\n0.271550\n1\n0.246692\n\n\n-0.690019\n0\n-1.433008\n\n\n-0.084229\n0\n-0.229395"
  },
  {
    "objectID": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#lower-bounds",
    "href": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#lower-bounds",
    "title": "Bounds Under Exogenous Treatment Assignment",
    "section": "Lower Bounds",
    "text": "Lower Bounds"
  },
  {
    "objectID": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#upper-bounds",
    "href": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#upper-bounds",
    "title": "Bounds Under Exogenous Treatment Assignment",
    "section": "Upper Bounds",
    "text": "Upper Bounds\n\nCalculate the lower bound values\nThis code turns the lower bound quantile values into an empirical CDF object.\nCalculate the upper bound values\nThis code turns the lower bound quantile values into an empirical CDF object.\n\nNow let’s look at the bounds for the quantile of the Treated Effect on the Treated (QoTT), i.e., the bounds on various quantiles of the treatment effect distribution.\n\n\nCode\nqwdu &lt;- quantile(F.wd.l, tau, type=1)\nqwdl &lt;- quantile(F.wd.u, tau, type=1)\n\ndf_wd &lt;- \n  data.frame(tau = c(tau,tau), bound = c(qwdu,qwdl), type=c(rep(\"upper\",length(qwdu)),rep(\"lower\",length(qwdl)))) %&gt;% \n  mutate(method =\"Worst-Case\\n[Williamson-Downs (1990)]\") %&gt;% \n  mutate(label = ifelse(type==\"upper\",\"Worst-Case\\n[Williamson-Downs (1990)]\",\"\")) \n\ncol_scheme &lt;- c(\"#FF5733\" ) # Williamson and Downs\n\ndf_wd %&gt;% \n  mutate(type = paste0(type,method)) %&gt;% \n  ggplot(aes(x = tau, y = bound, group = type, colour = method)) + \n  geom_line(lwd=1.25) + \n  geom_hline(aes(yintercept = params$delta), colour = \"darkred\",lwd=1.25) + \n  scale_color_manual(values = col_scheme) + \n  geom_dl(method = list(\"last.points\",hjust=1),aes(label = label)) +\n  scale_x_continuous(breaks = seq(0,1,0.1)) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\",x = 0.5, y = params$delta, label = \"True Treatment Effect\",vjust=-1,colour = \"darkred\") + \n  scale_y_continuous(limits = c(-5,5),breaks = seq(-5,5,1))\n\n\n\n\n\n\n\n\nFigure 1: Worst-Case (Williamson and Downs [1990]) Bounds"
  },
  {
    "objectID": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#incorporating-covariates",
    "href": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#incorporating-covariates",
    "title": "Bounds Under Exogenous Treatment Assignment",
    "section": "Incorporating Covariates",
    "text": "Incorporating Covariates\n\\(F_{\\Delta \\mid Y(0), X}^L(t \\mid Y(0), X):= \\begin{cases}0, & Y(0)+t&lt;\\tilde{Y}(1 \\mid X), \\\\ \\frac{F_{1 \\mid X}(Y(0)+t \\mid X)-F_{0 \\mid X}(Y(0) \\mid X)}{1-F_{0 \\mid X}(Y(0) \\mid X)}, & Y(0)+t \\geq \\tilde{Y}(1 \\mid X),\\end{cases}\\)\n\\(F_{\\Delta \\mid Y(0), X}^U(t \\mid Y(0), X):= \\begin{cases}\\frac{F_{1 \\mid X}(Y(0)+t \\mid X)}{F_{0 \\mid X}(Y(0) \\mid X)}, & Y(0)+t \\leq \\tilde{Y}(1 \\mid X) \\\\ 1, & Y(0)+t \\geq \\tilde{Y}(1 \\mid X)\\end{cases}\\)\n\\(\\begin{aligned} & F_{\\Delta \\mid Y(d)}^L(t \\mid Y(d))=E\\left[F_{\\Delta \\mid Y(d), X}^L(t \\mid Y(d), X) \\mid Y(d)\\right] \\\\ & F_{\\Delta \\mid Y(d)}^U(t \\mid Y(d))=E\\left[F_{\\Delta \\mid Y(d), X}^U(t \\mid Y(d), X) \\mid Y(d)\\right]\\end{aligned}\\)\n\\(\\begin{aligned} & \\Delta^L(Y(d))=\\int t d F_{\\Delta \\mid Y(d)}^U(t \\mid Y(d)) \\\\ & \\Delta^U(Y(d))=\\int t d F_{\\Delta \\mid Y(d)}^L(t \\mid Y(d))\\end{aligned}\\)\n\\(\\begin{aligned} & \\hat{F}_{\\Delta \\mid 0, X}^L\\left(t \\mid Y_j(0), X_j\\right):=\\max \\left\\{0, \\frac{\\hat{F}_{1 \\mid X}\\left(Y_j(0)+t \\mid X_j\\right)-\\hat{F}_{0 \\mid X}\\left(Y_j(0) \\mid X_j\\right)}{1-\\hat{F}_{0 \\mid X}\\left(Y_j(0) \\mid X_j\\right)}\\right\\} \\\\ & \\hat{F}_{\\Delta \\mid 0, X}^U\\left(t \\mid Y_j(0), X_j\\right):=\\min \\left\\{1, \\frac{\\hat{F}_{1 \\mid X}\\left(Y_j(0)+t \\mid X_j\\right)}{\\hat{F}_{0 \\mid X}\\left(Y_j(0) \\mid X_j\\right)}\\right\\} .\\end{aligned}\\)\n\ni1 &lt;-  # index of treated observations\n  df %&gt;% \n  mutate(i = row_number()) %&gt;% \n  filter(D==1) %&gt;% \n  pull(i)\n\ni0 &lt;-  # index of untreated observations\n  df %&gt;% \n  mutate(i = row_number()) %&gt;% \n  filter(D==0) %&gt;% \n  pull(i)\n\nX1 &lt;- # X values of treated observations\n  df %&gt;%\n  filter(D==1) %&gt;%\n  pull(X)\n\nX0 &lt;- # X values of untreated observations\n  df %&gt;% \n  filter(D==0) %&gt;% \n  pull(X)\n\nWe next create conditional CDFs, with a different CDF constructed for each untreated group \\(X\\) value.\nThe short way uses parametric quantile regression (rq()). This specification assumes a model that is linear in parameters.\n\ntaus0 &lt;- sort(ecdf(y0)(y0))\nquantreg_fit &lt;- quantreg::rq(Y ~ X, tau = taus0, data = df %&gt;% filter(D==0))\npvals &lt;- predict(quantreg_fit,newdata = data.frame(X=X0), stepfun=TRUE)\nhatF0X &lt;- pvals %&gt;% map(~(.x(taus0))) %&gt;% \n  map(~(BMisc::makeDist(.x,taus0)))\n\n\ntaus1 &lt;- sort(ecdf(y1)(y1))\nquantreg_fit &lt;- quantreg::rq(Y ~ X, tau = taus0, data = df %&gt;% filter(D==1))\npvals &lt;- predict(quantreg_fit,newdata = data.frame(X=X0), stepfun=TRUE)\nhatF1X &lt;- pvals %&gt;% map(~(.x(taus0))) %&gt;% \n  map(~(BMisc::makeDist(.x,taus0)))\n\nA (much) longer, but nonparametric approach, is to fit a nonparametric regression. In this example code, we fit a generalized additive model (GAM) with a logit link (for the constructed binary outcome needed to estimate the CDF).Note that the treatment effect bounds calcualted under a GAM vs. a parametric quantile regression approach for the condtiional CDFs are nearly identical in this example—though this will not generally be true!\n\n\nCode\n# This version constructs a full CDF for each X value\npb &lt;- progress_bar$new(total = length(y0))\nhatF0X &lt;-\n  map(X0, ~({\n    # for each untreated observation j\n    xx = .x\n    pb$tick()\n    hatF0X_ &lt;-\n      y_ %&gt;% map_dbl( ~({\n        yy = .x\n        # nonparameterically regress an indicator Y_i &lt;= Y_j on X_i in the untreated subsample\n        IY = as.integer(df$Y[i0] &lt;= yy)\n        X &lt;- X0\n        dat &lt;- cbind.data.frame(IY, X) %&gt;%\n          set_names(c(\"IY\", \"X\"))\n        \n        fit &lt;- gam(IY ~ s(X), data = dat, family = \"binomial\")\n        # construct predicted value\n        predict(fit, newdata = data.frame(X = xx), type = \"response\")\n        \n      })) %&gt;%\n      BMisc::makeDist(y_, .) # make this into an ecdf \n    \n    hatF0X_\n  }))\nwrite_rds(hatF0X,\"posts/extending-the-toolkit-experimental/results/hatF0X.rds\")\n\npb &lt;- progress_bar$new(total = length(X0))\nhatF1X &lt;-\n  map(X0, ~ ({\n    # for each untreated observation j\n    xx = .x\n    pb$tick()\n    hatF1X_ &lt;-\n      y_ %&gt;% map_dbl( ~ ({\n        yy = .x\n        # nonparameterically regress an indicator Y_i &lt;= Y_j on X_i in the treated subsample\n        IY = as.integer(df$Y[i1] &lt;= yy)\n        X &lt;- X1\n        dat &lt;- cbind.data.frame(IY, X) %&gt;%\n          set_names(c(\"IY\", \"X\"))\n        \n        fit &lt;- gam(IY ~ s(X), data = dat, family = \"binomial\")\n        # construct predicted value\n        predict(fit, newdata = data.frame(X = xx), type = \"response\")\n        \n      })) %&gt;%\n      BMisc::makeDist(y_, .) # make this into an ecdf\n    hatF1X_\n  }))\nwrite_rds(hatF1X,\"posts/extending-the-toolkit-experimental/results/hatF1X.rds\")\n\n\nWe next plug these condtiional CDFs into the formulas to obtain the CDF of the treatment effect bounds.\n\n\nCode\npb &lt;- progress_bar$new(total = length(delta_))\nF_l_flX_ &lt;- \n  delta_ %&gt;% map(~{ # outer loop is over possible values of the treatment effect\n    delt &lt;- .x\n    pb$tick()\n      map2_dbl(y0,X0,~({\n        y0_ = .x \n        xx_ = .y\n        i = which(X0==xx_); i\n        F1_fl_tmp &lt;- hatF1X[[i]]\n        F0_fl_tmp &lt;- hatF0X[[i]]\n        (F1_fl_tmp(y0_ + delt)-F0_fl_tmp(y0_))/(1-F0_fl_tmp(y0_))\n      }))  %&gt;% \n      map_dbl(~(max(0,.x,na.rm=TRUE))) %&gt;% \n      mean(.)\n  }) %&gt;% \n  unlist()\n# Make it into a proper eCDF object.\nF.flX.l &lt;- approxfun(delta_,  F_l_flX_, method = \"constant\", yleft = 0, yright = 1, \n                    f = 0, ties = \"ordered\")\nclass(F.flX.l) &lt;- c(\"ecdf\", \"stepfun\", class(F.flX.l))\nassign(\"nobs\", length(delta_), envir = environment(F.flX.l))\n\npb &lt;- progress_bar$new(total = length(delta_))\nF_u_flX_ &lt;- \n  delta_ %&gt;% \n  map(~{ # outer loop is over possible values of the treatment effect\n    delt &lt;- .x\n    pb$tick()\n    \n      map2_dbl(y0,X0,~({\n        y0_ = .x \n        xx_ = .y\n        i = which(X0==xx_); i\n        F1_fl_tmp &lt;- hatF1X[[i]]\n        F0_fl_tmp &lt;- hatF0X[[i]]\n        \n        (F1_fl_tmp(y0_+delt))/(F0_fl_tmp(y0_))\n      }))  %&gt;% \n      map_dbl(~(min(1,.x,na.rm=TRUE))) %&gt;% \n      mean(.)\n  }) %&gt;% \n  unlist()\n# Make it into a proper eCDF object. \nF.flX.u &lt;- approxfun(delta_,  F_u_flX_, method = \"constant\", yleft = 0, yright = 1, \n                    f = 0, ties = \"ordered\")\nclass(F.flX.u) &lt;- c(\"ecdf\", \"stepfun\", class(F.flX.u))\nassign(\"nobs\", length(delta_), envir = environment(F.flX.u))\n\n\nFirst, let’s take a look at bounds on various quantiles of the treatment effect (QoTT):\n\n\nCode\nqflXu &lt;- quantile(F.flX.l, tau, type=1)\nqflXl &lt;- quantile(F.flX.u, tau, type=1)\n\ndf_flX &lt;- \n  data.frame(tau = c(tau,tau), bound = c(qflXu,qflXl), type=c(rep(\"upper\",length(qflXu)),rep(\"lower\",length(qflXl)))) %&gt;% \n  mutate(method = \"Frandsen & Lefgrens (2021) Covariates\") %&gt;% \n  mutate(label = ifelse(type==\"upper\",\"Frandsen & Lefgrens (2021)\\nWith Covariates\",\"\")) \n\n\n\n\nCode\ncol_scheme &lt;- c(\"#0A2E36\" ,# Frandsen & Lefgrens (No X)\n                \"#7DC4CC\", # Frandsen & Lefgrens (X)\n                \"#FF5733\" ) # Williamson and Downs\n\ndf_fl %&gt;% \n  bind_rows(df_flX) %&gt;% \n  bind_rows(df_wd) %&gt;%  \n  mutate(method = factor(method, levels = c(\"Frandsen & Lefgrens (2021)\"     ,       \"Frandsen & Lefgrens (2021) Covariates\", \"Worst-Case\\n[Williamson-Downs (1990)]\"))) %&gt;% \n  mutate(type = paste0(type,method)) %&gt;% \n  ggplot(aes(x = tau, y = bound, group = type, colour = method)) + \n  geom_line(lwd=1.25) + \n  geom_hline(aes(yintercept = params$delta), colour = \"darkred\",lwd=1.25) + \n  scale_color_manual(values=col_scheme) + \n  geom_dl(method = list(\"last.points\",hjust=1),aes(label = label)) +\n  scale_x_continuous(breaks = seq(0,1,0.1)) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\",x = 0.5, y = params$delta, label = \"True Treatment Effect\",vjust=-1,colour = \"darkred\") + \n  scale_y_continuous(limits = c(-5,5),breaks = seq(-5,5,1))\n\n\n\n\n\n\n\n\nFigure 3: Treatment Effect Distribution Bounds with Covariates"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html",
    "href": "blog/drafts/cdfs/estimating-cdfs.html",
    "title": "Estimating Distribution Functions",
    "section": "",
    "text": "This posting runs through various approaches for estimating distribution functions, and functions of distribution functions such as expected values.\nLet’s start with some definitions. First, define random variable \\(X\\). The cumulative distribution function (CDF) of \\(X\\) is the probability that \\(X\\) takes on some value less than \\(x\\):\n\\[\n\\begin{eqnarray}\nF_X(s) = P(X \\leq x)\n\\end{eqnarray}\n\\tag{1}\\]\nThe probability density function (PDF) tells us about the relative likelihood that \\(X\\) takes on any given value, and can be defined as the derivative of the CDF:\n\\[\nf_X(x) = \\frac{dF_X(x)}{dx}\n\\tag{2}\\]\nWorking in the opposite direction, we can also define the CDF by integrating the PDF:\n\\[\nF_X(x)=\\int_{-\\infty}^x f_X(t) d t\n\\tag{3}\\]\nThis relationship is helpful because it allows us to define the expected value of \\(X\\) as a weighted sum of values \\(x\\), with weights defined by the PDF. In integral notation:\n\\[\n\\mathrm{E_X}[X]=\\int_{-\\infty}^{\\infty} x f_X(x) dx\n\\tag{4}\\]\n\n\nOur example data will be taken from the Oregon Health Insurance Experiment (OHIE). We’ll focus on the experimental or “reduced form” aspect of the OHIE by comparing individuals randomized to Medicaid eligibility to those randomized to control. Our primary outcome of interest will be hemoglobin A1C levels.\n\nlibrary(tidyverse)\nlibrary(qte)\nlibrary(here)\nlibrary(glue)\nlibrary(conflicted)\nlibrary(hrbrthemes)\nlibrary(broom)\nlibrary(edfun)\nlibrary(scam)\nlibrary(quantregForest)\nconflict_prefer(\"filter\",\"dplyr\")\nselect &lt;- dplyr::select\noptions(\"scipen\" = 100, \"digits\" = 5)\nggplot2::theme_set(hrbrthemes::theme_ipsum(grid = \"X\"))\n\ndf &lt;- haven::read_dta(here(\"_ignore/CS9-Oregon-Insurance-Experiment-RCT-IV-Data.dta\")) %&gt;% \n mutate(D =  treatment) %&gt;% \n mutate(Y = a1c_inp) %&gt;% \n select(Y,D,nnnnumhh_li_2 ,nnnnumhh_li_3 ,age_inp, bp_sar_inp, female, starts_with(\"age_decile_dum\"),weight_total_inp) %&gt;% \n na.omit()"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#description-of-data",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#description-of-data",
    "title": "Estimating Distribution Functions",
    "section": "",
    "text": "Our example data will be taken from the Oregon Health Insurance Experiment (OHIE). We’ll focus on the experimental or “reduced form” aspect of the OHIE by comparing individuals randomized to Medicaid eligibility to those randomized to control. Our primary outcome of interest will be hemoglobin A1C levels.\n\nlibrary(tidyverse)\nlibrary(qte)\nlibrary(here)\nlibrary(glue)\nlibrary(conflicted)\nlibrary(hrbrthemes)\nlibrary(broom)\nlibrary(edfun)\nlibrary(scam)\nlibrary(quantregForest)\nconflict_prefer(\"filter\",\"dplyr\")\nselect &lt;- dplyr::select\noptions(\"scipen\" = 100, \"digits\" = 5)\nggplot2::theme_set(hrbrthemes::theme_ipsum(grid = \"X\"))\n\ndf &lt;- haven::read_dta(here(\"_ignore/CS9-Oregon-Insurance-Experiment-RCT-IV-Data.dta\")) %&gt;% \n mutate(D =  treatment) %&gt;% \n mutate(Y = a1c_inp) %&gt;% \n select(Y,D,nnnnumhh_li_2 ,nnnnumhh_li_3 ,age_inp, bp_sar_inp, female, starts_with(\"age_decile_dum\"),weight_total_inp) %&gt;% \n na.omit()"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand-using-regression",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand-using-regression",
    "title": "Estimating Distribution Functions",
    "section": "Do It “By Hand” Using Regression",
    "text": "Do It “By Hand” Using Regression\nIn the example below, we’ll construct a CDF “by hand” by defining our various values of \\(t\\) (which we’ll call y_), and then looping over them. Within each loop, we first define a binary outcome, with values of one if the value of \\(Y\\) is less than or equal to the given y_ value under consideration, and zero otherwise. We next regress this binary outcome on an intercept only; the resulting coefficient on the intercept term provides an estimate of the fraction of the sample with a \\(Y\\) value less than or equal to the y_ value.\nWe repeat this for all y_ values and plot the result as a yellow line on top of the previous plot:\n\n\n\n\n\nEmpirical CDF\n\n\n\n\nAs the figure shows, we have successfully replicated the empirical CDF plot produced by ecdf()."
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand-using-logistic-regression",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand-using-logistic-regression",
    "title": "Estimating Distribution Functions",
    "section": "Do It “By Hand” Using Logistic Regression",
    "text": "Do It “By Hand” Using Logistic Regression\nWe’ll next repeat the above exercise, but only change the regression type. That is, rather than fit a linear probability model using lm(), we’ll fit a logistic regression model. We then need to predict the outcome response to obtain an estimate of the fraction of the sample with value less than or equal to the given y_ value (this is analogous to obtaining the coefficient on the intercept term in the linear probability model approach above).\nOur new eCDF values are plotted in red below. As the plot shows, we obtain essentially the same eCDF curve:\n\n\n\n\n\nEmpirical CDF"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#create-a-smoothed-version-using-a-shape-constrained-generalized-additive-model",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#create-a-smoothed-version-using-a-shape-constrained-generalized-additive-model",
    "title": "Estimating Distribution Functions",
    "section": "Create A “Smoothed” Version Using a Shape-Constrained Generalized Additive Model",
    "text": "Create A “Smoothed” Version Using a Shape-Constrained Generalized Additive Model\nRecall from above that to calculate the PDF of \\(X\\) we can differentiate the CDF (Equation 2). However, the eCDFs calculated above are “chunky”—they are essentially step functions that move at discrete values defined over the support of the outcome.\nDepending on the application we may want to fit a smoothed function to these step function values. While R provides functionality to fit a smoothed curve to a given set of points (approxfun()), the resulting approximation function will likely not play by the rules of a CDF (e.g., minimum value 0, maximum value 1, monotonically increasing throughout, etc.).\nTo fit this approximation function we can fit a shape constrained additive model that imposes these constraints. In the plot below, this new smoothed eCDF curve is plotted in green over the step function plotted above.\n\n\nThis approach is based on the paper here and the code here.\n\n\n\n\n\nEmpirical CDF based on Shape Constrained Additive Model"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand",
    "title": "Estimating Distribution Functions",
    "section": "Do it “By Hand”",
    "text": "Do it “By Hand”\nWe can also leverage Equation 2 and the shape-constrained GAM model fit to construct an estimate of the CDF above to construct the PDF by hand. In the code below, f0() is the constructed CDF function, and we can simply add the option ,1 to obtain the first derivative (i.e., f0(y0) provides CDF values and f0(y0,1) provides PDF values)."
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-logistic-regression",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-logistic-regression",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Logistic Regression",
    "text": "Conditional CDFs Using Logistic Regression\n\n\n\n\n\nConditional CDFs Using Logistic Regression"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-quantile-regression",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-quantile-regression",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Quantile Regression",
    "text": "Conditional CDFs Using Quantile Regression\nAn alternative method is to use quantile regression\n\n\n\n\n\nCDFs Constructed Using Quantile Regression"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-quantile-regression-forests",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-quantile-regression-forests",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Quantile Regression Forests",
    "text": "Conditional CDFs Using Quantile Regression Forests\n\n\n\n\n\nCDFs Constructed Using Quantile Regression Forest"
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html",
    "href": "blog/drafts/distribution-functions/distribution-functions.html",
    "title": "Estimating Distribution Functions",
    "section": "",
    "text": "This posting runs through various approaches for estimating distribution functions, and functions of distribution functions such as expected values.\nLet’s start with some definitions. First, define random variable \\(X\\). The cumulative distribution function (CDF) of \\(X\\) is the probability that \\(X\\) takes on some value less than \\(x\\):\n\\[\n\\begin{eqnarray}\nF_X(s) = P(X \\leq x)\n\\end{eqnarray}\n\\tag{1}\\]\nThe probability density function (PDF) tells us about the relative likelihood that \\(X\\) takes on any given value, and can be defined as the derivative of the CDF:\n\\[\nf_X(x) = \\frac{dF_X(x)}{dx}\n\\tag{2}\\]\nWorking in the opposite direction, we can also define the CDF by integrating the PDF:\n\\[\nF_X(x)=\\int_{-\\infty}^x f_X(t) d t\n\\tag{3}\\]\nThis relationship is helpful because it allows us to define the expected value of \\(X\\) as a weighted sum of values \\(x\\), with weights defined by the PDF. In integral notation:\n\\[\n\\mathrm{E_X}[X]=\\int_{-\\infty}^{\\infty} x f_X(x) dx\n\\tag{4}\\]\n\n\nOur example data will be taken from the Oregon Health Insurance Experiment (OHIE). We’ll focus on the experimental or “reduced form” aspect of the OHIE by comparing individuals randomized to Medicaid eligibility to those randomized to control. Our primary outcome of interest will be hemoglobin A1C levels.\n\nlibrary(tidyverse)\nlibrary(qte)\nlibrary(here)\nlibrary(glue)\nlibrary(conflicted)\nlibrary(hrbrthemes)\nlibrary(broom)\nlibrary(edfun)\nlibrary(scam)\nlibrary(quantregForest)\nconflict_prefer(\"filter\",\"dplyr\")\nselect &lt;- dplyr::select\noptions(\"scipen\" = 100, \"digits\" = 5)\nggplot2::theme_set(hrbrthemes::theme_ipsum(grid = \"X\"))\n\ndf &lt;- haven::read_dta(here(\"_ignore/CS9-Oregon-Insurance-Experiment-RCT-IV-Data.dta\")) %&gt;% \n mutate(D =  treatment) %&gt;% \n mutate(Y = a1c_inp) %&gt;% \n select(Y,D,nnnnumhh_li_2 ,nnnnumhh_li_3 ,age_inp, bp_sar_inp, female, starts_with(\"age_decile_dum\"),weight_total_inp) %&gt;% \n na.omit()"
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html#description-of-data",
    "href": "blog/drafts/distribution-functions/distribution-functions.html#description-of-data",
    "title": "Estimating Distribution Functions",
    "section": "",
    "text": "Our example data will be taken from the Oregon Health Insurance Experiment (OHIE). We’ll focus on the experimental or “reduced form” aspect of the OHIE by comparing individuals randomized to Medicaid eligibility to those randomized to control. Our primary outcome of interest will be hemoglobin A1C levels.\n\nlibrary(tidyverse)\nlibrary(qte)\nlibrary(here)\nlibrary(glue)\nlibrary(conflicted)\nlibrary(hrbrthemes)\nlibrary(broom)\nlibrary(edfun)\nlibrary(scam)\nlibrary(quantregForest)\nconflict_prefer(\"filter\",\"dplyr\")\nselect &lt;- dplyr::select\noptions(\"scipen\" = 100, \"digits\" = 5)\nggplot2::theme_set(hrbrthemes::theme_ipsum(grid = \"X\"))\n\ndf &lt;- haven::read_dta(here(\"_ignore/CS9-Oregon-Insurance-Experiment-RCT-IV-Data.dta\")) %&gt;% \n mutate(D =  treatment) %&gt;% \n mutate(Y = a1c_inp) %&gt;% \n select(Y,D,nnnnumhh_li_2 ,nnnnumhh_li_3 ,age_inp, bp_sar_inp, female, starts_with(\"age_decile_dum\"),weight_total_inp) %&gt;% \n na.omit()"
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html#do-it-by-hand-using-regression",
    "href": "blog/drafts/distribution-functions/distribution-functions.html#do-it-by-hand-using-regression",
    "title": "Estimating Distribution Functions",
    "section": "Do It “By Hand” Using Regression",
    "text": "Do It “By Hand” Using Regression\nIn the example below, we’ll construct a CDF “by hand” by defining our various values of \\(t\\) (which we’ll call y_), and then looping over them. Within each loop, we first define a binary outcome, with values of one if the value of \\(Y\\) is less than or equal to the given y_ value under consideration, and zero otherwise. We next regress this binary outcome on an intercept only; the resulting coefficient on the intercept term provides an estimate of the fraction of the sample with a \\(Y\\) value less than or equal to the y_ value.\nWe repeat this for all y_ values and plot the result as a yellow line on top of the previous plot:\n\n\nShow the code\ntaus &lt;- c(1:99)/100\n\ny0 &lt;- # Vector of untreated outcomes\n  df %&gt;% filter(D==0) %&gt;% pull(Y)\n\neCDF_y0 &lt;-\n  y_ %&gt;% # Iterate over the support of y\n  map_dbl(~({\n    IY = as.integer(y0 &lt;= .x)\n    fIY = lm(IY~1)\n    out &lt;- \n        tidy(fIY) %&gt;% pull(estimate)\n    return(out)\n  }))\n\np0 +\n  geom_step(\n    data = tibble(x = y_, y = eCDF_y0, method = \"Constructed\") , \n    aes(x = x, y = y), colour = \"yellow\")\n\n\n\n\n\nEmpirical CDF\n\n\n\n\nAs the figure shows, we have successfully replicated the empirical CDF plot produced by ecdf()."
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html#do-it-by-hand-using-logistic-regression",
    "href": "blog/drafts/distribution-functions/distribution-functions.html#do-it-by-hand-using-logistic-regression",
    "title": "Estimating Distribution Functions",
    "section": "Do It “By Hand” Using Logistic Regression",
    "text": "Do It “By Hand” Using Logistic Regression\nWe’ll next repeat the above exercise, but only change the regression type. That is, rather than fit a linear probability model using lm(), we’ll fit a logistic regression model. We then need to predict the outcome response to obtain an estimate of the fraction of the sample with value less than or equal to the given y_ value (this is analogous to obtaining the coefficient on the intercept term in the linear probability model approach above).\nOur new eCDF values are plotted in red below. As the plot shows, we obtain essentially the same eCDF curve:\n\n\nShow the code\ntaus &lt;- c(1:99)/100\n\ny0 &lt;- # Vector of untreated outcomes\n  df %&gt;% filter(D==0) %&gt;% pull(Y)\n\neCDF_y0_logit &lt;-\n  y_ %&gt;% # Iterate over the support of y\n  map_dbl(~({\n    IY = as.integer(y0 &lt;= .x)\n    fIY = glm(IY~1, family = \"binomial\")\n    out &lt;- predict(fIY , type=\"response\", newdata = data.frame(model.matrix(IY~1)[1,]))\n    return(out)\n  }))\n\np0 +\n  geom_step(\n    data = tibble(x = y_, y = eCDF_y0, method = \"LPM\") , \n    aes(x = x, y = y), colour = \"yellow\") + \n    geom_step(\n    data = tibble(x = y_, y = eCDF_y0, method = \"logit\") , \n    aes(x = x, y = y), colour = \"red\")\n\n\n\n\n\nEmpirical CDF"
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html#create-a-smoothed-version-using-a-shape-constrained-generalized-additive-model",
    "href": "blog/drafts/distribution-functions/distribution-functions.html#create-a-smoothed-version-using-a-shape-constrained-generalized-additive-model",
    "title": "Estimating Distribution Functions",
    "section": "Create A “Smoothed” Version Using a Shape-Constrained Generalized Additive Model",
    "text": "Create A “Smoothed” Version Using a Shape-Constrained Generalized Additive Model\nRecall from above that to calculate the PDF of \\(X\\) we can differentiate the CDF (Equation 2). However, the eCDFs calculated above are “chunky”—they are essentially step functions that move at discrete values defined over the support of the outcome.\nDepending on the application we may want to fit a smoothed function to these step function values. While R provides functionality to fit a smoothed curve to a given set of points (approxfun()), the resulting approximation function will likely not play by the rules of a CDF (e.g., minimum value 0, maximum value 1, monotonically increasing throughout, etc.).\nTo fit this approximation function we can fit a shape constrained additive model that imposes these constraints. In the plot below, this new smoothed eCDF curve is plotted in green over the step function plotted above.\n\n\nThis approach is based on the paper here and the code here.\n\n\nShow the code\ndf_ &lt;- \n  tibble(x = y_, tau = ecdf(y0)(y_))\n\nn.knots = 40\n\nn &lt;- nrow(df_)\n\nfit &lt;- \n  scam::scam(tau ~ s(x, bs = \"mpi\", k = n.knots),\n             data = df_, \n             weights = c(n, rep(1, n - 2), 10 * n))\n\n# Interior Knots\nxk &lt;- with(fit$smooth[[1]], knots[4:(length(knots) - 3)])\n\n# Spline values at interior knots\nyk &lt;- predict(fit, newdata = data.frame(x = xk))\n\n# Reparametrization into a monotone interpolation spline\nxg &lt;- seq(min(df_$x), max(df_$x), length = 100)\nf0 &lt;- stats::splinefun(xk, yk, \"hyman\")\ndf_$cdf_sm = f0(y_)\n\ndf_ %&gt;% \n  ggplot() + geom_step(aes(x = x, y = tau), lwd=2) + \n  geom_line(aes(x = x, y = cdf_sm), col = \"green\", lwd=1.25) +\n  scale_y_continuous(limits = c(0,1))\n\n\n\n\n\nEmpirical CDF based on Shape Constrained Additive Model"
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html#do-it-by-hand",
    "href": "blog/drafts/distribution-functions/distribution-functions.html#do-it-by-hand",
    "title": "Estimating Distribution Functions",
    "section": "Do it “By Hand”",
    "text": "Do it “By Hand”\nWe can also leverage Equation 2 and the shape-constrained GAM model fit to construct an estimate of the CDF above to construct the PDF by hand. In the code below, f0() is the constructed CDF function, and we can simply add the option ,1 to obtain the first derivative (i.e., f0(y0) provides CDF values and f0(y0,1) provides PDF values).\n\n\nShow the code\n# Note: f() is constructed above \ndens_y0 &lt;- approxfun(y0,f0(y0,1))\n\ndf_pdfs %&gt;%\n  ggplot(aes(x = x, y = y, colour = method)) + geom_line(lwd = 1.5,alpha=0.5) +\n  theme(legend.position = \"top\") +\n  ggsci::scale_colour_aaas(name = \"\")  +\n  geom_line(\n    data = tibble(y = y0,\n                  pdf = dens_y0(y0)),\n    aes(x = y, y = pdf) ,\n    colour = \"black\",\n    lwd = 0.5\n  )"
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html#conditional-cdfs-using-logistic-regression",
    "href": "blog/drafts/distribution-functions/distribution-functions.html#conditional-cdfs-using-logistic-regression",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Logistic Regression",
    "text": "Conditional CDFs Using Logistic Regression\n\n\nShow the code\ntaus &lt;- c(1:99)/100\n\ny_ &lt;- # Get 100 evenly spaced points along the support of the outcome (re75) \n  seq(range(df$Y)[1],range(df$Y)[2],length.out=100)\n\ny0 &lt;- # Vector of untreated outcomes\n  df %&gt;% filter(D==0) %&gt;% pull(Y)\n\ncovars &lt;- c(\"age_inp\", \"bp_sar_inp\", \"female\")\n\nfmla &lt;- as.formula(\"IY ~ age_inp + bp_sar_inp + female\")\n\nX_ &lt;- df %&gt;% \n  filter(D==0) %&gt;% \n  select(all_of(covars)) %&gt;% \n  as.matrix()\n\nlogit_fit &lt;- y_ %&gt;% # Iterate over the support of y\n  map( ~ ({\n    IY = as.integer(y0 &lt;= .x)\n    dat = model.frame(fmla, data = cbind.data.frame(IY, X_)) %&gt;% data.frame()\n    fit = glm(fmla, family = \"binomial\", data = dat) %&gt;% coef()\n  }))\n\ndf_ex1 &lt;- data.frame(IY = 1, age_inp = 40, bp_sar_inp = 120, female = 1)\ndf_ex2 &lt;- data.frame(IY = 1, age_inp = 65, bp_sar_inp = 120, female = 1)\n\nF0ex1 &lt;- \n  logit_fit %&gt;% \n  map_dbl(~({\n    boot::inv.logit(model.matrix(fmla,data=df_ex1) %*% .x)\n  }))\n\nF0ex2 &lt;- \n  logit_fit %&gt;%\n  map_dbl( ~ ({\n    boot::inv.logit(model.matrix(fmla, data = df_ex2) %*% .x)\n  }))\n\n\n  tibble(y_ = y_, FX = F0ex1, method = \"Logistic Regression\", sample = \"40 Year Old Female with 120 BP\") %&gt;% \n  bind_rows({\n    tibble(y_ = y_, FX = F0ex2, method = \"Logistic Regression\", sample = \"65 Year Old Female with 120 BP\")\n  }) %&gt;% \n  ggplot(aes(x = y_, y = FX, colour = sample, group  = sample, lty= method)) + geom_step() + \n  ggsci::scale_colour_aaas(name = \"\") +\n  scale_linetype_manual(name = \"\", values = c(1))+\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nConditional CDFs Using Logistic Regression"
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html#conditional-cdfs-using-quantile-regression",
    "href": "blog/drafts/distribution-functions/distribution-functions.html#conditional-cdfs-using-quantile-regression",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Quantile Regression",
    "text": "Conditional CDFs Using Quantile Regression\nAn alternative method is to use quantile regression\n\n\nShow the code\nquantreg_fit0 &lt;-\n  quantreg::rq(Y ~ age_inp + bp_sar_inp + female, tau = taus, data = df %&gt;% filter(D==0))\n\ndf_ex1 &lt;- data.frame(Y = 1, age_inp = 40, bp_sar_inp = 120, female = 1)\ndf_ex2 &lt;- data.frame(Y = 1, age_inp = 65, bp_sar_inp = 120, female = 1)\n\nF0ex1QR &lt;- \n    predict(quantreg_fit0, type = \"Fhat\", newdata = df_ex1, stepfun = TRUE)\nF0ex2QR &lt;- \n    predict(quantreg_fit0, type = \"Fhat\", newdata = df_ex2, stepfun = TRUE)\n\n\ntibble(y_ = y_, FX = F0ex1, method = \"Logistic Regression\", sample = \"40 Year Old Female with 120 BP\") %&gt;% \nbind_rows({\n  tibble(y_ = y_, FX = F0ex2, method = \"Logistic Regression\", sample = \"65 Year Old Female with 120 BP\")\n}) %&gt;% \nbind_rows({\n  tibble(y_ = y_, FX = F0ex1QR(y_), method = \"Quantile Regression\", sample = \"40 Year Old Female with 120 BP\")\n}) %&gt;% \nbind_rows({\n  tibble(y_ = y_, FX = F0ex2QR(y_), method = \"Quantile Regression\", sample = \"65 Year Old Female with 120 BP\")\n}) %&gt;%   \n    mutate(alpha = ifelse(method==\"Quantile Regression\",1,0.8)) %&gt;% \nggplot(aes(x = y_, y = FX, colour = sample,  lty= method)) + geom_step(aes(alpha = alpha)) + \n  ggsci::scale_colour_aaas(name = \"\") +\n  scale_linetype_manual(name = \"\", values = c(1,2)) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nCDFs Constructed Using Quantile Regression"
  },
  {
    "objectID": "blog/drafts/distribution-functions/distribution-functions.html#conditional-cdfs-using-quantile-regression-forests",
    "href": "blog/drafts/distribution-functions/distribution-functions.html#conditional-cdfs-using-quantile-regression-forests",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Quantile Regression Forests",
    "text": "Conditional CDFs Using Quantile Regression Forests\n\n\nShow the code\ndf0 &lt;- df %&gt;% filter(D==0) %&gt;% as.matrix()\n\nindextrain &lt;- sample(1:nrow(df0),round(0.6*nrow(df0)),replace=FALSE)\n\nXtrain &lt;- df0[indextrain,covars]\nXtest &lt;- df0[-indextrain,covars]\n\nYtrain &lt;- df0[ indextrain,\"Y\"]\nYtest &lt;- df0[-indextrain,\"Y\"]\n\nqrf &lt;- quantregForest::quantregForest(x = Xtrain, y = Ytrain, nodesize = 10, sampsize=30)\n\ndf_ex &lt;- df_ex2 &lt;- df0[1:2,c(\"Y\",covars)] %&gt;% as.data.frame()\ndf_ex$age_inp = c(40,65)\ndf_ex$bp_sar_inp = c(120,120)\ndf_ex$female = c(1,1)\n\nconditionalQuantiles &lt;- predict(qrf, df_ex, what = taus)\n\ntibble(y_ = y_, FX = F0ex1, method = \"Logistic Regression\", sample = \"40 Year Old Female with 120 BP\") %&gt;% \nbind_rows({\n  tibble(y_ = y_, FX = F0ex2, method = \"Logistic Regression\", sample = \"65 Year Old Female with 120 BP\")\n}) %&gt;% \nbind_rows({\n  tibble(y_ = y_, FX = F0ex1QR(y_), method = \"Quantile Regression\", sample = \"40 Year Old Female with 120 BP\")\n}) %&gt;% \nbind_rows({\n  tibble(y_ = y_, FX = F0ex2QR(y_), method = \"Quantile Regression\", sample = \"65 Year Old Female with 120 BP\")\n}) %&gt;%   \nbind_rows({\n  t(conditionalQuantiles) %&gt;%\n      data.frame() %&gt;%\n      as_tibble() %&gt;%\n      set_names(c(\"40 Year Old Female with 120 BP\", \"65 Year Old Female with 120 BP\")) %&gt;%\n      mutate(FX = taus) %&gt;%\n      gather(sample, y_, -FX) %&gt;% \n  mutate(method = \"Quantile Forest\")\n}) %&gt;%   \n  mutate(alpha = ifelse(method==\"Quantile Forest\",1,0.75)) %&gt;% \nggplot(aes(x = y_, y = FX, colour = sample,  lty= method)) + geom_step(aes(alpha = alpha)) + \n  ggsci::scale_colour_aaas(name = \"\") +\n  scale_linetype_manual(name = \"\", values = c(1,1,2)) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nCDFs Constructed Using Quantile Regression Forest"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome\nThe Vanderbilt Center for Health Economic Modeling was launched in 2020 to harness the diverse, internationally-recognized expertise of Vanderbilt researchers in modeling the health and economic consequences of health policy and technology changes worldwide.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Study Design\n\n\n\nCEA\n\n\nMVPF\n\n\n\n\n\n\n\nJohn Graves\n\n\nNov 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Decision Theory\n\n\n\nCEA\n\n\nMVPF\n\n\n\n\n\n\n\nJohn Graves\n\n\nNov 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Research Prioritization\n\n\n\nCEA\n\n\nMVPF\n\n\n\n\n\n\n\nJohn Graves\n\n\nNov 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Simulation to Calculate Power and Minimum Detectable Effects\n\n\n\n\n\n\nJohn Graves\n\n\nOct 9, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]