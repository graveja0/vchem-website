[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blog/resources/csabounds/NEWS.html",
    "href": "blog/resources/csabounds/NEWS.html",
    "title": "csabounds 1.0.0",
    "section": "",
    "text": "csabounds 1.0.0\n\nThe first version of the package csabounds is available\nAdded methods csabounds (the main method in the package)\nmethod attcpo (for computing the average treatment effect conditional on the previous outcome\nmethods ggcsabounds and ggattcpo for plotting the results"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html",
    "href": "blog/drafts/cdfs/estimating-cdfs.html",
    "title": "Estimating Distribution Functions",
    "section": "",
    "text": "This posting runs through various approaches for estimating distribution functions, and functions of distribution functions such as expected values.\nLet’s start with some definitions. First, define random variable \\(X\\). The cumulative distribution function (CDF) of \\(X\\) is the probability that \\(X\\) takes on some value less than \\(x\\):\n\\[\n\\begin{eqnarray}\nF_X(s) = P(X \\leq x)\n\\end{eqnarray}\n\\tag{1}\\]\nThe probability density function (PDF) tells us about the relative likelihood that \\(X\\) takes on any given value, and can be defined as the derivative of the CDF:\n\\[\nf_X(x) = \\frac{dF_X(x)}{dx}\n\\tag{2}\\]\nWorking in the opposite direction, we can also define the CDF by integrating the PDF:\n\\[\nF_X(x)=\\int_{-\\infty}^x f_X(t) d t\n\\tag{3}\\]\nThis relationship is helpful because it allows us to define the expected value of \\(X\\) as a weighted sum of values \\(x\\), with weights defined by the PDF. In integral notation:\n\\[\n\\mathrm{E_X}[X]=\\int_{-\\infty}^{\\infty} x f_X(x) dx\n\\tag{4}\\]\n\n\nOur example data will be taken from the Oregon Health Insurance Experiment (OHIE). We’ll focus on the experimental or “reduced form” aspect of the OHIE by comparing individuals randomized to Medicaid eligibility to those randomized to control. Our primary outcome of interest will be hemoglobin A1C levels.\n\nlibrary(tidyverse)\nlibrary(qte)\nlibrary(here)\nlibrary(glue)\nlibrary(conflicted)\nlibrary(hrbrthemes)\nlibrary(broom)\nlibrary(edfun)\nlibrary(scam)\nlibrary(quantregForest)\nconflict_prefer(\"filter\",\"dplyr\")\nselect &lt;- dplyr::select\noptions(\"scipen\" = 100, \"digits\" = 5)\nggplot2::theme_set(hrbrthemes::theme_ipsum(grid = \"X\"))\n\ndf &lt;- haven::read_dta(here(\"_ignore/CS9-Oregon-Insurance-Experiment-RCT-IV-Data.dta\")) %&gt;% \n mutate(D =  treatment) %&gt;% \n mutate(Y = a1c_inp) %&gt;% \n select(Y,D,nnnnumhh_li_2 ,nnnnumhh_li_3 ,age_inp, bp_sar_inp, female, starts_with(\"age_decile_dum\"),weight_total_inp) %&gt;% \n na.omit()"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#description-of-data",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#description-of-data",
    "title": "Estimating Distribution Functions",
    "section": "",
    "text": "Our example data will be taken from the Oregon Health Insurance Experiment (OHIE). We’ll focus on the experimental or “reduced form” aspect of the OHIE by comparing individuals randomized to Medicaid eligibility to those randomized to control. Our primary outcome of interest will be hemoglobin A1C levels.\n\nlibrary(tidyverse)\nlibrary(qte)\nlibrary(here)\nlibrary(glue)\nlibrary(conflicted)\nlibrary(hrbrthemes)\nlibrary(broom)\nlibrary(edfun)\nlibrary(scam)\nlibrary(quantregForest)\nconflict_prefer(\"filter\",\"dplyr\")\nselect &lt;- dplyr::select\noptions(\"scipen\" = 100, \"digits\" = 5)\nggplot2::theme_set(hrbrthemes::theme_ipsum(grid = \"X\"))\n\ndf &lt;- haven::read_dta(here(\"_ignore/CS9-Oregon-Insurance-Experiment-RCT-IV-Data.dta\")) %&gt;% \n mutate(D =  treatment) %&gt;% \n mutate(Y = a1c_inp) %&gt;% \n select(Y,D,nnnnumhh_li_2 ,nnnnumhh_li_3 ,age_inp, bp_sar_inp, female, starts_with(\"age_decile_dum\"),weight_total_inp) %&gt;% \n na.omit()"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand-using-regression",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand-using-regression",
    "title": "Estimating Distribution Functions",
    "section": "Do It “By Hand” Using Regression",
    "text": "Do It “By Hand” Using Regression\nIn the example below, we’ll construct a CDF “by hand” by defining our various values of \\(t\\) (which we’ll call y_), and then looping over them. Within each loop, we first define a binary outcome, with values of one if the value of \\(Y\\) is less than or equal to the given y_ value under consideration, and zero otherwise. We next regress this binary outcome on an intercept only; the resulting coefficient on the intercept term provides an estimate of the fraction of the sample with a \\(Y\\) value less than or equal to the y_ value.\nWe repeat this for all y_ values and plot the result as a yellow line on top of the previous plot:\n\n\n\n\n\nEmpirical CDF\n\n\n\n\nAs the figure shows, we have successfully replicated the empirical CDF plot produced by ecdf()."
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand-using-logistic-regression",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand-using-logistic-regression",
    "title": "Estimating Distribution Functions",
    "section": "Do It “By Hand” Using Logistic Regression",
    "text": "Do It “By Hand” Using Logistic Regression\nWe’ll next repeat the above exercise, but only change the regression type. That is, rather than fit a linear probability model using lm(), we’ll fit a logistic regression model. We then need to predict the outcome response to obtain an estimate of the fraction of the sample with value less than or equal to the given y_ value (this is analogous to obtaining the coefficient on the intercept term in the linear probability model approach above).\nOur new eCDF values are plotted in red below. As the plot shows, we obtain essentially the same eCDF curve:\n\n\n\n\n\nEmpirical CDF"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#create-a-smoothed-version-using-a-shape-constrained-generalized-additive-model",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#create-a-smoothed-version-using-a-shape-constrained-generalized-additive-model",
    "title": "Estimating Distribution Functions",
    "section": "Create A “Smoothed” Version Using a Shape-Constrained Generalized Additive Model",
    "text": "Create A “Smoothed” Version Using a Shape-Constrained Generalized Additive Model\nRecall from above that to calculate the PDF of \\(X\\) we can differentiate the CDF (Equation 2). However, the eCDFs calculated above are “chunky”—they are essentially step functions that move at discrete values defined over the support of the outcome.\nDepending on the application we may want to fit a smoothed function to these step function values. While R provides functionality to fit a smoothed curve to a given set of points (approxfun()), the resulting approximation function will likely not play by the rules of a CDF (e.g., minimum value 0, maximum value 1, monotonically increasing throughout, etc.).\nTo fit this approximation function we can fit a shape constrained additive model that imposes these constraints. In the plot below, this new smoothed eCDF curve is plotted in green over the step function plotted above.\n\n\nThis approach is based on the paper here and the code here.\n\n\n\n\n\nEmpirical CDF based on Shape Constrained Additive Model"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#do-it-by-hand",
    "title": "Estimating Distribution Functions",
    "section": "Do it “By Hand”",
    "text": "Do it “By Hand”\nWe can also leverage Equation 2 and the shape-constrained GAM model fit to construct an estimate of the CDF above to construct the PDF by hand. In the code below, f0() is the constructed CDF function, and we can simply add the option ,1 to obtain the first derivative (i.e., f0(y0) provides CDF values and f0(y0,1) provides PDF values)."
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-logistic-regression",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-logistic-regression",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Logistic Regression",
    "text": "Conditional CDFs Using Logistic Regression\n\n\n\n\n\nConditional CDFs Using Logistic Regression"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-quantile-regression",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-quantile-regression",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Quantile Regression",
    "text": "Conditional CDFs Using Quantile Regression\nAn alternative method is to use quantile regression\n\n\n\n\n\nCDFs Constructed Using Quantile Regression"
  },
  {
    "objectID": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-quantile-regression-forests",
    "href": "blog/drafts/cdfs/estimating-cdfs.html#conditional-cdfs-using-quantile-regression-forests",
    "title": "Estimating Distribution Functions",
    "section": "Conditional CDFs Using Quantile Regression Forests",
    "text": "Conditional CDFs Using Quantile Regression Forests\n\n\n\n\n\nCDFs Constructed Using Quantile Regression Forest"
  },
  {
    "objectID": "blog/drafts/power-simulation/power-simulation.html",
    "href": "blog/drafts/power-simulation/power-simulation.html",
    "title": "Using Simulation to Calculate Power and Minimum Detectable Effects",
    "section": "",
    "text": "This posting will walk through the steps to perform power and minimum detectable effect calculations via simulation.\nlibrary(mcreplicate)\nlibrary(tidyverse)\nlibrary(tictoc)\nlibrary(CVXR)"
  },
  {
    "objectID": "blog/drafts/power-simulation/power-simulation.html#power",
    "href": "blog/drafts/power-simulation/power-simulation.html#power",
    "title": "Using Simulation to Calculate Power and Minimum Detectable Effects",
    "section": "Power",
    "text": "Power\n\nB = 1000\npower =\n    seq(100,1000,100) %&gt;%\n    map(~(mc_replicate(B,est_power(modifyList(params,list(beta = .1,n=.x))),mc.cores=10))) %&gt;%\n    map_dbl(~(mean(.x)))  %&gt;%\n    data.frame(row.names = seq(100,1000,100)) %&gt;%\n    rownames_to_column(var = \"N\") %&gt;%\n    set_names(c(\"N\",\"power\")) %&gt;%\n    as_tibble() %&gt;%\n    mutate(N = as.numeric(paste0(N)))\npower %&gt;% knitr::kable()\n\n\n\n\nN\npower\n\n\n\n\n100\n0.150\n\n\n200\n0.297\n\n\n300\n0.433\n\n\n400\n0.512\n\n\n500\n0.603\n\n\n600\n0.681\n\n\n700\n0.758\n\n\n800\n0.793\n\n\n900\n0.852\n\n\n1000\n0.876\n\n\n\n\npower %&gt;%\n    ggplot(aes(x = N , y = power)) + geom_line() +\n    ggthemes::theme_few()"
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "",
    "text": "Part one in a three-part series on how teh tools of welfare analysis and decision science can be used to inform the direction, scope, and design of research and decision-making."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#introduction",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#introduction",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "Introduction",
    "text": "Introduction\nSuppose a policymaker is considering strategies to reduce poverty. For the sake of simplicity, let’s assume the policymaker is weighing the tradeoffs of creating or expanding an in-kind benefit transfer, such as a job training program.\nImplementing the program has a measurable impact on welfare-relevant outcomes (e.g., education, lifetime earnings, health, etc.). However, the program also imposes costs on society. These costs reflect both the budgetary cost (i.e., the total sum of program expenditures), as well as other changes in behavior, expenditures, or tax revenues that either bolster or drag on social welfare.\nBefore we proceed, it is useful to formalize the above and define summary measures of policy benefits \\(W(\\mathbf{\\pi},\\alpha)\\) and costs \\(C(\\mathbf{\\pi},\\alpha)\\). The vector \\(\\mathbf{\\pi}\\) captures welfare-relevant parameters such as the average willingness-to-pay for the policy, program costs, and any fiscal externalities (FEs) that occur as a consequence of the policy.1 We define and measure welfare benefits and costs for each of \\(D\\) total policy strategies \\(\\boldsymbol{\\alpha} = (\\alpha_1, \\cdots , \\alpha_D)\\).\n1 For example, these fiscal externalities might include changes to government tax revenues stemming from changes in participation in the labor force and/or other social programs.In a series of influential papers, Hendren and colleagues define the Marginal Value of Public Funds (MVPF) as the ratio of benefits to costs (Finkelstein and Hendren 2020; Hendren and Sprung-Keyser 2022, 2022; Hendren 2016):\n\\[\nMVPF(\\mathbf{\\pi},\\alpha) = \\frac{W(\\mathbf{\\pi},\\alpha)}{C(\\mathbf{\\pi},\\alpha)}\n\\tag{1}\\]\nThe MVPF measures the marginal value of an additional dollar spent on a policy. That is, the MVPF quantifies how the welfare benefits accrued by implementing a policy compare to the costs of adopting it.\nWhile we will leave the theoretical details to the aforementioned citations, we can summarize the MVPF of an in-kind benefit transfer as:\n\\[\nMVPF^{\\text{inkind}}(\\mathbf{\\pi},\\alpha) = \\frac{W(\\mathbf{\\pi},\\alpha)}{1+FE(\\mathbf{\\pi},\\alpha)}\n\\tag{2}\\] where \\(FE(\\mathbf{\\pi},\\alpha)\\) is the fiscal externality associated with the policy, and \\(W(\\mathbf{\\pi},\\alpha)\\) is the willingness to pay among infra-marginal recipients of the program.\nIn this example, we are comparing a single policy strategy (in-kind benefit program) to an alternative strategy of doing nothing. However, in principle we could think of alternative (competing) strategies to achieve the same objective—each with its own welfare cost and benefit estimates—that might be under consideration."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-state-of-current-knowledge",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-state-of-current-knowledge",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "The State of Current Knowledge",
    "text": "The State of Current Knowledge\nSuppose that previous research has quantified the welfare benefits and costs—such that the hypothetical policymaker has at her disposal some information that can guide her decision on which policy (if any) to pursue.\nThe state of current information is summarized in Table 1.\n\n\n\n\nTable 1: Summary of Current Knowledge\n\n\n\n\n\n\n\nMVPF [95% interval]\nBenefits [95% Interval]\nCosts [95% Interval]\n\n\n\n\ninkind\n0.89 [0.73,1.08]\n1.21 [0.99,1.46]\n1.35 [0.31,0.39]"
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#mvpf-as-a-decision-tool",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#mvpf-as-a-decision-tool",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "MVPF as a Decision Tool",
    "text": "MVPF as a Decision Tool\nTable 1 highlights that the policymaker’s decision is fraught with uncertainty. Based on current information, the estimated MVPF of the in-kind benefit is 0.894. However, the 95% interval shows that current knowledge is consistent with the policy more than paying for itself (i.e., an MVPF above 1), and with the policy resulting in some redistribution (i.e., an MVPF below 1).\nIn short, based on current evidence, it is hard to say for sure whether the policy should be adopted.\nOur policymaker’s decision problem actually goes one step further. The MVPF summarizes the private benefits that accrue from the in-kind benefit transfer; it may be that social preferences are such that, from a societal perspective, a policy with an MVPF below 1.0 is not worth pursuing.\nWe can formalize this idea by defining an additional parameter \\(\\lambda\\) summarizing societal willigness-to-pay (WTP). This threshold value could simply be based on an MVPF of one (i.e., the benefit must be at least as great as the cost). Or, if society values some redistributive consequence of the policy, \\(\\lambda\\) could be set based on a value less than one.2\n2 For example, Finkelstein, Hendren, and Shepard (2019) make comparative assessments of health insurance subsidization policies by specifying a social welfare function over Constant Relative Risk Aversion (CRRA) utility and a defined coefficient of risk aversion (\\(\\sigma = 3\\)). This results in \\(\\lambda = 0.2\\). But researchers do not necessarily have to specify the structure of the social welfare function to define a decision-making benchmark. A value tied to an existing policy with strong social support could also suffice. For instance, Finkelstein, Hendren, and Shepard (2017) also consider a benchmark (\\(\\lambda = 0.88\\)) based on the MVPF of the Earned Income Tax Credit (EITC)—a popular means-tested cash transfer program. Finally, Hendren (2020) argues for the use of efficient welfare weights that project the welfare costs and benefits of any specific policy into the MVPF of a tax transfer between the affected populations.3 For the sake of this example, welfare benefits are drawn from a lognormal distribution with mean \\(\\log(1.2)\\) and standard deviation \\(0.1\\). Welfare costs are based on Equation 2 and a fiscal externality that is normally distributed with mean \\(0.35\\) and standard deviation \\(0.2\\).Figure 1 visualizes this uncertainty for 1,000 draws from the uncertainty distributions of \\(W^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\) and \\(C^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\) in Table 1.3 In addition, for three hypothetical values of \\(\\lambda\\), each point is shaded based on whether the implied MVPF is above or below \\(\\lambda\\).\nThe dotted lines show a ray from the origin with slope \\(1/\\lambda\\); values that fall under and to the right of the line are those where the MVPF\\(\\geq \\lambda\\) and those that fall up and to the left of the line are those where MVPF\\(&lt;\\lambda\\). Finally, the green diamonds plot the average welfare benefit and cost values as summarized in Table 1.\n\n\n\n\n\n\n\n\n\n\n\n(a) lambda = 1.0\n\n\n\n\n\n\n\n\n\n\n\n(b) lambda = 0.90\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) lambda = 0.5\n\n\n\n\n\n\n\nFigure 1: Welfare Cost and Benefits Overlaid With Decision Rules Based on \\(\\lambda\\)\n\n\n\nFigure 1 (a) highlights that when \\(\\lambda=1\\), the MVPF of the in-kind benefit strategy rarely exceeds the societal willingness-to-pay threshold. In other words, there are few points in the joint uncertainty distribution where the value falls below and to the right of the dotted line. Thus, there is some—but not much—uncertainty in the decision to not implement the policy under this decision criterion.\nBy comparison, Figure 1 (c) shows that when \\(\\lambda=0.5\\), there is no decision uncertainty; our policymaker would conclude that the the in-kind benefit should be adopted—and this decision is consistent across all values in the uncertainty ranges."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-opportunity-cost-of-imperfect-information",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-opportunity-cost-of-imperfect-information",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "The Opportunity Cost of Imperfect Information",
    "text": "The Opportunity Cost of Imperfect Information\nThe above discussion highlights that depending on social preferences, policy decisions based on current information may carry an opportunity cost of making the wrong decision. This is most evident in Figure 1 (b), where based on the average welfare cost estimates in Table 1 (plotted as a green dot in Figure 1 (b)), the policymaker might elect to pursue an in-kind benefit program. In other words, the implied average MPVF basd on these values is 0.894. If \\(\\lambda = 0.9\\), this value is below the WTP threshold—so the policy would appear to pass a societal cost-benefit test.\nHowever, Figure 1 (b) also makes clear the available information is also consistent with the “true” MVPF falling above \\(\\lambda\\). That is, roughly half of the points are shaded gold (i.e., the policy does not pass our defined societal cost-benefit test) and half are shaded black (i.e., MVPF\\(&lt;\\lambda\\)). If the true MVPF is below \\(\\lambda\\), then society would incur a net welfare loss from implementing the policy.\nContrast this with the scenario in Figure 1 (c), which is based on \\(\\lambda = 0.5\\). In that scenario, there is uncertainty in the underlying welfare estimates but no uncertainty in policy adoption decisions. The same decision (to implement the in-kind benefit program) occurs across the entire uncertainty range, so there is no opportunity cost to making the “wrong” decision."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#net-welfare-benefit",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#net-welfare-benefit",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "Net Welfare Benefit",
    "text": "Net Welfare Benefit\nLet’s now formalize the above observations by defining the net welfare benefit as the benefits of a given policy minus \\(\\lambda\\) multiplied by the costs:\n\\[\nNWB(\\boldsymbol{\\pi},\\alpha,\\lambda) = W(\\boldsymbol{\\pi},\\alpha) - \\lambda \\cdot C(\\boldsymbol{\\pi},\\alpha)\n\\tag{3}\\]\nIntuitively, policies where \\(NWB \\geq 0\\) indicate situations where the MVPF is equal to or greater than \\(\\lambda\\). Put simply, when the NWB is positive, the policy passes the societal cost-benefit test; when it is negative, it does not.\nWith the NWB defined, it is useful to think about uncertainty along two distinct but related dimensions:\n\nVariation in the NWB that derives from sampling/structural/modeling uncertainty in estimates of \\(W^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\) and \\(C^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\).\nVariation in optimal decisions, which occurs when variation from (1) causes frequent sign changes in the NWB.\n\nIn other words, depending on the value of \\(\\lambda\\), variation in welfare outcomes (costs and benefits) does not necessarily imply variation in optimal decisions; it may be \\(\\lambda\\) is sufficiently low (or high) that policy decisions do not vary across the uncertainty distribution.4\n4 This is the scenario depicted in Figure 1 (c)."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#from-net-welfare-benefit-to-value-of-information",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#from-net-welfare-benefit-to-value-of-information",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "From Net Welfare Benefit to Value of Information",
    "text": "From Net Welfare Benefit to Value of Information\nThe idea that decisions based on current information may carry a welfare-valued opportunity cost underlies decision theoretic concepts of the value of information (VOI).\nBefore we define various VOI concepts and measures, let’s lay out the practical questions a VOI-based approach to welfare analysis based on the MVPF can answer:\n\nWhich strategies are cost-effective given social preferences and based on current evidence? To answer this question, we can assess whether current knowledge–cast against a summary measure of social preferences such as \\(\\lambda\\)—is sufficient to confidently make policy decisions. Because we may not want to make a stance on the particular value of \\(\\lambda\\), we can vary these assessments over a plausible range of values and estimate the expected welfare loss of making the wrong decision at a given value of \\(\\lambda\\).\nShould we invest more resources to reduce uncertainty in our decisions? If so, it will be important to isolate which sources of uncertainty we should focus on. Furthermore, we want to think about the most efficient way to sample the population to improve our knowledge on these dimensions."
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-welfare-loss-from-imperfect-information",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#the-welfare-loss-from-imperfect-information",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "The Welfare Loss from Imperfect Information",
    "text": "The Welfare Loss from Imperfect Information\nTo answer the first question, we need a summary measure of the expected welfare loss from making the wrong decision.\nDefine the optimal strategy as\n\\[\n\\alpha^* =\\arg\\max E_{\\boldsymbol{\\pi}} \\big [ NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ]\n\\] so that \\(NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\\) is the net welfare benefit evaluated at the optimal strategy, i.e.,\n\\[\nNWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda) = \\max_{\\boldsymbol{\\alpha}} E_{\\boldsymbol{\\pi}} \\big [  NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ]\n\\]\nNext, define a welfare loss function\n\\[\nL_{\\alpha} = \\max_{\\boldsymbol{\\alpha}} NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) - NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda)\n\\tag{4}\\]\nThe loss function evaluated at \\(\\alpha^*\\) is\n\\[\nL_{\\alpha^*} = \\max_{\\boldsymbol{\\alpha}} NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) - NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\n\\tag{5}\\]\nAnd its expected value is given by\n\\[\nE_{\\boldsymbol{\\pi}} \\big [ L_{\\alpha^*} \\big ]  = E_{\\boldsymbol{\\pi}} \\big [ \\max_{\\boldsymbol{\\alpha}} NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ] - NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\n\\tag{6}\\]\nThe expected welfare loss in Equation 6 is also known as the expected value of perfect information (Jackson et al. 2022; Wilson 2015):\n\\[\nE_{\\boldsymbol{\\pi}} \\big [ L_{\\alpha^*} \\big ]  = EVPI(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda)\n\\]\n\nEstimating the Expected Welfare Loss\nThe code below calcualtes the EVPI for the MVPF of the in-kind benefit transfer above, for a particular value of \\(\\lambda\\):\n\nset.seed(23)\nn &lt;- 1e5   # Number of uncertainty distribution draws\nw &lt;- rlnorm(n, log(1.2),0.1)   # welfare benefit is lognormal(ln(1.2),0.1)\nfe &lt;- rnorm(n, 0.35,.02)  # fiscal externality is norm(0.35,0.02)\nc &lt;- 1+fe  # cost is denominator of MVPF\n\nlambda &lt;- 0.9  # set a societal WTP value\nnwb &lt;- w - lambda * c  # calculate the net welfare benefit\nevpi &lt;-mean(pmax(0,nwb))-max(0,mean(nwb))  # expected value of perfect information\nevpi\n\n[1] 0.04441101\n\n\nThe estimated EVPI (0.044) is non-zero, indicating that there is overall value in reducing uncertainty in the policymaker’s decision to implement the in-kind benefit transfer. However, note that the EVPI varies over different values of \\(\\lambda\\). If \\(\\lambda\\) were instead 0.5, we would make the same decision (to implement the policy) across the entire uncertainty range—so there is no value in obtaining new information on uncertain inputs into the MVPF estimate. This can be seen in the code below:\n\nlambda &lt;- 0.5 # set a societal WTP value\nnwb_alt &lt;- w - lambda * c  # calculate the net welfare benefit\nevpi_alt &lt;-mean(pmax(0,nwb_alt))-max(0,mean(nwb_alt))  # expected value of perfect information\nevpi_alt\n\n[1] 0\n\n\nFigure 2 is based on repeating the above exercise across a variety of \\(\\lambda\\) values (x-axis) and plotting the resulting EVPI estimate for each (y-axis):\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Expected Value of Reducing Decision Uncertainty Through Future Research, by Societal Willingness-to-Pay Value (lambda)"
  },
  {
    "objectID": "blog/posts/mvpf-evpi/mvpf-evpi.html#summary-and-next-steps",
    "href": "blog/posts/mvpf-evpi/mvpf-evpi.html#summary-and-next-steps",
    "title": "Welfare Analysis Meets Decision Theory",
    "section": "Summary and Next Steps",
    "text": "Summary and Next Steps\nFigure 2 tells us that based on existing evidence, we have an answer to our first question: if the societal willigness-to-pay value (\\(\\lambda\\)) is in the neighborhood of 0.75-1.15, then there is high information value in future research to reduce uncertainty in \\(W(\\mathbf{\\pi},\\alpha)\\) and \\(C(\\mathbf{\\pi},\\alpha)\\).\nWith this information in mind—and so long as pursuing more information has value—we can move on to the second question and start to ask (a) which specific sources of uncertainty (i.e., individual parameters or sets of parmeters in \\(W(\\mathbf{\\pi},\\alpha)\\) and \\(C(\\mathbf{\\pi},\\alpha)\\)) drive the overall EVPI estimate? And how can we prospectively design a clinical trial or randomized evaluation in such a way as to most efficiently reduce information uncertainty to a point where a better decision can be made? Answering these questions is the focus of part two in this series."
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "",
    "text": "Setup R session\nlibrary(tidyverse)\nlibrary(here)\nlibrary(glue)\nlibrary(demography)\nlibrary(MortalityLaws)\nlibrary(janitor)\nlibrary(data.table)\nlibrary(expm)\ntranspose &lt;- purrr::transpose\nlibrary(dtplyr)\nlibrary(ggsci)\nlibrary(directlabels)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(hrbrthemes)\nlibrary(furrr)\nlibrary(tictoc)\nlibrary(patchwork)\n\n\nrate_to_prob &lt;- function(x) 1-exp(-x)\nprob_to_rate &lt;- function(x) -log(1-x)\n\noptions(scipen = 5) \nselect &lt;- dplyr::select\noptions(knitr.kable.NA = '')\n\ngen_wcc &lt;- function (n_cycles, method = c(\"Simpson1/3\", \"half-cycle\", \"none\")) \n{\n    if (n_cycles &lt;= 0) {\n        stop(\"Number of cycles should be positive\")\n    }\n    method &lt;- match.arg(method)\n    n_cycles &lt;- as.integer(n_cycles)\n    if (method == \"Simpson1/3\") {\n        v_cycles &lt;- seq(1, n_cycles + 1)\n        v_wcc &lt;- ((v_cycles%%2) == 0) * (2/3) + ((v_cycles%%2) != \n                                                     0) * (4/3)\n        v_wcc[1] &lt;- v_wcc[n_cycles + 1] &lt;- 1/3\n    }\n    if (method == \"half-cycle\") {\n        v_wcc &lt;- rep(1, n_cycles + 1)\n        v_wcc[1] &lt;- v_wcc[n_cycles + 1] &lt;- 0.5\n    }\n    if (method == \"none\") {\n        v_wcc &lt;- rep(1, n_cycles + 1)\n    }\n    return(v_wcc)\n}\n\nage_group_lut &lt;- c(\n    \"5\" = 1,\n    \"6\" = 5,\n    \"7\" = 10,\n    \"8\" = 15,\n    \"9\" = 20,\n    \"10\" = 25,\n    \"11\" = 30,\n    \"12\" = 35,\n    \"13\" = 40,\n    \"14\" = 45,\n    \"15\" = 50,\n    \"16\" = 55,\n    \"17\" = 60,\n    \"18\" = 65,\n    \"19\" = 70,\n    \"20\" = 75,\n    \"30\" = 80,\n    \"31\" = 85,\n    \"32\" = 90,\n    \"33\" = 95,\n    \"44\" = 100,\n    \"45\" = 105,\n    \"148\" = 110,\n    \"28\" = 0\n)\n\nlut_age_incidence = \ntibble::tribble(\n  ~age_name, ~age,\n  \"&lt;1 year\",  0L,\n  \"1-4 years\",  1L,\n  \"5-9 years\",  5L,\n  \"10-14 years\", 10L,\n  \"15-19 years\", 15L,\n  \"20-24 years\", 20L,\n  \"25-29 years\", 25L,\n  \"30-34 years\", 30L,\n  \"35-39 years\", 35L,\n  \"40-44 years\", 40L,\n  \"45-49 years\", 45L,\n  \"50-54 years\", 50L,\n  \"55-59 years\", 55L,\n  \"60-64 years\", 60L,\n  \"65-69 years\", 65L,\n  \"70-74 years\", 70L,\n  \"75-79 years\", 75L,\n  \"80-84\", 80L,\n  \"85-89\", 85L,\n  \"90-94\", 90L,\n  \"95+ years\", 95L\n)"
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#construct-a-cause-deleted-life-table",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#construct-a-cause-deleted-life-table",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "Construct a Cause-Deleted Life Table",
    "text": "Construct a Cause-Deleted Life Table\nFor a disease as prevalent as CVD, it is important that background mortality in our model net out all CVD-related deaths—otherwise, we will overcount CVD deaths, as they would be captured in a separate death-from-CVD rate, and in the background mortality rate.\nTo construct a cause-deleted life table we will use the GBD query tool to extract an estimate of the percentage of deaths from CVD for various (5-year) age groups. We will then apply this percentage to deaths in the overall life table to obtain an estimate of the number of deaths from CVD. We net this from total deaths and reconstruct the life table using a Multiple Decrements approach.\n\nLife Table Data\nThe GBD life table data are arranged by age group, so we need to download a separate file for each group, and extract the relevant location and year.\n\n\nDownload and process GBD life table data.\nif (!file.exists(here(glue(\"blog/posts/modeling-dalys/_data/gbd_life_table_{location}-{life_table_year}.rds\")))) {\n    gbd_life_tables &lt;- c(\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_28_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_5_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_6_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_7_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_8_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_9_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_10_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_11_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_12_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_13_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_14_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_15_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_16_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_17_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_18_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_19_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_20_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_30_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_31_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_32_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_33_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_44_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_45_0.zip\",\n      \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/IHME_GBD_2019_LIFE_TABLES_1950_2019_ID_148_0.zip\"\n  )\n  \n  life_table &lt;-\n    gbd_life_tables %&gt;% map(~ ({\n      cat(glue::glue(\"File: {.x}\\n\"))\n      tmp &lt;- tempfile()\n      tmpdir &lt;- tempdir()\n      download.file(.x, tmp)\n      nn &lt;-\n        gsub(\n          \"https://ghdx.healthdata.org/sites/default/files/record-attached-files/\",\n          \"\",\n          .x\n        ) %&gt;% gsub(\".ZIP|.zip\", \"\", .)\n      unzip(tmp)\n      ff &lt;- list.files(here(), pattern = \".CSV|.csv\")\n      lt_age_group &lt;-\n        ff[grep(\"WSHOCK\", ff)] %&gt;% map( ~ (read.csv(.x) %&gt;% as_tibble() %&gt;% mutate(file = .x))) %&gt;% pluck(1) %&gt;%\n        filter(year_id == life_table_year &\n                 location_name == location)\n      \n      file.remove(ff)\n      lt_age_group\n    })) %&gt;%\n    bind_rows()\n  \n  lt &lt;-\n    life_table %&gt;%\n    group_by(location_name, location_id) %&gt;%\n    nest()  %&gt;%\n    mutate(life_table = map(data,  ~ ({\n      .x %&gt;% select(sex_name, age_group_id, age_group_name, measure_name, val) %&gt;%\n        mutate(age = age_group_lut[paste0(age_group_id)]) %&gt;% \n        spread(measure_name, val) %&gt;%\n        janitor::clean_names() %&gt;%\n        rename(ex = life_expectancy,\n               qx = probability_of_death) %&gt;%\n        arrange(sex_name, age) %&gt;%\n        select(sex_name, age, ex, qx) %&gt;%\n        gather(measure, value, -sex_name, -age) %&gt;%\n        mutate(measure = paste0(measure, gsub(\"_both\", \"\", paste0(\"_\", sex_name)))) %&gt;%\n        select(-sex_name)  %&gt;%\n        spread(measure, value) %&gt;%\n        mutate(\n          p = 1 - qx,\n          p_male = 1 - qx_male,\n          p_female = 1 - qx_female\n        ) %&gt;%\n        mutate(\n          lx = radix * cumprod(c(1, p[-nrow(.)])),\n          lx_male = radix * cumprod(c(1, p_male[-nrow(.)])),\n          lx_female = radix * cumprod(c(1, p_female[-nrow(.)]))\n        )\n    })))\n\n  lt &lt;-\n    lt %&gt;%\n    mutate(hp_mort = map(life_table,  ~ ({\n      ages     &lt;- .x$age\n      deaths   &lt;- .x$lx * .x$qx\n      exposure &lt;- .x$lx\n      \n      mort_fit &lt;- MortalityLaw(\n        x  = ages,\n        Dx  = deaths,\n        # vector with death counts\n        Ex  = exposure,\n        # vector containing exposures\n        law = \"HP2\",\n        opt.method = \"LF2\"\n      )\n      coef(mort_fit) %&gt;% data.frame() %&gt;% t()\n    })))\n\n  lt %&gt;% write_rds(here(glue(\"blog/posts/modeling-dalys/_data/gbd_life_table_{location}-{life_table_year}.rds\")))\n  \n} \ndf_life_table = read_rds(here(glue(\"blog/posts/modeling-dalys/_data/gbd_life_table_{location}-{life_table_year}.rds\")))\n\n\nThe overall life table for our country of interest is shown in Table 2. Relevant columns are described in Table 3.\n\n\nConstruct Overall Life Table\nlt &lt;- \n    df_life_table %&gt;% \n    select(location_name,location_id,life_table) %&gt;% \n    unnest(cols = c(life_table))  %&gt;% \n    select(location_name, location_id, age, ex, qx)   %&gt;% \n    mutate(age_diff = c(1,lead(diff(age)))) %&gt;%   # Age difference in age group\n    mutate(mx = -log(1 - qx)/age_diff) %&gt;%  # Mortality rate\n    select(location_name, location_id, age, ex, qx, mx)  %&gt;% \n    mutate(p = 1 - qx) %&gt;%  # Survival probability\n    mutate(cump = ifelse(row_number() == 1, 1, lag(cumprod(p)))) %&gt;% # Cumulative survival\n    mutate(lx = radix * cump) %&gt;% # At risk\n    mutate(dx = lx * qx) %&gt;% # Deaths = at risk * probability of death\n    as.data.table()\nsetkey(lt, age)\n\nlt %&gt;% select(-location_id) %&gt;% kable(digits = 3) %&gt;% kable_styling()\n\n\n\n\nTable 2: Overall Life Table\n\n\n\n\n\n\nlocation_name\nage\nex\nqx\nmx\np\ncump\nlx\ndx\n\n\n\n\nUnited Kingdom\n0\n81.070\n0.004\n0.004\n0.996\n1.000\n100000.000\n350.925\n\n\nUnited Kingdom\n1\n80.355\n0.001\n0.000\n0.999\n0.996\n99649.075\n59.041\n\n\nUnited Kingdom\n5\n76.401\n0.000\n0.000\n1.000\n0.996\n99590.034\n35.692\n\n\nUnited Kingdom\n10\n71.428\n0.000\n0.000\n1.000\n0.996\n99554.341\n43.338\n\n\nUnited Kingdom\n15\n66.458\n0.001\n0.000\n0.999\n0.995\n99511.003\n120.053\n\n\nUnited Kingdom\n20\n61.535\n0.002\n0.000\n0.998\n0.994\n99390.950\n189.262\n\n\nUnited Kingdom\n25\n56.647\n0.002\n0.000\n0.998\n0.992\n99201.688\n227.279\n\n\nUnited Kingdom\n30\n51.771\n0.003\n0.001\n0.997\n0.990\n98974.409\n311.052\n\n\nUnited Kingdom\n35\n46.926\n0.004\n0.001\n0.996\n0.987\n98663.357\n437.835\n\n\nUnited Kingdom\n40\n42.124\n0.007\n0.001\n0.993\n0.982\n98225.522\n669.101\n\n\nUnited Kingdom\n45\n37.394\n0.010\n0.002\n0.990\n0.976\n97556.421\n984.145\n\n\nUnited Kingdom\n50\n32.748\n0.015\n0.003\n0.985\n0.966\n96572.276\n1489.166\n\n\nUnited Kingdom\n55\n28.219\n0.024\n0.005\n0.976\n0.951\n95083.110\n2312.887\n\n\nUnited Kingdom\n60\n23.856\n0.039\n0.008\n0.961\n0.928\n92770.223\n3601.522\n\n\nUnited Kingdom\n65\n19.712\n0.060\n0.012\n0.940\n0.892\n89168.701\n5376.422\n\n\nUnited Kingdom\n70\n15.805\n0.098\n0.021\n0.902\n0.838\n83792.279\n8207.582\n\n\nUnited Kingdom\n75\n12.233\n0.160\n0.035\n0.840\n0.756\n75584.698\n12084.596\n\n\nUnited Kingdom\n80\n9.055\n0.270\n0.063\n0.730\n0.635\n63500.101\n17118.564\n\n\nUnited Kingdom\n85\n6.434\n0.433\n0.113\n0.567\n0.464\n46381.538\n20064.172\n\n\nUnited Kingdom\n90\n4.426\n0.637\n0.202\n0.363\n0.263\n26317.366\n16755.052\n\n\nUnited Kingdom\n95\n3.100\n0.799\n0.320\n0.201\n0.096\n9562.313\n7636.243\n\n\nUnited Kingdom\n100\n2.226\n0.904\n0.469\n0.096\n0.019\n1926.070\n1741.274\n\n\nUnited Kingdom\n105\n1.720\n0.956\n0.623\n0.044\n0.002\n184.796\n176.607\n\n\nUnited Kingdom\n110\n1.452\n1.000\n\n0.000\n0.000\n8.189\n8.189\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 3: Life Table Parameters\n\n\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\nex\nRemaining life expectancy\n\n\nqx\nProbability of death in age group\n\n\nmx\nDeath rate in age group\n\n\np\nSurvival probability (1-qx)\n\n\ncump\nCumulative survival probability\n\n\nlx\nNumber at risk (set at the radix parameter value for the first age group)\n\n\ndx\nNumber of deaths in age group\n\n\n\n\n\n\nNote the life expectancy at age 0 (ex in the table). We’ll come back to this later, when we benchmark life expectancy in our model vs. the life table value."
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#gbd-cause-of-death-and-disease-incidence-data",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#gbd-cause-of-death-and-disease-incidence-data",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "GBD Cause of Death and Disease Incidence Data",
    "text": "GBD Cause of Death and Disease Incidence Data\nTo construct cause-deleted life tables we need an estimate of the number of deaths (dx) due to CVD. And to model transitions from the Healthy state to the CVD health state we’ll need disease incidence rates. To obtain these data we’ll draw on the GBD data tool to extract the percentage of deaths due to CVD, and the CVD incidence rate.1\n1 Note you need an account with login and password to download these data.The specific data query used for this example is provided in Figure 2, and the specific cause-of-death percentages for the country/region of interest are shown in Table 4 and Table 5. Code for constructing the cause-deleted life table will be provided later in this document.\n\n\n\n\n\n\n\n\n\n\n\n(a) Cause of Death\n\n\n\n\n\n\n\n\n\n\n\n(b) Age Ranges\n\n\n\n\n\n\n\nFigure 2: Global Burden of Disease Data Query Tool\n\n\n\n\n\nDownload and process GBD CVD incidence and cause of death data.\n# You can then click on \"Download.\" To obtain the data in the code below,\n# I downloaded the .csv file and used the\n# [datapasta](https://github.com/MilesMcBain/datapasta) package in R to\n# simply copy and paste the values as a table. Alternatively, you could\n# just manually load the .csv file.\n\n\ndf_gbd &lt;- \ntibble::tribble(\n    ~measure_id, ~measure_name, ~location_id,   ~location_name, ~sex_id, ~sex_name, ~age_id,     ~age_name, ~cause_id,               ~cause_name, ~metric_id, ~metric_name, ~year,        ~val,      ~upper,      ~lower,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.028996032, 0.032271777, 0.024354871,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.035378341, 0.038200527,  0.02982068,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.031923654, 0.033877513,  0.02749347,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.450558018, 0.518217768, 0.366558761,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.489648455, 0.546394959, 0.415998276,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.469612322, 0.520633016, 0.400518019,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.028030375, 0.030218263, 0.025065873,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.034179575, 0.038337972, 0.030031173,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.030684194, 0.032765225, 0.027736481,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.223162961, 0.243068851, 0.195925728,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.216691535, 0.243515145,  0.18996081,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.220004378, 0.236329232, 0.198461094,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.039746344, 0.041717485, 0.036621253,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.039007566, 0.043057948, 0.035699452,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.03942622, 0.041491836, 0.036825279,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.383598812, 0.405724933,  0.34991092,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.301487698, 0.333401339, 0.275739379,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.343507011,  0.36308575, 0.319699847,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.040429815, 0.042516915, 0.038634534,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.050448817, 0.056212097, 0.047257679,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.043765321, 0.046440911, 0.041928954,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1.272151624, 1.340633778, 1.215478459,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 0.830116477, 0.926181301, 0.778133659,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1.056297216, 1.122235147, 1.011670449,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.047865254, 0.049912826, 0.045757303,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.064022359, 0.070540903, 0.060728528,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.05241896, 0.055214123, 0.050297559,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2.584733912, 2.705960617, 2.466297393,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1.396334943, 1.540852926, 1.320505171,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1.999067921, 2.108246777, 1.910639006,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.089939927,  0.09346508, 0.086949806,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.089152972, 0.094352463,  0.08473271,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.089703584, 0.092727269, 0.086724818,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 5.734533296, 5.967850508, 5.529144225,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2.476079844, 2.623849325, 2.341002774,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 4.117495802, 4.260669343, 3.978963164,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.127257147,  0.13212298, 0.122966034,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.101388841, 0.105278948, 0.097807228,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.118479515, 0.122297221, 0.114897896,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 10.53187361, 10.94789275, 10.15541571,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  4.35406213, 4.535772035, 4.190158194,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 7.458822907, 7.697315036, 7.229905553,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.164731863, 0.169563876, 0.159608872,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.115825591, 0.120310278,  0.11192131,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.146787432,  0.15076718, 0.142663671,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 18.48100716, 19.11206584, 17.88312257,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 7.595845898, 7.897360424, 7.306437613,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 13.06167796, 13.43788854, 12.69877405,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.203159048,  0.20891541, 0.195943858,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.129206482,  0.13385869,   0.1244222,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.175222389, 0.180012567, 0.169598709,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 34.46754982, 35.59363313, 33.10261974,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  13.3674334, 13.90211799, 12.83885807,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  23.9408787, 24.62393849, 23.10570335,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.235022661, 0.241826968, 0.226840899,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.137040316, 0.141886473, 0.132341184,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.195843982, 0.201187744, 0.189756704,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 57.64153172, 59.64549167,  55.4687179,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 22.06546161,  22.9227553, 21.21789055,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 39.72241359, 40.94841318, 38.38898409,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.277583327, 0.283873162, 0.270171622,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.145665326, 0.150899461,  0.14013874,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.223082899, 0.228558598,  0.21707824,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 102.4443991, 105.5930044, 99.34510962,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  36.9364505, 38.40924932, 35.41764292,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 69.29273074, 71.26787821, 67.22859058,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.285271809, 0.291369585, 0.277471527,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.150177365, 0.155825218,  0.14478974,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.229861955, 0.235028894, 0.223731529,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 167.4830541, 172.2242284, 162.1481434,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 59.90725095,  62.3881737, 57.55691512,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 113.0734263, 116.0596868, 109.7658926,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.281151021, 0.287179834, 0.273136951,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.170456967,  0.17712227,  0.16456188,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.236307862, 0.241466541, 0.229548522,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,   268.83905,  276.361035, 259.7994394,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 107.5466843, 112.1159275,  103.324387,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 186.9215396, 191.8272762, 181.0862897,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.278931352, 0.285390185, 0.270097256,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.189643852, 0.199262556,  0.18169671,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.24226236, 0.248654952, 0.234632356,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 419.0918214, 431.4790993, 404.4716545,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 188.0950489, 198.0374997, 180.4032472,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 300.4669833,  309.027596, 290.4451193,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.290219838, 0.297721979,  0.27908183,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.228546288, 0.241247991, 0.217055247,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.264132668, 0.270822598, 0.253757269,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 718.2484425, 740.2576009, 689.8783971,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 380.8726776, 402.6775444, 361.1707849,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 542.4055968, 558.3963894,  519.894653,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.305504066,  0.31501236,  0.28991667,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.274243167, 0.291526918,   0.2534384,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.291549172, 0.302042907,   0.2749541,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  1261.89787, 1304.650375, 1194.426145,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 787.6159218, 837.4076702, 725.4738778,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  1007.22694, 1045.701239, 946.8585675,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.280637165, 0.285934654, 0.273055284,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.170429973, 0.177027993, 0.164412797,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.235520163, 0.240311903, 0.229465139,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 223.4543262, 229.1140273, 216.5032114,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 91.11203448, 94.94062023, 87.74771187,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 156.2300101, 159.9320749, 151.8013825,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.00858897, 0.010099315, 0.006696668,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.00848085, 0.010271002, 0.006544871,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.008541898, 0.010077272, 0.006836472,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3.330450581, 4.156576477, 2.485530865,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2.655721293, 3.332256697, 1.951722168,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3.001802716, 3.744109822, 2.265385428,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.323863277, 0.338597632, 0.294179612,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.320968389,  0.34424093, 0.277353832,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.322454879, 0.339212536, 0.286007648,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2350.714411, 2464.746783, 2115.530404,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  1717.38829, 1845.228956, 1482.945198,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1994.660464,  2104.05733, 1763.636077,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.333006314, 0.353674853, 0.292419986,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.355395094, 0.385917974, 0.295950118,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.345166391, 0.370659076,  0.29406337,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 4259.496089,  4537.70974,  3739.26705,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3505.823065, 3819.445125, 2924.110658,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3802.353716, 4086.741745,   3239.6705,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.347012504, 0.373106092, 0.294444394,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,   0.3819742, 0.419626054, 0.306253645,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.368727066, 0.401142671, 0.302323004,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 7531.385885, 8114.087688, 6404.069434,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 6853.993141, 7529.937194, 5521.436605,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 7081.097512, 7697.566621,  5793.23943,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.284276872, 0.289881816, 0.275883579,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.19327508, 0.202233434, 0.185474593,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.246545226, 0.251873308, 0.239180583,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 304.9005627, 312.7897016, 295.3683794,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 140.9599264, 147.5119758, 135.1275867,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 221.2598346, 226.8003663, 214.2987814,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.354344993, 0.386231837,  0.29265909,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.393392896, 0.434119892, 0.307881158,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.382935248, 0.420279524, 0.303833964,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      1L,    \"Male\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 12002.04233, 13078.34657, 9872.784146,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      2L,  \"Female\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 12202.06901,  13473.7584, 9504.961774,\n             1L,      \"Deaths\",          95L, \"United Kingdom\",      3L,    \"Both\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 12151.87861,  13346.9543,  9633.43595,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.004427021, 0.005078144, 0.003817809,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.002897491, 0.003307504, 0.002518334,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.003648131, 0.004144026, 0.003162723,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1972.922887, 2183.340769, 1783.151307,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1297.746085, 1452.740976, 1159.106723,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     25L, \"50-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1629.961478, 1804.956505, 1471.349106,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    2.91e-05,     4.1e-05,    1.94e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,     3.4e-05,    4.83e-05,    2.34e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    3.14e-05,    4.48e-05,    2.14e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  24.9433321, 33.96240142, 17.20782015,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  27.4884571, 37.70959202,  19.4225552,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 26.18301432, 35.92282821, 18.20916589,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006985657, 0.008364013, 0.005750184,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006563398, 0.007860287, 0.005399195,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006751604, 0.008089858,  0.00558803,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 4161.213887, 4821.321585, 3586.445187,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3776.346094, 4384.426185, 3238.701183,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3944.842428, 4557.939924,  3413.53611,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.007242723, 0.008670361, 0.006080238,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006763107,  0.00802545, 0.005733058,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006955542, 0.008211624, 0.005897207,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 4809.500805, 5599.626169, 4146.960721,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 4337.652627, 5022.204185, 3779.822992,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  4523.30004, 5241.389845, 3924.282623,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.007008438, 0.008388593, 0.005838585,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006764404, 0.008053951, 0.005709127,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006847976, 0.008131149, 0.005757493,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  5153.35834, 6054.284082, 4415.493281,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 4794.899993, 5535.925139, 4168.347946,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 4915.077627, 5704.042276, 4254.345879,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.00478628, 0.005371526, 0.004215691,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.003465161, 0.003938792, 0.003016288,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.004112838, 0.004618675,    0.003617,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2194.428451,  2406.85803, 1993.159002,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1585.679788, 1774.225227, 1422.457827,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     41L, \"50-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  1883.85151, 2073.117622, 1709.401335,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    3.66e-05,    5.08e-05,    2.53e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    4.35e-05,    6.21e-05,    3.07e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    3.98e-05,    5.55e-05,    2.81e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 24.59324904,  32.3236423, 18.14212397,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 26.63263159, 34.91841748, 19.49651583,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 25.58732887, 33.35788704, 18.93808663,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    3.67e-05,    5.34e-05,    2.38e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    3.95e-05,    5.91e-05,    2.59e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    3.81e-05,    5.55e-05,    2.49e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  22.3310297, 29.90118254, 15.75228658,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 22.79052798, 31.18314184, 16.29025681,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  22.5553023, 30.36903203, 16.05870836,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006466182, 0.008113919,  0.00494906,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006717997, 0.008413103, 0.005246113,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006652245, 0.008337733, 0.005160268,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 5178.260058, 6399.752007, 4145.846455,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 5131.479569, 6198.777078, 4184.513358,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 5143.217659, 6229.849414, 4181.774145,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    4.67e-05,    6.82e-05,    3.08e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    4.09e-05,     6.2e-05,    2.66e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    4.39e-05,     6.5e-05,    2.89e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 22.87371889, 31.65284084,  16.4573203,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 20.23199773, 28.68155445, 14.22015021,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 21.58386475, 30.12858466, 15.54645087,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    7.22e-05, 0.000104325,    4.85e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    5.64e-05,    7.98e-05,    3.84e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    6.41e-05,     9.1e-05,    4.37e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 34.20250428, 46.12793294, 24.68278487,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 29.51771321, 39.71237203, 21.21899829,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 31.91482917, 42.67746643, 23.23585145,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.00011163, 0.000147235,     8.4e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,    9.12e-05, 0.000117658,    6.89e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000100777, 0.000131563,    7.71e-05,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  54.5951151, 68.64899462, 42.89967879,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 51.94509918, 63.09509796, 41.63066082,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 53.28913602, 65.48823937, 42.45328627,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000158707, 0.000207095, 0.000117263,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000136054, 0.000173899, 0.000103402,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000146489, 0.000188698, 0.000109849,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 76.70838862, 93.77250984, 60.39124664,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 78.03707895, 94.15243505, 62.22901138,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 77.36776342, 94.19699663, 61.29602546,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000236315, 0.000300063, 0.000183309,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000168815, 0.000212039, 0.000129666,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000200002, 0.000251883,  0.00015506,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 114.2120994, 133.3595391, 95.66979032,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 95.90878029, 112.3761348, 79.98772686,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 105.1074144,  122.658906, 88.44256099,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000347394, 0.000453312, 0.000270394,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000193038, 0.000245021, 0.000153326,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000265664, 0.000339163, 0.000209296,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 167.1175818, 202.0579812, 138.5905463,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 105.3475316, 124.0452099,  89.9565812,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 136.3645016, 162.6483674, 115.1871198,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000835388, 0.001023785, 0.000655528,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000603191, 0.000738318, 0.000478687,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000713624, 0.000864301, 0.000569002,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 384.8955549, 434.9926458, 338.5765355,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 307.5936835, 349.2217189, 267.4334345,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 346.3302996, 388.3935502, 306.5318635,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.001508699, 0.001919095, 0.001135102,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000807068, 0.001040227,  0.00061275,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.001140713, 0.001440407, 0.000876251,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 664.2277732, 785.5254694, 550.7914263,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,  386.048847, 474.1180626, 314.1720448,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 524.1133361,  619.976481, 437.6751311,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.002633258, 0.003203164, 0.002128852,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.001326599,  0.00163697, 0.001070251,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,   0.0019557,  0.00239358, 0.001601614,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L,   1140.2292, 1286.609938, 999.7682213,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 603.6877022, 695.1201457,  518.048283,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 868.7011461, 979.7466799, 763.2998709,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.004204248, 0.005237554, 0.003290237,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.002204806, 0.002739343, 0.001726623,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.003187612, 0.003910492, 0.002515045,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1804.405504, 2137.561767, 1516.901006,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 956.2414154, 1139.293354, 792.3649777,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1375.421559, 1618.977162, 1154.786978,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.005447639, 0.006505564, 0.004396856,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.003639274, 0.004311934, 0.002988642,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.004538721,  0.00539902, 0.003725753,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2394.559222, 2706.417654, 2122.400887,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1565.638269, 1778.970591, 1380.985421,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 1973.565082, 2231.553114, 1752.133146,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006009328, 0.007365994, 0.004737917,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.005129966, 0.006403949, 0.004026852,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.005564837, 0.006856215, 0.004415209,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2908.778347, 3387.432236, 2421.804073,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2402.344734, 2879.709168, 1958.743969,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2648.707158, 3117.504164, 2198.479731,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006372452, 0.007564146, 0.005124882,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.005920085, 0.007032463, 0.004847155,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006140623, 0.007282752, 0.004987772,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3318.591571, 3781.522952, 2836.207168,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 2971.474942,  3406.04759, 2572.284332,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3137.671712, 3587.877828, 2728.823411,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006725001, 0.008257301, 0.005419978,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006329174, 0.007735237, 0.005093644,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.006515635, 0.007885192, 0.005288763,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      1L,    \"Male\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3661.648917, 4282.318944, 3098.287225,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      2L,  \"Female\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3327.243918, 3900.027926, 2789.070287,\n             6L,   \"Incidence\",          95L, \"United Kingdom\",      3L,    \"Both\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         3L,       \"Rate\", 2019L, 3482.086459, 4048.435372, 2933.525299\n    )\n\n\n\n\nGBD Cause of Death (CVD) Data Table\ndf_gbd %&gt;% \n  filter(sex_name==\"Both\") %&gt;% \n  filter((measure_name==\"Deaths\" & metric_name==\"Percent\")) %&gt;% \n  mutate(age_name= factor(age_name,levels=lut_age_incidence$age_name)) %&gt;% arrange(age_name) %&gt;% \n  filter(!is.na(age_name))  %&gt;% \n  select(-location_id,-sex_id,-sex_name,-age_id,-cause_id,-metric_id,-location_name,-cause_name,-measure_name,-measure_id,-year) %&gt;% \n  kable(digits = 3) %&gt;% \n  kable_styling()\n\n\n\n\nTable 4: GBD Cause-of-Death Data\n\n\n\n\n\n\nage_name\nmetric_name\nval\nupper\nlower\n\n\n\n\n&lt;1 year\nPercent\n0.009\n0.010\n0.007\n\n\n1-4 years\nPercent\n0.032\n0.034\n0.027\n\n\n5-9 years\nPercent\n0.031\n0.033\n0.028\n\n\n10-14 years\nPercent\n0.039\n0.041\n0.037\n\n\n15-19 years\nPercent\n0.044\n0.046\n0.042\n\n\n20-24 years\nPercent\n0.052\n0.055\n0.050\n\n\n25-29 years\nPercent\n0.090\n0.093\n0.087\n\n\n30-34 years\nPercent\n0.118\n0.122\n0.115\n\n\n35-39 years\nPercent\n0.147\n0.151\n0.143\n\n\n40-44 years\nPercent\n0.175\n0.180\n0.170\n\n\n45-49 years\nPercent\n0.196\n0.201\n0.190\n\n\n50-54 years\nPercent\n0.223\n0.229\n0.217\n\n\n55-59 years\nPercent\n0.230\n0.235\n0.224\n\n\n60-64 years\nPercent\n0.236\n0.241\n0.230\n\n\n65-69 years\nPercent\n0.242\n0.249\n0.235\n\n\n70-74 years\nPercent\n0.264\n0.271\n0.254\n\n\n75-79 years\nPercent\n0.292\n0.302\n0.275\n\n\n80-84\nPercent\n0.322\n0.339\n0.286\n\n\n85-89\nPercent\n0.345\n0.371\n0.294\n\n\n90-94\nPercent\n0.369\n0.401\n0.302\n\n\n95+ years\nPercent\n0.383\n0.420\n0.304\n\n\n\n\n\n\n\n\n\n\n\n\nCVD Incidence Rate (per 100k population) Data Table\ndf_gbd %&gt;% \n  filter(sex_name==\"Both\") %&gt;% \n  filter((measure_name==\"Incidence\" & metric_name==\"Rate\")) %&gt;% \n  mutate(age_name= factor(age_name,levels=lut_age_incidence$age_name)) %&gt;% arrange(age_name) %&gt;% \n  filter(!is.na(age_name))  %&gt;% \n  select(-location_id,-sex_id,-sex_name,-age_id,-cause_id,-metric_id,-location_name,-cause_name,-measure_name,-measure_id,-year) %&gt;% \n  kable(digits = 3) %&gt;% \n  kable_styling()\n\n\n\n\nTable 5: GBD CVD Incidence Rate Data\n\n\n\n\n\n\nage_name\nmetric_name\nval\nupper\nlower\n\n\n\n\n&lt;1 year\nRate\n26.183\n35.923\n18.209\n\n\n1-4 years\nRate\n25.587\n33.358\n18.938\n\n\n5-9 years\nRate\n22.555\n30.369\n16.059\n\n\n10-14 years\nRate\n21.584\n30.129\n15.546\n\n\n15-19 years\nRate\n31.915\n42.677\n23.236\n\n\n20-24 years\nRate\n53.289\n65.488\n42.453\n\n\n25-29 years\nRate\n77.368\n94.197\n61.296\n\n\n30-34 years\nRate\n105.107\n122.659\n88.443\n\n\n35-39 years\nRate\n136.365\n162.648\n115.187\n\n\n40-44 years\nRate\n346.330\n388.394\n306.532\n\n\n45-49 years\nRate\n524.113\n619.976\n437.675\n\n\n50-54 years\nRate\n868.701\n979.747\n763.300\n\n\n55-59 years\nRate\n1375.422\n1618.977\n1154.787\n\n\n60-64 years\nRate\n1973.565\n2231.553\n1752.133\n\n\n65-69 years\nRate\n2648.707\n3117.504\n2198.480\n\n\n70-74 years\nRate\n3137.672\n3587.878\n2728.823\n\n\n75-79 years\nRate\n3482.086\n4048.435\n2933.525\n\n\n80-84\nRate\n3944.842\n4557.940\n3413.536\n\n\n85-89\nRate\n4523.300\n5241.390\n3924.283\n\n\n90-94\nRate\n4915.078\n5704.042\n4254.346\n\n\n95+ years\nRate\n5143.218\n6229.849\n4181.774"
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#define-functions-for-time-inhomogeneous-parameters",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#define-functions-for-time-inhomogeneous-parameters",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "Define Functions for Time Inhomogeneous Parameters",
    "text": "Define Functions for Time Inhomogeneous Parameters\nNearly all health state progression parameters in our model are age-depdendent. We therefore need to define functions for each transition rate that are a function of the age of the cohort in the cycle. The functions below draw on the GBD data above to estimate age-specific transition rates for the following transitions:\n\nrH_CVD(age) = Healthy to CVD (uses a slightly calibrated GBD disease incidence rate).\nrCVD_D(age) = CVD to death from CVD (uses the cause-specific mortality rate from a cause-deleted life table).\nrD(age) = Death from other causes (uses cause-deleted mortality rate from a cause-deleted life table).\n\nFor this model, we will simply draw rates directly from the GBD life tables and other data. A limitation of this approach is that ages are grouped into five-year buckets—meaning that the mortality rate will be held constant within an age group.\n\n\nAge-dependent incidence rate function\nrH_CVD &lt;- function(aa,gg = \"Both\") {\n  df_gbd %&gt;% \n    filter(measure_name == \"Incidence\" & sex_name==gg & metric_name==\"Rate\") %&gt;% \n    inner_join(lut_age_incidence,\"age_name\") %&gt;% \n    select(age, cvd_incidence = val) %&gt;% \n    arrange(age) %&gt;% \n    mutate(age_diff = c(1,lead(diff(age)))) %&gt;% \n    mutate(age_diff = ifelse(age==95,5,age_diff)) %&gt;% \n    mutate_at(vars(contains(\"incidence\")),function(x) x) %&gt;% \n    as.data.table() %&gt;% \n    mutate(cvd_incidencepop = cvd_incidence / 100000) %&gt;% \n    setkey(.,age) %&gt;% \n    {.[data.table(age=aa) %&gt;% setkey(.,age),roll=\"nearest\"]} %&gt;% \n    pull(cvd_incidencepop) %&gt;% \n    {. * params$rr_incidence}\n}\n\n\n\nOptional: Parametric Mortality\nAs an alternative option that provides age-specific (i.e., ungrouped) rates, we also include a parametric morality model (based on the Heligman-Pollard model, which captures mortality across ages quite well).2\n2 To explore more on parametric mortality modeling, see our interactive tutorial here.The leftmost panel in Figure 3 shows the observed vs. fitted log(mortality rate) for our population, while the rightmost panel shows the residual. The residuals show clearly that the model fits mortality rates well up until about age 80, at which point the modeled mortality rate overstates the death rate until roughly age 95—after which the modeled mortality rate is well below the observed rate.\nIn the code below, we provide alternative functions to draw on the modeled mortality rates to return age-specific death transition rates—though note that in our results below, we continue to draw directly off the GBD data.\n\n\nFit Parametric Mortality Model\nfit_mort &lt;- function(params, mortality_model = \"HP2\", gg = \"Both\", outcome = \"dx_nocvd\") {\n    with(params,({\n        \n        pct_cvd &lt;-\n            df_gbd %&gt;%\n            filter(measure_name == \"Deaths\" & sex_name == gg & metric_name==\"Percent\") %&gt;%\n            inner_join(lut_age_incidence, \"age_name\") %&gt;%\n            select(\n                age,\n                pct_cvd = val,\n                upper_pct_cvd = upper,\n                lower_pct_cvd = lower\n            ) %&gt;%\n            as.data.table() %&gt;% \n            arrange(age)\n        setkey(pct_cvd, age)\n        \n        lt_cvd &lt;-\n            pct_cvd[lt, roll = \"nearest\"] %&gt;%\n            as_tibble() %&gt;%\n            mutate(age_diff = c(1,diff(age))) %&gt;% \n            mutate(dx_cvd = (lx * qx * pct_cvd)/age_diff) %&gt;%\n            mutate(dx_nocvd  = (dx - dx_cvd)/age_diff) %&gt;% \n            mutate(dx = lx * qx / age_diff) %&gt;% \n            na.omit() \n        \n        ages = lt_cvd$age\n        deaths = unname(unlist(lt_cvd[,outcome]))\n        exposure = lt_cvd$lx\n        \n        fit_hp &lt;- \n            MortalityLaw(\n                x  = ages,\n                Dx  = deaths,\n                # vector with death counts\n                Ex  = exposure,\n                # vector containing exposures\n                law = \"HP2\",\n                opt.method = \"LF2\"\n            )\n        \n        return(fit_hp)\n    }))\n}\n\n\n\n\nFit and Plot Heligman-Pollard Model\nfit_hp = params %&gt;% fit_mort(outcome = \"dx\") \nplot(fit_hp)\n\n\n\n\n\n\n\n\nFigure 3: Fitted vs. Observed Mortality Using Heligman-Pollard Parametric Mortality Model\n\n\n\n\n\n\n\nUpdate parameters with Heligman-Pollard models for CVD deaths and non-CVD deaths.\nparams &lt;- modifyList(params,{\n    list(\n        mort_fit_dx = params %&gt;% fit_mort(outcome = \"dx\") %&gt;% coef(.), \n        mort_fit_dx_nocvd = params %&gt;% fit_mort(outcome = \"dx_nocvd\")  %&gt;% coef() , \n        mort_fit_dx_cvd = params %&gt;% fit_mort(outcome = \"dx_cvd\")  %&gt;% coef()\n    )\n})\n\ndisc = \n  exp(-params$r_Delta_t * 0:(params$omega))\n\n\n\n\nAge-dependent mortality rate function\nrD &lt;- function(aa, gg = \"Both\") {\n  setkey(lt, age)\n  \n  pct_cvd &lt;-\n      df_gbd %&gt;%\n      filter(measure_name == \"Deaths\" & sex_name == gg & metric_name==\"Percent\") %&gt;%\n      inner_join(lut_age_incidence, \"age_name\") %&gt;%\n      select(\n          age,\n          pct_cvd = val,\n          upper_pct_cvd = upper,\n          lower_pct_cvd = lower\n      ) %&gt;%\n      as.data.table() %&gt;% \n      arrange(age) %&gt;% \n    mutate(pct_cvd = params$rr_deathCVD * pct_cvd)\n  setkey(pct_cvd, age)\n  \n  lt_cvd_ &lt;-\n      pct_cvd[lt, roll = \"nearest\"] %&gt;%\n      as_tibble() \n  lt_cvd &lt;- \n      lt_cvd_ %&gt;% \n      #mutate(pct_cvd = 0) %&gt;% \n      mutate(dx_cvd = lx * qx * pct_cvd) %&gt;%\n      mutate(dx_nocvd  = dx - dx_cvd,\n             R_nocvd = (dx - dx_cvd) / dx) %&gt;%\n      mutate(mx_nocvd = R_nocvd * mx,\n             mx_cvd = mx - mx_nocvd) %&gt;%\n      na.omit() \n\n  r &lt;-\n    lt_cvd %&gt;%\n    as.data.table() %&gt;%\n    setkey(., age) %&gt;%\n    {\n        .[data.table(age = aa) %&gt;% setkey(., age), roll = \"nearest\"]\n    } %&gt;%\n    pull(mx_nocvd)\n\n  return(r)\n}\n\nrCVD_D &lt;- function(aa, gg = \"Both\") {\nsetkey(lt, age)\n  \n  pct_cvd &lt;-\n      df_gbd %&gt;%\n      filter(measure_name == \"Deaths\" & sex_name == gg & metric_name==\"Percent\") %&gt;%\n      inner_join(lut_age_incidence, \"age_name\") %&gt;%\n      select(\n          age,\n          pct_cvd = val,\n          upper_pct_cvd = upper,\n          lower_pct_cvd = lower\n      ) %&gt;%\n      as.data.table() %&gt;% \n      arrange(age) %&gt;% \n      mutate(pct_cvd = params$rr_deathCVD * pct_cvd)\n  setkey(pct_cvd, age)\n  \n  lt_cvd_ &lt;-\n      pct_cvd[lt, roll = \"nearest\"] %&gt;%\n      as_tibble() \n  lt_cvd &lt;- \n      lt_cvd_ %&gt;% \n      mutate(dx_cvd = lx * qx * pct_cvd) %&gt;%\n      mutate(dx_nocvd  = dx - dx_cvd,\n             R_nocvd = (dx - dx_cvd) / dx) %&gt;%\n      mutate(mx_nocvd = R_nocvd * mx,\n             mx_cvd = mx - mx_nocvd) %&gt;%\n      na.omit() \n\n  r &lt;-\n    lt_cvd %&gt;%\n    as.data.table() %&gt;%\n    setkey(., age) %&gt;%\n    {\n        .[data.table(age = aa) %&gt;% setkey(., age), roll = \"nearest\"]\n    } %&gt;%\n    pull(mx_cvd)\n\n  return(r)\n  \n}\n\nrD_unadj_p = function(aa,params) {\n    with(params,{\n         coef_ &lt;- mort_fit_dx\n        HP2(aa,coef_)$hx   \n    })\n}\n\nrD_p = function(aa,params) {\n      with(params,{\n         coef_ &lt;- mort_fit_dx_nocvd\n        HP2(aa,coef_)$hx   \n    })\n}\n\nrCVD_D_p = function(aa,params) {\n      with(params,{\n         coef_ &lt;- mort_fit_dx_cvd\n        HP2(aa,coef_)$hx   \n    })\n}\n\n\nUsing the functions defined above, we can easily extract transition rates for a given age. Echoing the comments above, note that the basic function (rD(age)) uses grouped mortality rate data, whereas the function based on the Heligman-Pollard model yields different rates for each age:\n\n# Rate of non-cause death for a 75 and 76 year-old\nrD(75)\n\n[1] 0.02366835\n\nrD(76)\n\n[1] 0.02366835\n\n# Rate of non-cause death for a 75 and 76 year-old based on Heligman Pollard model\nrD_p(75, params = params)\n\n[1] 0.02761481\n\nrD_p(76, params = params)\n\n[1] 0.03007687"
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#checkpoint-overall-survival",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#checkpoint-overall-survival",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "Checkpoint: Overall Survival",
    "text": "Checkpoint: Overall Survival\nBefore we proceed, it is useful to stop and check whether the experience of our modeled cohort mirrors the experience of the population as summarized in the GBD input data sources.\nIn Figure 5 below, we calculate and plot the percent of the cohort surviving at each age (1 - DeathOC - DeathCVD) and overlay the survival probability from the population life table used to parameterize the model. As the figure shows, our modeled cohort nearly exactly matches the survival experience of the population.\n\n\nConstruct Survival Curves\n# Check Life Expectancy vs. Life Table\nlt_ &lt;- df_life_table %&gt;% \n    select(location_name,location_id,life_table) %&gt;% \n    unnest(cols = c(life_table))  %&gt;% \n    select(location_name, location_id, age, ex, qx)   %&gt;% \n    filter(age &gt;= params1$age0) %&gt;% \n    mutate(age_diff = c(1,lead(diff(age)))) %&gt;% \n    mutate(mx = -log(1 - qx)/age_diff) %&gt;% \n    select(location_name, location_id, age, ex, qx, mx)  %&gt;% \n    mutate(p = 1 - qx) %&gt;%\n    mutate(cump = ifelse(row_number() == 1, 1, lag(cumprod(p)))) %&gt;%\n    mutate(lx = radix * cump) %&gt;%\n    mutate(dx = lx * qx) %&gt;%\n    as.data.table()\n\nd_ &lt;- c(1,1,0,0)\nas.matrix(tr) %*% d_ %&gt;% data.frame() %&gt;% \n    as_tibble() %&gt;% \n    set_names(c('model')) %&gt;% \n    mutate(age = params$ages_trace) %&gt;% \n    inner_join(lt_ %&gt;% select(age,life_table = cump)) %&gt;% \n    gather(method,value,-age)  %&gt;% \n    ggplot(aes(x = age, y = value)) + geom_line(aes(colour=method)) + \n    theme_ipsum() + \n    geom_dl(method = list(\"last.points\",\"bumpup\"), aes(label = method, colour = method)) + \n    scale_x_continuous(expand = c(.25,0), breaks = seq(0,110,10)) + \n    theme(legend.position=\"none\") + \n    scale_colour_aaas() + \n    labs(x = \"Age\", y = \"Percent Living\")\n\n\n\n\n\n\n\n\nFigure 5: Survival Curve"
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#checkpoint-cvd-prevalence",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#checkpoint-cvd-prevalence",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "Checkpoint: CVD Prevalence",
    "text": "Checkpoint: CVD Prevalence\nOur next checkpoint is designed to assess whether CVD prevalance at any age matches the prevalance value in the GBD data. Figure 6 below shows this using the parameters above.\n\n\n\n\n\n\nNote that this\n\n\n\n\n\nPrevalence by Age, Model vs. GBD Data\ndf_prevalence &lt;- \n  tibble::tribble(\n      ~measure_id, ~measure_name, ~location_id,   ~location_name, ~sex_id, ~sex_name, ~age_id,     ~age_name, ~cause_id,               ~cause_name, ~metric_id, ~metric_name, ~year,        ~val,      ~upper,      ~lower,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",      5L,   \"1-4 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,   0.0000878, 0.000129159,   0.0000585,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",      6L,   \"5-9 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.001149058, 0.001697486, 0.000762774,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",      7L, \"10-14 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.002124186, 0.003148646, 0.001371886,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",      8L, \"15-19 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.004583822, 0.006644945, 0.003073985,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",      9L, \"20-24 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.005942458, 0.008226115, 0.004300527,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     10L, \"25-29 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.00996704, 0.013682815, 0.007414362,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     11L, \"30-34 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.011397874, 0.014942621, 0.009118873,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     12L, \"35-39 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.014296479, 0.016443542,  0.01252059,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     13L, \"40-44 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.037308496, 0.045780893, 0.031435951,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     14L, \"45-49 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.051644521, 0.057469379, 0.046823625,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     15L, \"50-54 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.078084533, 0.086939447, 0.070462836,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     16L, \"55-59 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.120485163, 0.132099872, 0.109649198,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     17L, \"60-64 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L,  0.17921163,  0.19685285,  0.16262344,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     18L, \"65-69 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.256318787, 0.277513117, 0.236628128,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     19L, \"70-74 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.334571503, 0.360158788, 0.307798254,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     20L, \"75-79 years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.402821035, 0.432475543, 0.373508479,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     28L,     \"&lt;1 year\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.000000668,  0.00000144, 0.000000237,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     30L,       \"80-84\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.452174474, 0.483670261, 0.419854319,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     31L,       \"85-89\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.472928576, 0.506979294, 0.441347641,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",     32L,       \"90-94\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.470160144, 0.508229264, 0.437316163,\n               5L,  \"Prevalence\",          95L, \"United Kingdom\",      3L,    \"Both\",    235L,   \"95+ years\",      491L, \"Cardiovascular diseases\",         2L,    \"Percent\", 2019L, 0.448909821, 0.488972286, 0.413508609\n      ) %&gt;% \n  inner_join(lut_age_incidence,\"age_name\") %&gt;% \n  select(age,val)\n\nas.matrix(tr) %&gt;% \n  as_tibble() %&gt;% \n  mutate(age = params$ages_trace) %&gt;% \n  filter(age %in% lut_age_incidence$age)  %&gt;% \n  mutate(prev_model = CVD / (CVD + Healthy)) %&gt;% \n  select(age,prev_model) %&gt;% \n  data.frame() %&gt;% \n  left_join(df_prevalence %&gt;% rename(prev_gbd = val),\"age\") %&gt;% \n  gather(method,value,-age) %&gt;% \n  ggplot(aes(x = age, y = value, colour = method)) + geom_point() +  geom_line() +\n  geom_dl(method=list(\"last.points\",\"bumpup\"),aes(label = method)) +\n  theme_ipsum() + \n  scale_colour_aaas() + \n  scale_x_comma(expand = c(0.25,0))\n\n\n\n\n\n\n\n\nFigure 6: Prevalence by Age, Model vs. GBD Data\n\n\n\n\n\n\nYears Lost Due to Disability (YLD)\nTo calculate YLDs in a given cycle, we multiply state occupancy by a disability weight payoff vector \\(\\mathbf{d}\\),\n\\[\n\\mathbf{d}=\\left[\\begin{array}{c}\n0 \\\\\n\\text{dw}_{CVD} \\big ( \\frac{1}{r_{\\Delta_t}}(1-e^{-r_{\\Delta_t}}) \\Delta_t \\big ) \\\\\n0 \\\\\n0\n\\end{array}\\right]\n\\] where \\(\\texttt{dwS1}\\) and \\(\\texttt{dwS2}\\) are the disability weights for the Sick and Sicker states, respectively.\n\n\nYears of Life Lost (YLL)\nYLLs are based on the present value of remaining life expectancy among deaths that occur in each cycle \\(t\\). Define \\(a(t)\\) as the age of the cohort at cycle \\(t\\), i.e., \\(a(t) = t \\cdot \\Delta t + a0\\), where \\(a_0\\) is the age of the cohort at \\(t=0\\). Define \\(e(t)=e(a(t))\\) as the present value of remaining life expectancy at cycle \\(t\\). Following the GBD continuous time discounting approach, \\(e(a(t))\\) is given by\n\\[\ne(a(t)) = \\frac{1}{r}\\big (1 - e^{-rEx(a(t))} \\big )\n\\tag{1}\\]\nwhere \\(Ex(a)\\) is the remaining life expectancy at age \\(a\\). \\(Ex(a)\\) is drawn from either an exogenous or an endogenous life table, depending on the objectives of the modeling exercise (Anand and Reddy 2019).\nWe next define a remaining life expectancy payoff vector at cycle \\(t\\):\n\\[\n\\mathbf{e}(t)=\\left[\\begin{array}{c}\n0   \\\\\n0   \\\\\n0   \\\\\n0   \\\\\n\\frac{1}{r}\\big (1 - e^{-rEx(a(t))} \\big )\n\\end{array}\\right]\n\\]\nThis payoff vector reflects discounting, but only in terms of the present value of remaining life expectancy at time \\(t\\).\n\n\nCalculate Outcomes\n# Life Expectancy (Non-Discounted)\nle_ = with(params1,(matrix(c(1,\n              1 ,\n              0,\n              0),\n            dimnames = list(c(\n                c(tr_names,ab_names)\n            ), c(\"DW\")))\n))\n\nLEt &lt;- trace1 %&gt;% map( ~ ({\n    tmp = as.matrix(.x) %*% le_\n    tmp \n}))\n\nLE = LEt %&gt;% map(~sum(.x * gen_wcc(params1$omega, method = params1$cycle_correction))) \n\n\n# Life Expectancy (Non-Discounted)\nqaly_ = with(params1,(matrix(c(uH,\n              uCVD ,\n              0,\n              0),\n            dimnames = list(c(\n                c(tr_names,ab_names)\n            ), c(\"DW\")))\n))\n\nQALYt &lt;- trace1 %&gt;% map( ~ ({\n    tmp = as.matrix(.x) %*% qaly_\n    tmp \n}))\n\nQALY = QALYt %&gt;% map(~sum(.x * disc * gen_wcc(params1$omega, method = params1$cycle_correction))) \n\n# YLD\n\nyld_ = with(params1,(matrix(c(0,\n              dw * Delta_t * (1/r_Delta_t) * (1 - exp(-r_Delta_t)) ,\n              0,\n              0),\n            dimnames = list(c(\n                c(tr_names,ab_names)\n            ), c(\"DW\")))\n))\n\n\nYLDt &lt;- trace1 %&gt;% map( ~ ({\n    tmp = as.matrix(.x) %*% yld_\n    tmp \n}))\n\nYLD = YLDt %&gt;% map(~sum(.x*  disc * gen_wcc(params1$omega, method = params1$cycle_correction)))\n\n# YLL\n\nnew_deaths_from_disease &lt;- \n    map(trace1,~({\n        c(0,diff(.x[,\"DeathCVD\"]))\n    })) \n   \nremaining_life_expectancy &lt;- \n    with(params1,(1/r_ann) * (1 - exp(-r_ann * fExR(ages_trace))))\n    \nYLLt &lt;- \n    new_deaths_from_disease %&gt;% map(~(.x * remaining_life_expectancy ))\n\nYLL &lt;- \n    YLLt %&gt;% map(~(sum(.x * disc * gen_wcc(params1$omega,method = params1$cycle_correction))))\n\nDALY &lt;- \n    map2(YLL,YLD,~(.x + .y))\n\nresult1 &lt;- cbind(LE, YLD, YLL, DALY) %&gt;%\n  as.data.frame() %&gt;%\n  mutate_all( ~ as.numeric(.))  %&gt;%\n  rownames_to_column(var = \"strategy\") %&gt;%\n  mutate(approach = \"Markov Trace\") %&gt;%\n  mutate(LE_LT = lt %&gt;% filter(age == params1$age0) %&gt;% pull(ex)) %&gt;%\n  mutate(LE_LT = ifelse(strategy != \"natural_history\", NA, LE_LT)) %&gt;%\n  dplyr::select(approach, strategy, LE_LT, LE, YLD, YLL, DALY) \n\nresult1 %&gt;% \n    kable(digits = 3, col.names = c(\"Approach\",\"Scenario\",\"Life Expectancy (Life Table)\",\"Life Expectancy (Model)\",\"YLDs\",\"YLLs\",\"DALYs\")) %&gt;% \n    kable_styling()\n\n\n\n\n\nApproach\nScenario\nLife Expectancy (Life Table)\nLife Expectancy (Model)\nYLDs\nYLLs\nDALYs\n\n\n\n\nMarkov Trace\nnatural_history\n81.07\n81.081\n0.363\n1.921\n2.284\n\n\nMarkov Trace\nprevent\n\n81.188\n0.334\n1.787\n2.121\n\n\nMarkov Trace\ntreat\n\n81.255\n0.370\n1.704\n2.074\n\n\nMarkov Trace\nprevent_treat\n\n81.350\n0.341\n1.585\n1.926"
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#total-expected-outcomes",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#total-expected-outcomes",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "Total Expected Outcomes",
    "text": "Total Expected Outcomes\nFor both occupancy- and transition-based outcomes, total (across all ages) outcomes for each starting health state are calculated as\n\\[\n\\boldsymbol{\\rho}_{m}^{\\text {stage }}(\\operatorname{age} x)=\\left(\\mathbf{e}_{x}^{\\top} \\otimes \\mathbf{I}_{\\tau}\\right) \\tilde{\\boldsymbol{\\rho}}_{m} \\quad \\tau \\times 1\n\\] where \\(\\otimes\\) is the Kronecker operator.\nAlternatively, we may wish to calculate outcomes separately under different starting ages, and for a specified starting health state (e.g., healthy). This is given by\n\\[\n\\boldsymbol{\\rho}_{m}^{\\text {age }}(\\text { stage } i)=\\left(\\mathbf{I}_{\\omega} \\otimes \\mathbf{e}_{i}^{\\top}\\right) \\tilde{\\boldsymbol{\\rho}}_{m} \\quad \\omega \\times 1,\n\\]"
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#a-note-on-discounting",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#a-note-on-discounting",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "A Note on Discounting",
    "text": "A Note on Discounting\nThough later GBD iterations removed age and time discounting for the purposes of documenting disease burdens worldwide, the World Health Organization’s Choosing Interventions that are Cost-Effective (WHO-CHOICE) program recommends consideration of time discounting of health outcomes (Murray et al. 2020; Bertram et al. 2021). Discounting is also not covered in the original formulation of the Healthy Longevity approach as outlined in Caswell and van Daalen (2021).\nWhile we have set the annual discount rate to zero for this example, our approach adopts the WHO-CHOICE recommendation and includes the option for time discounting in the provided code. Specifically, we apply the cycle-specific discount factor to the values in the rewards matrix \\(\\mathbf{V}\\) and vector \\(\\mathbf{v}\\) for occupancy-based outcomes. For YLL outcomes, we apply the appropriate discounting factor to the age classes in the remaining life expectancy vector \\(\\tilde{\\boldsymbol{\\eta}}^{\\top}\\)."
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#results",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#results",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "Results",
    "text": "Results\nTable 8 adds results based on the healthy longevity approach for comparison. In this table, we calculate YLLs using the exogenous reference life table from the GBD (Global Burden of Disease Collaborative Network 2021).\nRemaining life expectancy is identical across approaches, reflecting the fact that we used a half-cycle correction for Approaches 1 and 2, and the Healthy Longevity approach applies a similar half-cycle correction.11 YLDs, YLLs and DALYs are also similar across the three methods.\n11 Had we used a different cycle correction method we would yield slightly different results—but the differences are rarely meaningful for optimal decisions.\n\nCalculate DALY Outcomes\n# Life Expectancy \n\nH = with(params3,matrix(1,nrow=tau, ncol=omega))\nV_LE = with(params3,matrix(1,nrow=tau, ncol = omega))\n# Only include the below if discounting remaining life expectancy\n# V_LE[1,] &lt;- disc\n# V_LE[2,] &lt;- disc\n# V_LE[3,] &lt;- disc\n\nV_YLD = with(params3,matrix(0,nrow=tau, ncol = omega))\nV_YLD[2,] &lt;- disc[-length(disc)]*with(params3,dw * Delta_t * (1/r_Delta_t) * (1 - exp(-r_Delta_t)))\n\nV_QALY = with(params3,matrix(0,nrow=tau, ncol = omega))\nV_QALY[1,] &lt;- disc[-length(disc)]*with(params3,uH)\nV_QALY[2,] &lt;- disc[-length(disc)]*with(params3,uCVD)\n\nLE3_ &lt;- params3 %&gt;% healthy_longevity_occupancy(H = H, V = V_LE)\nQALY3_ &lt;- params3 %&gt;% healthy_longevity_occupancy(H = H, V = V_QALY)\nYLD3_ &lt;- params3 %&gt;% healthy_longevity_occupancy(H = H, V = V_YLD)\n\nremaining_life_expectancy &lt;- with(params3,(1/r_ann) * (1 - exp(-r_ann * fExR(ages))))\nYLL3_ &lt;- params3 %&gt;% healthy_longevity_yll(life_expectancy = remaining_life_expectancy, disc = disc[-length(disc)])\nDALY3_ &lt;- map2(YLL3_,YLD3_,~(.x+.y))\n\nLE3 &lt;- LE3_ %&gt;% map(~({\n  tmp &lt;- (kronecker(t(c(1,rep(0,params3$omega-1))) ,diag(params3$tau)) %*% as.matrix(.x))\n  tmp[1,1]\n}))\n\nQALY3 &lt;- QALY3_ %&gt;% map(~({\n  tmp &lt;- (kronecker(t(c(1,rep(0,params3$omega-1))) ,diag(params3$tau)) %*% as.matrix(.x))\n  tmp[1,1]\n}))\n\nYLD3 &lt;- YLD3_ %&gt;% map(~({\n  tmp &lt;- (kronecker(t(c(1,rep(0,params3$omega-1))) ,diag(params3$tau)) %*% as.matrix(.x))\n  tmp[1,1]\n}))\n\nYLL3 &lt;- YLL3_ %&gt;% map(~({\n  tmp &lt;- (kronecker(t(c(1,rep(0,params3$omega-1))) ,diag(params3$tau)) %*% as.matrix(.x))\n  tmp[1,1]\n}))\n\nDALY3 &lt;- DALY3_ %&gt;% map(~({\n  tmp &lt;- (kronecker(t(c(1,rep(0,params3$omega-1))) ,diag(params3$tau)) %*% as.matrix(.x))\n  tmp[1,1]\n}))\n\nresult3 &lt;- cbind(LE3, YLD3,YLL3,DALY3) %&gt;%\n    as.data.frame() %&gt;%\n    mutate_all(~as.numeric(.))  %&gt;%\n    rownames_to_column(var=\"strategy\") %&gt;%\n    mutate(approach = \"Markov Chain With Rewards\") %&gt;%\n    dplyr::select(approach, strategy, LE = LE3, YLD=YLD3, YLL=YLL3, DALY=DALY3)\n\ntib &lt;- result1 %&gt;%\n    bind_rows(result2) %&gt;% \n  bind_rows(result3)\n\ntib %&gt;%\n    arrange(strategy) %&gt;%\n    select(-strategy) %&gt;%\n    kable(digits = 3, col.names = c(\"Approach\",\"Life Expectancy (Life Table)\",\"Life Expectancy (Model)\",\"YLDs\",\"YLLs\",\"DALYs\")) %&gt;% \n    kable_styling() %&gt;% \n    pack_rows(index = c(\"natural_history\" =3, \"prevention\" = 3, \"treatment\" = 3,\"prevent_treat\" = 3)) %&gt;%\n    kable_styling()\n\n\n\n\nTable 8: Life Expectancy, YLD, YLL and DALY Outcomes, by Approach\n\n\n\n\n\n\nApproach\nLife Expectancy (Life Table)\nLife Expectancy (Model)\nYLDs\nYLLs\nDALYs\n\n\n\n\nnatural_history\n\n\nMarkov Trace\n81.07\n81.081\n0.363\n1.921\n2.284\n\n\nTransition States\n\n81.081\n0.363\n1.921\n2.284\n\n\nMarkov Chain With Rewards\n\n81.081\n0.353\n2.022\n2.376\n\n\nprevention\n\n\nMarkov Trace\n\n81.188\n0.334\n1.787\n2.121\n\n\nTransition States\n\n81.188\n0.334\n1.787\n2.121\n\n\nMarkov Chain With Rewards\n\n81.188\n0.325\n1.882\n2.207\n\n\ntreatment\n\n\nMarkov Trace\n\n81.350\n0.341\n1.585\n1.926\n\n\nTransition States\n\n81.350\n0.341\n1.585\n1.926\n\n\nMarkov Chain With Rewards\n\n81.350\n0.331\n1.670\n2.001\n\n\nprevent_treat\n\n\nMarkov Trace\n\n81.255\n0.370\n1.704\n2.074\n\n\nTransition States\n\n81.255\n0.370\n1.704\n2.074\n\n\nMarkov Chain With Rewards\n\n81.255\n0.360\n1.794\n2.155"
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#dalys-for-different-starting-ages",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#dalys-for-different-starting-ages",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "DALYs for Different Starting Ages",
    "text": "DALYs for Different Starting Ages\nOur models above assumed a starting cohort age of 0. One nice feature of the healthy longevity approach, however, is that we can calculate outcomes for any starting age.12 We can apply the following formula to our constructed transition and reward matrices to yield expected outcomes across ages:\n12 We could do this using the Markov-traced approaches, too, but we’d need to re-run the model with a new cohort starting at each age.\\[\n\\boldsymbol{\\rho}_{m}^{\\text {age }}(\\text { stage } i)=\\left(\\mathbf{I}_{\\omega} \\otimes \\mathbf{e}_{i}^{\\top}\\right) \\tilde{\\boldsymbol{\\rho}}_{m} \\quad \\omega \\times 1,\n\\]\nFigure 11 plots the results.\n\n\nCreate Plot by Age\np1 = YLL3_ %&gt;% map(~({\n  as.data.frame(kronecker(diag(params3$omega),t(c(1,0))) %*% as.matrix(.x)) %&gt;% \n  mutate(age = params3$ages)  %&gt;% \n  mutate(initial = params3$tr_names[1])\n})) %&gt;% \n  set_names(params3$tx_names) %&gt;% \n  bind_rows(.id = \"strategy\") %&gt;% \n  ggplot(aes(x = age, y = V1, colour = strategy, lty=strategy)) + geom_line() + theme_ipsum() + \n  scale_colour_aaas() + \n  geom_dl(method = list(\"first.points\",\"bumpup\", hjust=-1),aes(label = strategy)) +\n    theme(legend.position = \"none\") + ggtitle(\"YLL\") + labs(x = \"Age\", y = \"YLL\")\n\np2 = YLD3_ %&gt;% map(~({\n  as.data.frame(kronecker(diag(params3$omega),t(c(1,0))) %*% as.matrix(.x)) %&gt;% \n  mutate(age = params3$ages)  %&gt;% \n  mutate(initial = params3$tr_names[1])\n})) %&gt;% \n  set_names(params3$tx_names) %&gt;% \n  bind_rows(.id = \"strategy\") %&gt;% \n  ggplot(aes(x = age, y = V1, colour = strategy, lty=strategy)) + geom_line() + theme_ipsum() + \n  scale_colour_aaas() + \n  geom_dl(method = list(\"first.points\",\"bumpup\", hjust=-1),aes(label = strategy))  + \n  theme(legend.position = \"none\") + ggtitle(\"YLD\") + labs(x = \"Age\", y = \"YLD\")\n\np3 = DALY3_ %&gt;% map(~({\n  as.data.frame(kronecker(diag(params3$omega),t(c(1,0))) %*% as.matrix(.x)) %&gt;% \n  mutate(age = params3$ages)  %&gt;% \n  mutate(initial = params3$tr_names[1])\n})) %&gt;% \n  set_names(params3$tx_names) %&gt;% \n  bind_rows(.id = \"strategy\") %&gt;% \n  ggplot(aes(x = age, y = V1, colour = strategy, lty=strategy)) + geom_line() + theme_ipsum() + \n  scale_colour_aaas() + \n  geom_dl(method = list(\"first.points\",\"bumpup\", hjust=-1),aes(label = strategy))  + \n  theme(legend.position = \"none\") + ggtitle(\"DALY\") + labs(x = \"Age\", y = \"DALY\")\n\n\np3 + p1  / p2\n\n\n\n\n\n\n\n\nFigure 11: DALYs by Model Starting Age\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that had we employed an annual discount rate in our results, the age-based plots shown in Figure 11 are not recommended, as the various later ages would be discounted and would therefore not represent cohorts with different initial agess from the same baseline period."
  },
  {
    "objectID": "blog/posts/modeling-dalys/modeling-dalys.html#daly-shortcut-qaly-like-daly",
    "href": "blog/posts/modeling-dalys/modeling-dalys.html#daly-shortcut-qaly-like-daly",
    "title": "Structuring Markov Models for Multidimensional Health Outcomes",
    "section": "DALY Shortcut: QALY-like DALY",
    "text": "DALY Shortcut: QALY-like DALY\nSome applications and modeling platforms apply a “shortcut” to estimate DALYs by defining a payoff vector that “rewards” time in the sick state using the disability weight (as in the approaches above), and also applies a payoff value of 1 for each cycle spent in the disease-related death state.\nTo implement this shortcut we multiply state occupancy in a given cycle by the payoff vector \\(\\mathbf{d_{QALYDALY}}\\),\n\\[\n\\mathbf{d_{QALYDALY}}=\\left[\\begin{array}{c}\n0 \\\\\n\\text{dw}_{CVD} \\\\\n1.0 \\\\\n0\n\\end{array}\\right]\n\\] where \\(\\text{dwS}\\) is the disability weights for CVD.\n\n\n\n\n\n\nImportant\n\n\n\nAs we will see in the results below, this approach will yield different results for DALYs because it conflates the model time horizon with life expectancy. A primary issue is that it applies a payoff value of 1.0 to an absorbing state; the number of times this payoff value is applied to the population is purely a function of the time horizon in the model. In other words, we can arbitrarily increase or decrease the estimated contribution of YLLs to DALYs by lengthening or shortening the number of cycles in our model. Since occupancy in an absorbing state will remain positive even if everyone in the cohort has died, we will continue to accrue (or lose) YLLs as we add or subtract cycles to the end of the Markov trace\nWe do not face a similar issue when estimating YLDs because if everyone has entered an absorbing state, we are simply multiplying the disability weight by an occupancy value that is essentially zero.\n\n\n\n\nCalculate Endogenous DALYs\n# QALY-LIKE DALY\nqaly_daly_ = with(params1,(matrix(c(0,\n               (dw * Delta_t * (1/r_Delta_t) * (1 - exp(-r_Delta_t))) ,\n              0,\n              1),\n            dimnames = list(c(\n                c(tr_names,ab_names)\n            ), c(\"DW\")))\n))\n\n# QALY-LIKE DALY\nYLL_qaly_daly_ = with(params1,(matrix(c(0,\n               0 ,\n              0,\n              1),\n            dimnames = list(c(\n                c(tr_names,ab_names)\n            ), c(\"DW\")))\n))\n\nYLL_QALY_DALYt &lt;- trace1 %&gt;% map( ~ ({\n    tmp = as.matrix(.x) %*% YLL_qaly_daly_\n    tmp\n}))\n\nYLL_QALY_DALY = YLL_QALY_DALYt %&gt;% map(~sum(.x*  disc * gen_wcc(params1$omega, method = params1$cycle_correction)))\n\n\nQALY_DALYt &lt;- trace1 %&gt;% map( ~ ({\n    tmp = as.matrix(.x) %*% qaly_daly_\n    tmp\n}))\n\nQALY_DALY = QALY_DALYt %&gt;% map(~sum(.x*  disc * gen_wcc(params1$omega, method = params1$cycle_correction)))\n\n\n\n\nDALYs based on endogenous life expectancy\n# Caswell and van Daalen (2021) recommend using eq (51), which multiplies the \n# fundamental matrix (eq 16) by a vector of ones. However, this estimate\n# of longevity does not make any kind of cycle correction. Instead, we will\n# use the estimate of life expectancy calculated earlier (LE3) to fill out the \n# \"reward\" matrix for remaining life expectancy at each age. The \n# code to use the original approach is provided (and commented out) below, however.\n# N = with(params3,({\n#   mUtilde %&gt;% map(~({\n#     solve(diag(tau*omega)-.x)\n#   }))\n# }))\n# \n# remaining_life_expectancy_endogenous = as.vector(t(rep(1,params3$tau*params3$omega)) %*% N[[1]]) %&gt;% {.[seq(1,params3$tau*params3$omega,2)]}\n# YLL3_endogenous_ &lt;- params3 %&gt;% healthy_longevity_yll(life_expectancy = remaining_life_expectancy_endogenous, disc = disc[-length(disc)])\n\nremaining_life_expectancy_endogenous &lt;- \n  LE3_ %&gt;% map(~({.x[seq(1,params3$tau*params3$omega,2)]})) %&gt;% {.$natural_history}\nYLL3_endogenous_ &lt;- params3 %&gt;% healthy_longevity_yll(life_expectancy = remaining_life_expectancy_endogenous, disc = disc[-length(disc)])\n\nYLL3_endogenous &lt;- YLL3_endogenous_ %&gt;% map(~({\n  tmp &lt;- (kronecker(t(c(1,rep(0,params3$omega-1))) ,diag(params3$tau)) %*% as.matrix(.x))\n  tmp[1,1] # life expectancy when starting healthy\n}))\n\n# Endogeneous life expectancy only affects YLLs, so we can simply use the YLD value from above.\nYLD3_endogenous &lt;- YLD3_ %&gt;% map(~({\n  tmp &lt;- (kronecker(t(c(1,rep(0,params3$omega-1))) ,diag(params3$tau)) %*% as.matrix(.x))\n  tmp[1,1]\n}))\n\nDALY3_endogenous_ &lt;- map2(YLL3_endogenous_,YLD3_,~(.x+.y))\n\nDALY3_endogenous &lt;- DALY3_endogenous_ %&gt;% map(~({\n  tmp &lt;- (kronecker(t(c(1,rep(0,params3$omega-1))) ,diag(params3$tau)) %*% as.matrix(.x))\n  tmp[1,1]\n}))\n\n\nresult4 &lt;- cbind(LE3, YLD3_endogenous, YLL3_endogenous, DALY3_endogenous) %&gt;%\n    as.data.frame() %&gt;%\n    mutate_all(~as.numeric(.))  %&gt;%\n    rownames_to_column(var=\"strategy\") %&gt;%\n    mutate(approach = \"Markov Chain With Rewards - Endogenous\") %&gt;%\n    dplyr::select(approach, strategy ,LE = LE3, YLD = YLD3_endogenous, YLL = YLL3_endogenous,  DALY=DALY3_endogenous) %&gt;% \n  bind_rows(\n     cbind(LE,YLD,YLL_QALY_DALY,QALY_DALY) %&gt;%\n      as.data.frame() %&gt;%\n      mutate_all(~as.numeric(.))  %&gt;%\n      rownames_to_column(var=\"strategy\") %&gt;%\n      mutate(approach = \"Markov Trace - QALY-like DALY\") %&gt;%\n      dplyr::select(approach, strategy, LE, YLD , YLL= YLL_QALY_DALY, DALY=QALY_DALY)\n  )\n\ntib &lt;- result1 %&gt;%\n    bind_rows(result2) %&gt;% \n  bind_rows(result3) %&gt;% \n  bind_rows(result4)\n\ntib %&gt;%\n    arrange(strategy) %&gt;%\n    select(-strategy) %&gt;%\n    kable(digits = 3, col.names = c(\"Approach\",\"Life Expectancy (Life Table)\",\"Life Expectancy (Model)\",\"YLDs\",\"YLLs\",\"DALYs\")) %&gt;% \n    kable_styling() %&gt;% \n    pack_rows(index = c(\"natural_history\" =5, \"prevention\" = 5, \"treatment\" = 5,\"prevent_treat\" = 5)) %&gt;%\n    kable_styling()\n\n\n\n\n\nApproach\nLife Expectancy (Life Table)\nLife Expectancy (Model)\nYLDs\nYLLs\nDALYs\n\n\n\n\nnatural_history\n\n\nMarkov Trace\n81.07\n81.081\n0.363\n1.921\n2.284\n\n\nTransition States\n\n81.081\n0.363\n1.921\n2.284\n\n\nMarkov Chain With Rewards\n\n81.081\n0.353\n2.022\n2.376\n\n\nMarkov Chain With Rewards - Endogenous\n\n81.081\n0.353\n1.484\n1.837\n\n\nMarkov Trace - QALY-like DALY\n\n81.081\n0.363\n6.409\n6.772\n\n\nprevention\n\n\nMarkov Trace\n\n81.188\n0.334\n1.787\n2.121\n\n\nTransition States\n\n81.188\n0.334\n1.787\n2.121\n\n\nMarkov Chain With Rewards\n\n81.188\n0.325\n1.882\n2.207\n\n\nMarkov Chain With Rewards - Endogenous\n\n81.188\n0.325\n1.380\n1.705\n\n\nMarkov Trace - QALY-like DALY\n\n81.188\n0.334\n5.980\n6.314\n\n\ntreatment\n\n\nMarkov Trace\n\n81.350\n0.341\n1.585\n1.926\n\n\nTransition States\n\n81.350\n0.341\n1.585\n1.926\n\n\nMarkov Chain With Rewards\n\n81.350\n0.331\n1.670\n2.001\n\n\nMarkov Chain With Rewards - Endogenous\n\n81.350\n0.331\n1.223\n1.555\n\n\nMarkov Trace - QALY-like DALY\n\n81.350\n0.341\n5.348\n5.689\n\n\nprevent_treat\n\n\nMarkov Trace\n\n81.255\n0.370\n1.704\n2.074\n\n\nTransition States\n\n81.255\n0.370\n1.704\n2.074\n\n\nMarkov Chain With Rewards\n\n81.255\n0.360\n1.794\n2.155\n\n\nMarkov Chain With Rewards - Endogenous\n\n81.255\n0.360\n1.315\n1.675\n\n\nMarkov Trace - QALY-like DALY\n\n81.255\n0.370\n5.732\n6.102"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vanderbilt Center for Health Economic Modeling",
    "section": "",
    "text": "Disability-Adjusted Life Years for Policy and Decision Analysis\n\n\nA Tutorial\n\n\n\n\n\n\n\n\nDec 13, 2023\n\n\nJohn Graves\n\n\n\n\n\n\n\n\n\n\n\n\nStructuring Markov Models for Multidimensional Health Outcomes\n\n\nConstruction of a Decision-Analytic Markov Model Using Global Burden of Disease Data\n\n\n\n\n\n\n\n\nDec 15, 2023\n\n\nJohn Graves\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Decision Theory\n\n\nPart One: Net Welfare Benefit and the Value of Information\n\n\n\n\n\n\n\n\nNov 1, 2023\n\n\nJohn Graves\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Research Prioritization\n\n\nPart Two: Using the MVPF to Inform the Direction of Future Research\n\n\n\n\n\n\n\n\nNov 1, 2023\n\n\nJohn Graves\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Study Design\n\n\nPart Three: Using the MVPF to Inform the Design of a Randomized Experiment\n\n\n\n\n\n\n\n\nNov 1, 2023\n\n\nJohn Graves\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Vanderbilt Center for Health Economic Modeling"
    ]
  },
  {
    "objectID": "blog/posts/dalys/modeling-dalys.html",
    "href": "blog/posts/dalys/modeling-dalys.html",
    "title": "Disability-Adjusted Life Years for Policy and Decision Analysis",
    "section": "",
    "text": "Introduction\nSources: Caswell and Zarulli (2018) and Caswell and Daalen (2021)\n\n\nProgressive Disease Model\n\n\n\nSetup\n\nlibrary(tidyverse)\nlibrary(MASS)\nlibrary(expm)\nlibrary(knitr)\nlibrary(kableExtra)\noptions(scipen = 5) \nselect &lt;- dplyr::select\noptions(knitr.kable.NA = '')\n\n\n\nParameterize\n\n\nApproach 1: Markov Trace\n\n\n\n\n\n\nHealthy\nSick\nSicker\nDeadBG\nDeadDisease\n\n\n\n\n1.000\n0.000\n0.000\n0.000\n0.000\n\n\n0.861\n0.041\n0.002\n0.095\n0.001\n\n\n0.741\n0.066\n0.008\n0.181\n0.004\n\n\n0.638\n0.080\n0.015\n0.258\n0.009\n\n\n0.549\n0.087\n0.022\n0.328\n0.015\n\n\n0.472\n0.089\n0.028\n0.390\n0.021\n\n\n0.407\n0.087\n0.033\n0.446\n0.028\n\n\n0.350\n0.083\n0.037\n0.496\n0.035\n\n\n0.301\n0.077\n0.040\n0.540\n0.042\n\n\n0.259\n0.071\n0.041\n0.579\n0.049\n\n\n\n\n\n\n\n\n\n\n\n\nApproach\nScenario\nLife Expectancy\nYLDs\nYLLs\nDALYs\n\n\n\n\nMarkov Trace\nnatural_history\n8.733\n0.150\n2.616\n2.766\n\n\nMarkov Trace\nprevention\n8.915\n0.127\n2.213\n2.340\n\n\nMarkov Trace\ntreatment\n9.017\n0.154\n1.980\n2.134\n\n\n\n\n\n\n\n\n\nApproach 2: Transition States\n\n\n\n\n\n\nApproach\nLife Expectancy\nYLDs\nYLLs\nDALYs\n\n\n\n\nnatural_history\n\n\nMarkov Trace\n8.733\n0.150\n2.616\n2.766\n\n\nTransition States\n8.733\n0.150\n2.616\n2.766\n\n\nprevention\n\n\nMarkov Trace\n8.915\n0.127\n2.213\n2.340\n\n\nTransition States\n8.915\n0.127\n2.213\n2.340\n\n\ntreatment\n\n\nMarkov Trace\n9.017\n0.154\n1.980\n2.134\n\n\nTransition States\n9.017\n0.154\n1.980\n2.134\n\n\n\n\n\n\n\n\n\nApproach 3: Markov Chains With Rewards\n\nNote that this strategy essentially uses a half-cycle correction (more accurately, it assumes events happen half-way through the cycle)\nIt also cannot incorporate discounting at the moment.\nNotation/Objects to Define\n\n\\(\\mathbf{D}\\)\n\\(\\mathbf{V}\\)\n\\(\\mathbf{R}\\)\n\\(\\mathbf{Q}\\) and \\(\\mathbf{\\tilde Q}\\)\n\\(\\mathbf{P}\\)\n\\(\\mathbf{U}\\)\n\\(\\mathbf{M}\\)\n\n\n\\[\n\\mathbf{P}=\\left(\\begin{array}{c|c}\n\\mathbf{U} & \\mathbf{0} \\\\\n\\hline \\mathbf{M} & \\mathbf{I}\n\\end{array}\\right)\n\\]\n\\[\n\\mathbf{Q}=\\left(\\begin{array}{c|c}\n\\mathbf{V} & \\mathbf{0} \\\\\n\\hline \\mathbf{S} & \\mathbf{0}\n\\end{array}\\right)\n\\]\n\\[\n\\mathbf{P}=e^{\\mathbf{Q} \\Delta t}\n\\]\n\\[\n\\mathbf{D}_j=\\left(\\begin{array}{ccc}\n0 & 0 & 0 \\\\\n1 & 0 & 0 \\\\\n0 & 1 & {[1]}\n\\end{array}\\right) \\quad j=1, \\ldots, \\tau\n\\]\n\\[\n\\mathbb{U}=\\left(\\begin{array}{c|c|c}\n\\mathbf{U}_1 & \\cdots & \\mathbf{0} \\\\\n\\hline & \\ddots & \\\\\n\\hline \\mathbf{0} & \\cdots & \\mathbf{U}_\\omega\n\\end{array}\\right)\n\\]\n\\[\n\\mathbb{D}=\\left(\\begin{array}{c|c|c}\n\\mathbf{D}_1 & \\cdots & \\mathbf{0} \\\\\n\\hline & \\ddots & \\\\\n\\hline \\mathbf{0} & \\cdots & \\mathbf{D}_\\tau\n\\end{array}\\right)\n\\]\n\\[\n\\tilde{\\mathbf{U}}=\\mathbf{K}^{\\top} \\mathbb{D} \\mathbf{K} \\mathbb{U} \\quad \\tau \\omega \\times \\tau \\omega\n\\]\n\\[\n\\tilde{\\mathbf{M}}=\\left(\\begin{array}{lll}\n\\mathbf{M}_1 & \\cdots & \\mathbf{M}_\\omega\n\\end{array}\\right) \\quad \\alpha \\times \\tau \\omega\n\\]\n\\[\n\\tilde{\\mathbf{P}}=\\left(\\begin{array}{c|c}\n\\tilde{\\mathbf{U}} & \\mathbf{0}_{\\tau \\omega \\times \\alpha} \\\\\n\\hline \\tilde{\\mathbf{M}} & \\mathbf{I}_{\\alpha \\times \\alpha}\n\\end{array}\\right) \\quad(\\tau \\omega+\\alpha) \\times(\\tau \\omega+\\alpha)\n\\]\n\n\n\n\n\nApproach\nLife Expectancy\nYLDs\nYLLs\nDALYs\n\n\n\n\nnatural_history\n\n\nMarkov Trace\n8.733\n0.150\n2.616\n2.766\n\n\nTransition States\n8.733\n0.150\n2.616\n2.766\n\n\nHealthy Longevity\n8.733\n0.138\n2.696\n2.834\n\n\nprevention\n\n\nMarkov Trace\n8.915\n0.127\n2.213\n2.340\n\n\nTransition States\n8.915\n0.127\n2.213\n2.340\n\n\nHealthy Longevity\n8.915\n0.117\n2.281\n2.398\n\n\ntreatment\n\n\nMarkov Trace\n9.017\n0.154\n1.980\n2.134\n\n\nTransition States\n9.017\n0.154\n1.980\n2.134\n\n\nHealthy Longevity\n9.005\n0.143\n2.553\n2.696\n\n\n\n\n\n\n\n\n\n\n\n\nApproach\nDALY (ref.)\nincDALY Prevention\nincDALY Treatment\n\n\n\n\nHealthy Longevity\n2.834\n-0.436\n-0.138\n\n\nMarkov Trace\n2.766\n-0.426\n-0.632\n\n\nTransition States\n2.766\n-0.426\n-0.632\n\n\n\n\n\n\n\n\n\nApproach 4: QALY-Like DALY\n\n\n\n\n\nApproach\nLife Expectancy\nYLDs\nYLLs\nDALYs\nQALY-like DALY\n\n\n\n\nnatural_history\n\n\nMarkov Trace\n8.733\n0.150\n2.616\n2.766\n\n\n\nTransition States\n8.733\n0.150\n2.616\n2.766\n\n\n\nHealthy Longevity\n8.733\n0.138\n2.696\n2.834\n\n\n\nQALY-like DALY\n\n\n\n\n1.299\n\n\nprevention\n\n\nMarkov Trace\n8.915\n0.127\n2.213\n2.340\n\n\n\nTransition States\n8.915\n0.127\n2.213\n2.340\n\n\n\nHealthy Longevity\n8.915\n0.117\n2.281\n2.398\n\n\n\nQALY-like DALY\n\n\n\n\n1.100\n\n\ntreatment\n\n\nMarkov Trace\n9.017\n0.154\n1.980\n2.134\n\n\n\nTransition States\n9.017\n0.154\n1.980\n2.134\n\n\n\nHealthy Longevity\n9.005\n0.143\n2.553\n2.696\n\n\n\nQALY-like DALY\n\n\n\n\n1.459\n\n\n\n\n\n\n\n\n\n\n\n\nApproach\nDALY (ref.)\nincDALY Prevention\nincDALY Treatment\n\n\n\n\nHealthy Longevity\n2.834\n-0.436\n-0.138\n\n\nMarkov Trace\n2.766\n-0.426\n-0.632\n\n\nQALY-like DALY\n1.299\n-0.198\n0.160\n\n\nTransition States\n2.766\n-0.426\n-0.632\n\n\n\n\n\n\n\n\n\nDebugging\n\nThe fundamental matrix gives you expected occupancy without any cycle correction. So it’s not great for plugging in endogenous life table values; you’d really want to just solve for life expectancy using rewards and use those values.\n\nSee 1. vs. 2 for this (with no discounting, no sickness transitions, and a reasonably high background death transition)\n\nOnce you add the reward matrices (3 vs. 4) you essentially get the same answer whether or not you use the cycle correction. This is because the cycle correction is just a way of accounting for the fact that transitions don’t happen at the beginning or end of each cycle. But the reward matrix approach is already accounting for that. So you don’t need to do both.\nWe can also use basic math and an exponential death rate to get the same answer as above (see 3. vs. 4 vs. 5)\n6 and 7 use partial rewards and are similar to the above. Markov trace with half-cycle correction, and reward matrix, both yield nearly identical answers.\n8 vs. 9 shows that transition rewards (for YLLs) are also hte same using a markov trace diff(deaths) approach and the matrix with rewards approach.\n\n\n\n\n\n\nReferences\n\nCaswell, Hal, and Silke van Daalen. 2021. “Healthy Longevity from Incidence-Based Models: More Kinds of Health Than Stars in the Sky.” Demographic Research 45 (July): 397–452. https://doi.org/10.4054/demres.2021.45.13.\n\n\nCaswell, Hal, and Virginia Zarulli. 2018. “Matrix Methods in Health Demography: A New Approach to the Stochastic Analysis of Healthy Longevity and DALYs.” Population Health Metrics 16 (1). https://doi.org/10.1186/s12963-018-0165-5."
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html",
    "title": "Welfare Analysis Meets Study Design",
    "section": "",
    "text": "Part three in a three-part series on how the tools of comparative welfare analysis can be used to refine and design prospective randomized evaluations.\nReference"
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html#what-is-the-expected-value-of-sample-information",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html#what-is-the-expected-value-of-sample-information",
    "title": "Welfare Analysis Meets Study Design",
    "section": "What is the Expected Value of Sample Information?",
    "text": "What is the Expected Value of Sample Information?\nTo build an intuitive foundation for what follows, suppose we decide to design a randomized experiment that will improve our knowledge of MVPF parameter(s) \\(\\pi_z\\).3\n3 Note that all other remaining MVPF parameters in \\(\\mathbf{\\pi}\\) are captured in \\(\\mathbf{\\pi_{-z}}\\), such that \\(\\mathbf{\\pi} = (\\mathbf{\\pi_{z}},\\mathbf{\\pi_{-z}})\\).We traditionally think about the design of randomized experiments in terms of their statistical power—that is, the probability that a statistical test will detect a difference between treated and untreated groups, when such a difference exists.\nAnother way to state the above is that we want to avoid Type II error. But there are often practical (often resource-based) limits to how far we are willing to go on this.\nOne way to minimize Type II error is simply to enroll thousands or even millions of study units (e.g., people, households, clinics, etc.). But while that would yield a trial with power at or near 100%, our trial would be costly, time-consuming, and resource intensive—and we may well incur an additional loss in social welfare if an efficacious policy is (randomly) withheld from a large fraction of the overall population.\nConsequently, it is common to think of trial design in terms of enrolling enough study units so that a comparison of outcomes between treated and treated units has least 80% power to detect an effect. There is a vast statistical literature specifying analytic formulas and simulation-based exercises to optimize this (statistical) dimension of experimental design.\nA useful way to think about the EVSI is as the social welfare analog to power. That is, we want to avoid implementing a policy that results in a sub-optimal level of social welfare. It may be that doing nothing (or implementing some alternative policy option) would be the welfare-optimizing choice–but the available (uncertain) evidence leads us down the wrong decision path. To avoid this, we can leverage the EVSI to guide our study design so that we can optimize societal payoff of both the research itself, and the resulting policy decision.\nFrom a design perspective, the EVPPI for our parameter(s) of interest (\\(\\pi_z\\)) provides an upper bound on the information value that would accrue from obtaining perfect information on the “true” value(s) of \\(\\pi_z\\). In that sense, designing a trial that enrolls enough people or units to obtain an EVSI that is very close to the EVPPI is like designing a trial with statistical power at or near 100%.\nBy the same token, we can also think about designing a smaller-scale experiment that provides some new information value, but not (near) perfect information. But just as we want to avoid an under-powered trial, we also want to avoid a situation where the information value we obtain from our study is not enough to inform the policymaker’s decision.\nCalculating the EVSI for different trial sizes (and designs) allows us to do just this."
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html#expected-value-of-perfect-information",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html#expected-value-of-perfect-information",
    "title": "Welfare Analysis Meets Study Design",
    "section": "Expected Value of Perfect Information",
    "text": "Expected Value of Perfect Information\nOur first guidepost is to make sure that any future research would help inform our policymaker’s decision.6 To assess this, we estimate the EVPI for various societal willingness-to-pay parameter (\\(\\lambda\\)) values. Figure 1 summarizes this exercise.\n6 We covered the EVPI in detail in part one of this series, however both the formulas and code are provided here for the example at hand.\n\n\n\n\n\nEVPI Equations and Notation (click to expand)\n\n\n\n\n\nPolicy benefits are summarized by \\(W(\\mathbf{\\pi},\\alpha)\\), and costs by \\(C(\\mathbf{\\pi},\\alpha)\\). The vector \\(\\mathbf{\\pi}\\) captures welfare-relevant parameters such as the average willingness-to-pay for the policy, program costs, and any fiscal externalities (FEs) that occur as a consequence of the policy.\nWe define and measure welfare benefits and costs for each of \\(D\\) total policy strategies \\(\\boldsymbol{\\alpha} = (\\alpha_1, \\cdots , \\alpha_D)\\).\nFinally, \\(\\lambda\\) summarizes societal willigness-to-pay (WTP), i.e., a policy with MVPF greater than or equal to \\(\\lambda\\) passes a societal cost-benefit test. This threshold value could simply be based on an MVPF of one (i.e., the benefit must be at least as great as the cost). Or, if society values some redistribution, \\(\\lambda\\) could be set based on a value less than one.\nThe net welfare benefit (NWB) is defined as:\n\\[\nNWB(\\boldsymbol{\\pi},\\alpha,\\lambda) = W(\\boldsymbol{\\pi},\\alpha) - \\lambda \\cdot C(\\boldsymbol{\\pi},\\alpha)\n\\tag{1}\\]\nand we define the optimal strategy as\n\\[\n\\alpha^* =\\arg\\max E_{\\boldsymbol{\\pi}} \\big [ NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ]\n\\]\nwhere \\(E_{\\pi}\\) is the expectation over the joint uncertainty distribution of current knowledge. Thus, \\(NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\\) captures the net welfare benefit evaluated at the optimal strategy.\nThe Expected Value of Perfect Information (EVPI) is given by:\n\\[\nEVPI(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) = E_{\\boldsymbol{\\pi}} \\big [ \\max_{\\boldsymbol{\\alpha}} NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ] - NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)\n\\tag{2}\\]\n\n\n\n\n\nCode\ncalc_nwb &lt;- function(B,C,lambda) {\n    B - lambda * C\n}\n\ncalc_evpi &lt;- function(B,      # Benefits\n                      C,      # Net Costs\n                      lambda  # Societal willingness-to-pay \n                     ) {\n    nwb_ &lt;- calc_nwb(B = B, C = C, lambda = lambda)\n    evpi &lt;- mean(pmax(0,nwb_))-max(0,mean(nwb_)) \n    return(tibble(lambda = lambda, evpi = evpi))\n}\n\nevpi_data &lt;- \n    lambdas %&gt;% \n    map_df(~(calc_evpi(B = delta_W, C = (delta_E - delta_C), lambda = .x)))\n\nxlab &lt;- expression(paste(\"MVPF Value of Societal Willingness-to-Pay (\",lambda,\")\"))\n  \np &lt;- \n    evpi_data %&gt;% \n    ggplot(aes(x = lambda, y = evpi)) + \n    geom_point(size = 4) + geom_line(linewidth=1.25) + \n    theme_hc() + \n    theme(text = element_text(family = 'Arial')) +\n    labs(x = xlab, y = \"Value of Information\\nEVPI\")\n    #labs(x = \"Societal WTP Value (lambda)\", y = \"Value of Information (EVPI, EVPPI)\")\np\n\n\n\n\n\n\n\n\nFigure 1: Expected Value of Perfect Information by Societal Willingness to Pay Value\n\n\n\n\n\nFigure 1 shows that there is overall value in reducing information uncertainty in the policy decision—and this information value is maximized near a \\(\\lambda\\) value of 0.85.7\n7 To provide some context for this value, Hendren (2016) estimates that the the MVPF for the Earned Income Tax Credit (EITC)—a popular means-tested cash transfer program—is around 0.9. It is worth noting, however, that later updates center the EITC MVPF estimate at 1.12."
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html#expected-value-of-partial-perfect-information",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html#expected-value-of-partial-perfect-information",
    "title": "Welfare Analysis Meets Study Design",
    "section": "Expected Value of Partial Perfect Information",
    "text": "Expected Value of Partial Perfect Information\nOur next task is to prioritize future research around efforts to obtain information on parameter(s) with high information value. To do this, we will take probabilistic draws from the joint uncertainty distribution of the MVPF paramters in Table 1 and fit flexible metamodels for each parameter, with the calculated net welfare benefit as the outcome.8\n8 Details on how to do this are provided in part two.\n\n\n\n\n\nEVPPI Equations and Notation\n\n\n\n\n\nSuppose we could obtain perfect information on some subset (\\(\\boldsymbol{\\pi}_z\\)) of the parameter(s) that determine the MVPF; we do not pursue additional research on the remaining uncertain parameters \\(\\boldsymbol{\\pi}_{-z}\\).\nThe expected value of partial perfect information (EVPPI) is defined as:\n\\[\nEVPPI(\\boldsymbol{\\pi}_z,\\lambda) = E_{\\boldsymbol{\\pi_z}} \\big [  \\max_{\\boldsymbol{\\alpha}} E_{\\boldsymbol{\\pi_{-z}}|\\boldsymbol{\\pi_z}}NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi}_z,\\boldsymbol{\\pi}_{-z},\\lambda) \\big ] -\n\\max E_{\\boldsymbol{\\pi}} \\big [ NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi},\\lambda) \\big ]\n\\tag{3}\\]\n\n\n\nBased on this exercise, we can calculate and plot the EVPPI value for each MVPF parameter for various \\(\\lambda\\) values:\n\n\nCode\nest_evppi &lt;- function(B ,C,pi,lambda) {\n    nwb_ &lt;- calc_nwb(B = B, C = C, lambda = lambda)\n    \n    evppi_2 &lt;- pmax(0,mean(nwb_))\n    \n    evppi &lt;- list()\n    \n    names(pi) %&gt;% \n        map(~{\n            z &lt;- pi[[.x]]\n            mm.fit &lt;- gam(nwb_ ~ te(z))\n            evppi_inner &lt;- pmax(0, mm.fit$fitted)\n            evppi_1 &lt;- mean(evppi_inner)\n            evppi[[.x]] &lt;- evppi_1 - evppi_2\n        }) %&gt;% \n        set_names(names(pi)) %&gt;% \n        unlist()\n\n}\n\nevppi_lambdas &lt;- \n    lambdas %&gt;% \n    map(~(est_evppi(B = delta_W, C = (delta_E - delta_C), pi = pi, lambda = .x))) %&gt;% \n    bind_rows() %&gt;% \n    mutate(lambda = lambdas)\ncolnames(evppi_lambdas) &lt;- gsub(\"delta_\",\"\",colnames(evppi_lambdas))\n\np2 &lt;- \n    evppi_lambdas %&gt;% \n    gather(z,value,-lambda) %&gt;% \n    mutate(z = gsub(\"delta_\",\"\",z)) %&gt;% \n    ggplot() + geom_line(aes(x = lambda, y = value, colour = z )) + \n    ggsci::scale_color_d3() + \n    theme_hc() + \n    theme(text = element_text(family = 'Arial')) +\n    labs(x = xlab, y = \"Value of Information (EVPI, EVPPI)\")\n\ndirect.label(p2,list(method = \"top.bumponce\" , fontface=\"bold\", fontfamily ='Arial'))\n\n\n\n\n\n\n\n\nFigure 2: Expected Value of Partial Perfect Information by Societal Willingness to Pay Value\n\n\n\n\n\nFigure 2 shows that for \\(\\lambda\\) values near 0.85, the parameter summarizing the welfare benefit of the policy has the highest (partial) information value—though the taxpayer benefit parameter (\\(C\\)) also has high information value, especially for higher \\(\\lambda\\) values."
  },
  {
    "objectID": "blog/posts/mvpf-evsi/mvpf-evsi.html#what-happens-with-different-lambda-values",
    "href": "blog/posts/mvpf-evsi/mvpf-evsi.html#what-happens-with-different-lambda-values",
    "title": "Welfare Analysis Meets Study Design",
    "section": "What Happens with Different \\(\\lambda\\) values?",
    "text": "What Happens with Different \\(\\lambda\\) values?\nThe exercise above was carried out with a single societal willingness-to-pay parameter value in mind (\\(\\lambda=0.85\\)) but it is straightforward to carry out same exercise for different \\(\\lambda\\) values.\n\n\nCode\np_evsi2 &lt;- \n    evsi %&gt;%\n    bind_rows(evsi2) %&gt;% \n  mutate(evppi = ifelse(lambda ==0.85, evppi_w, evppi_w2)) %&gt;% \n  mutate(lab = glue::glue(\".  {n} ({round(100*value/evppi,1)}%)\")) %&gt;% \n    ggplot(aes(x = n, y = value, colour = factor(lambda))) + geom_point() + geom_line() + theme_hc() + \n    ggsci::scale_color_d3()+\n    geom_hline(aes(yintercept = evppi_w), colour = \"darkred\") + geom_text(aes(label = lab,hjust=0)) + \n    geom_hline(aes(yintercept = evppi_w2), colour = \"darkred\") +\n    theme(legend.position = \"none\") +\n    labs(x = \"Experimental Sample Size\", y = \"Expected value of Sample Information (EVSI)\") + \n    annotate(\"text\",x = 0, y = evppi_w, label = glue::glue(\"EVPPI (lambda = 0.85): {round(evppi_w,2)}\"),vjust=-1,hjust=0, colour= \"darkred\") +\n   annotate(\"text\",x = 0, y = evppi_w2, label = glue::glue(\"EVPPI (lambda = 1.0): {round(evppi_w2,2)}\"),vjust=-1,hjust=-1, colour= \"darkred\") +\n    scale_y_continuous(expand = c(.25,0)) + theme(text = element_text(family = 'Arial')) +\n  scale_x_continuous(expand=expansion(mult = c(0, .35)),breaks = c(100,250, 500, 1000,2000, 5000, 10000),guide = guide_axis(n.dodge=3))\np_evsi2\n\n\n\n\n\n\n\n\nFigure 4: Expected Value of Sample Information (% of EVPPI) by Societal Willingness to Pay Value"
  },
  {
    "objectID": "blog/posts/mvpf-evppi/mvpf-evppi.html",
    "href": "blog/posts/mvpf-evppi/mvpf-evppi.html",
    "title": "Welfare Analysis Meets Research Prioritization",
    "section": "",
    "text": "Part two in a three-part series on how the tools of comparative welfare analysis can be used to refine and design prospective randomized evaluations."
  },
  {
    "objectID": "blog/posts/mvpf-evppi/mvpf-evppi.html#estimating-the-expected-value-of-partial-perfect-information",
    "href": "blog/posts/mvpf-evppi/mvpf-evppi.html#estimating-the-expected-value-of-partial-perfect-information",
    "title": "Welfare Analysis Meets Research Prioritization",
    "section": "Estimating the Expected Value of Partial Perfect Information",
    "text": "Estimating the Expected Value of Partial Perfect Information\nWe can estimate the EVPPI by drawing values from the joint uncertainty distributions of \\(W^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\) and \\(C^{\\text{inkind}}(\\mathbf{\\pi},\\alpha)\\).\nSpecifically, suppose we construct a \\(K\\)-sized sample of model outputs from a Monte Carlo-based exercise. That is, we draw sets of parameters \\(\\boldsymbol{\\pi}^{(1)},\\ldots,\\boldsymbol{\\pi}^{(K)}\\) and generate a \\(K\\)-sized vector of net welfare benefits for a given \\(\\lambda\\) value.\nThe code below samples the constituent pieces for the MVPF and NWB for \\(\\lambda=0.88\\):\n\nset.seed(23)\nK &lt;- 1e5\nlambda = 0.88\nw_inkind = rlnorm(K, log(1.2),0.1)\nfe_inkind = rnorm(K, 0.35,.02)\nc_inkind = 1+fe_inkind\nnwb_inkind = w_inkind - lambda * c_inkind\n\n\n\n\n\nAt \\(\\lambda = 0.88\\) the in-kind benefit passes the societal cost-benefit test, so implementation of the in-kind benefit (as compared with doing nothing) is the optimal strategy based on current information. Therefore, the second term in Equation 3 (i.e., \\(E_{\\boldsymbol{\\pi}}[NWB(\\alpha^*,\\boldsymbol{\\pi},\\lambda)]\\)) is simply the average NWB of the in-kind benefit:\n\nevppi_2 &lt;- pmax(0,mean(nwb_inkind))\nevppi_2\n\n[1] 0.01831933\n\n\nEstimation of the conditional expectation in the first term in equation Equation 3 is less straightforward. Borrowing from the approach in Strong, Oakley, and Brennan (2014), we can express the NWB outcome as the sum of a conditional expectation plus a mean-zero error term:\n\\[\nNWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi^{(k)}},\\lambda)  =  E_{\\boldsymbol{\\pi_{-z}}|\\boldsymbol{\\pi_z}=\\boldsymbol{\\pi_z}^{(k)}}NWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi}_z^{(k)},\\boldsymbol{\\pi}_{-z},\\lambda)  + \\epsilon^{(k)}\n\\tag{4}\\]\nIn addition, the expectation in equation Equation 4 can be thought of in terms of an unknown function \\(g(\\cdot)\\) of \\(\\boldsymbol{\\pi_z}\\):\n\\[\nNWB(\\boldsymbol{\\alpha},\\boldsymbol{\\pi^{(k)}},\\lambda)  = g(\\boldsymbol{\\alpha},\\boldsymbol{\\pi}_z^{(k)},\\lambda) + \\epsilon^{(k)}\n\\tag{5}\\]\nBased on equation Equation 5, one option is to estimate the conditional expectation using a “metamodel,” or a regression model predicting how the net welfare benefit for a particular policy varies with unknown parameters of interest \\(\\boldsymbol{\\pi}_z\\). For example, a metamodel might specify the function \\(g(\\cdot)\\) as a standard linear regression. Alternatively, we might not wish to impose a functional form and instead estimate \\(g(\\cdot)\\) nonparametrically.3\n3 If we suspect the underlying relationships have important nonlinearities in the parameters of interest, we could also appeal to machine learning methods to estimate \\(g(\\cdot)\\).4 In our running example, we have a scalar value for welfare benefits and costs, so the metamodels end up being quite simple in structure. In principle, however, multiple parameters might inform the overall welfare cost or benefit values—in which case we could think of estimating metamodels separately for each, or combine them all into a single metamodel with interaction terms, etc. to capture dependencies or nonlinearities among them in determining the overall welfare benefit or cost value.The code below estimates basic metamodels separately for welfare benefits and costs using a generalized additive model:4\n\n# Metamodel for welfare benefits\ngam.w &lt;- gam(nwb_inkind ~ w_inkind)\n\n# Metamodel for welfare costs\ngam.c &lt;- gam(nwb_inkind ~ c_inkind)\n\nBecause we are comparing the in-kind benefit policy to doing nothing (i.e., a policy with zero-valued welfare costs and benefits), the inner (square bracketed) term of the first term in Equation 3 can be estimated by taking the maximum of 0 and the predicted values from the metamodels:\n\nevppi_w_inner &lt;-pmax(0,gam.w$fitted)\nevppi_c_inner &lt;-pmax(0,gam.c$fitted)\n\nThe outer expectation of the first term in Equation 3 is estimated using the average across the \\(K\\) probabilistic draws:\n\nevppi_w_1 = mean(evppi_w_inner)\nevppi_c_1 = mean(evppi_c_inner)\n\nAnd finally, the EVPPI for welfare costs and benefits is estimated by the difference:\n\nevppi_w = evppi_w_1 - evppi_2\nevppi_c = evppi_c_1 - evppi_2\n\nc(\"EVPPI_W\" = evppi_w, \n  \"EVPPI_C\" = evppi_c)\n\n    EVPPI_W     EVPPI_C \n0.038941735 0.001417349 \n\n\nFrom these estimates of the EVPPI we would conclude that the component of \\(\\mathbf{\\pi}\\) with the highest information value is \\(W(\\boldsymbol{\\pi},\\alpha)\\)."
  },
  {
    "objectID": "blog/posts/mvpf-evppi/mvpf-evppi.html#next-steps",
    "href": "blog/posts/mvpf-evppi/mvpf-evppi.html#next-steps",
    "title": "Welfare Analysis Meets Research Prioritization",
    "section": "Next Steps",
    "text": "Next Steps\nA this point we have:\n\nExplored the range of current knowledge to ascertain whether future research could help a policymaker’s decision to pursue an in-kind benfefit transfer program.\nDecomposed the value of information to identify the parameters with highest decision leverage.\n\nAs mentioned above, however, our estimates of the value of information are based on a theoretical exercise under which we obtain perfect information on uncertain parameters. In practice, however, we do not have unlimited resources to reduce information uncertainty to zero; we must weigh the costs and benefits of sampling the population—perhaps by carrying out a randomized evaluation of the in-kind benefit transfer—to obtain better, but not perfect, information.\nThe next post in this series will explore different study designs so that we can optimally design a randomized evaluation in such a way as to efficiently gain information to inform the decision."
  },
  {
    "objectID": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html",
    "href": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html",
    "title": "Bounds Under Exogenous Treatment Assignment",
    "section": "",
    "text": "Code\nparams &lt;- \n  list(\n    N = 2e3,\n    sigma_sq_X = 1.0,\n    sigma_sq_epsilon = 0.3,\n    delta = 0.5\n  )\nparams &lt;- with(params,\n               modifyList(params,list(\n                 r_squared = 1 - sigma_sq_epsilon,\n                 beta = sqrt(1 - sigma_sq_epsilon),\n                 Sigma = matrix(c(sigma_sq_X,0,0,sigma_sq_epsilon),\n                                byrow=TRUE, nrow = 2, ncol = 2))))\n\ngen_data &lt;- function(params) {\n  with(params, \n       mvrnorm(n = N, mu = c(0,0), Sigma = Sigma)) %&gt;% \n    data.frame() %&gt;% \n    as_tibble() %&gt;% \n    set_names(c(\"X\",\"epsilon\")) %&gt;% \n    mutate(Y_i0 = params$beta * X + epsilon) %&gt;% \n    mutate(Y_i1 = Y_i0 + params$delta) %&gt;% \n    mutate(random = runif(nrow(.))) %&gt;% \n    mutate(D = as.integer(row_number()&lt;=(params$N)/2)) %&gt;% \n    arrange(random) %&gt;% \n    select(-random) %&gt;% \n    mutate(Y = D * Y_i1 + (1 - D) * Y_i0) %&gt;% \n    select(Y,D,X)\n}\n\nset.seed(123)\ndf &lt;- params %&gt;% gen_data()\n\ndf %&gt;% head(n=10) %&gt;% kable() %&gt;% \n    kable_styling()\n\n\n\n\nTable 1: First 10 rows of data\n\n\n\n\n\n\nY\nD\nX\n\n\n\n\n0.636525\n0\n1.136893\n\n\n-1.017545\n0\n-1.143835\n\n\n-2.660006\n0\n-1.769366\n\n\n-0.234232\n0\n-1.314321\n\n\n-1.052531\n1\n-1.236676\n\n\n-0.082499\n0\n-1.321069\n\n\n1.284970\n1\n1.516068\n\n\n0.271550\n1\n0.246692\n\n\n-0.690019\n0\n-1.433008\n\n\n-0.084229\n0\n-0.229395"
  },
  {
    "objectID": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#lower-bounds",
    "href": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#lower-bounds",
    "title": "Bounds Under Exogenous Treatment Assignment",
    "section": "Lower Bounds",
    "text": "Lower Bounds"
  },
  {
    "objectID": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#upper-bounds",
    "href": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#upper-bounds",
    "title": "Bounds Under Exogenous Treatment Assignment",
    "section": "Upper Bounds",
    "text": "Upper Bounds\n\nCalculate the lower bound values\nThis code turns the lower bound quantile values into an empirical CDF object.\nCalculate the upper bound values\nThis code turns the lower bound quantile values into an empirical CDF object.\n\nNow let’s look at the bounds for the quantile of the Treated Effect on the Treated (QoTT), i.e., the bounds on various quantiles of the treatment effect distribution.\n\n\nCode\nqwdu &lt;- quantile(F.wd.l, tau, type=1)\nqwdl &lt;- quantile(F.wd.u, tau, type=1)\n\ndf_wd &lt;- \n  data.frame(tau = c(tau,tau), bound = c(qwdu,qwdl), type=c(rep(\"upper\",length(qwdu)),rep(\"lower\",length(qwdl)))) %&gt;% \n  mutate(method =\"Worst-Case\\n[Williamson-Downs (1990)]\") %&gt;% \n  mutate(label = ifelse(type==\"upper\",\"Worst-Case\\n[Williamson-Downs (1990)]\",\"\")) \n\ncol_scheme &lt;- c(\"#FF5733\" ) # Williamson and Downs\n\ndf_wd %&gt;% \n  mutate(type = paste0(type,method)) %&gt;% \n  ggplot(aes(x = tau, y = bound, group = type, colour = method)) + \n  geom_line(lwd=1.25) + \n  geom_hline(aes(yintercept = params$delta), colour = \"darkred\",lwd=1.25) + \n  scale_color_manual(values = col_scheme) + \n  geom_dl(method = list(\"last.points\",hjust=1),aes(label = label)) +\n  scale_x_continuous(breaks = seq(0,1,0.1)) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\",x = 0.5, y = params$delta, label = \"True Treatment Effect\",vjust=-1,colour = \"darkred\") + \n  scale_y_continuous(limits = c(-5,5),breaks = seq(-5,5,1))\n\n\n\n\n\n\n\n\nFigure 1: Worst-Case (Williamson and Downs [1990]) Bounds"
  },
  {
    "objectID": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#incorporating-covariates",
    "href": "blog/drafts/partial-ID-experimental/partial-ID-experimental.html#incorporating-covariates",
    "title": "Bounds Under Exogenous Treatment Assignment",
    "section": "Incorporating Covariates",
    "text": "Incorporating Covariates\n\\(F_{\\Delta \\mid Y(0), X}^L(t \\mid Y(0), X):= \\begin{cases}0, & Y(0)+t&lt;\\tilde{Y}(1 \\mid X), \\\\ \\frac{F_{1 \\mid X}(Y(0)+t \\mid X)-F_{0 \\mid X}(Y(0) \\mid X)}{1-F_{0 \\mid X}(Y(0) \\mid X)}, & Y(0)+t \\geq \\tilde{Y}(1 \\mid X),\\end{cases}\\)\n\\(F_{\\Delta \\mid Y(0), X}^U(t \\mid Y(0), X):= \\begin{cases}\\frac{F_{1 \\mid X}(Y(0)+t \\mid X)}{F_{0 \\mid X}(Y(0) \\mid X)}, & Y(0)+t \\leq \\tilde{Y}(1 \\mid X) \\\\ 1, & Y(0)+t \\geq \\tilde{Y}(1 \\mid X)\\end{cases}\\)\n\\(\\begin{aligned} & F_{\\Delta \\mid Y(d)}^L(t \\mid Y(d))=E\\left[F_{\\Delta \\mid Y(d), X}^L(t \\mid Y(d), X) \\mid Y(d)\\right] \\\\ & F_{\\Delta \\mid Y(d)}^U(t \\mid Y(d))=E\\left[F_{\\Delta \\mid Y(d), X}^U(t \\mid Y(d), X) \\mid Y(d)\\right]\\end{aligned}\\)\n\\(\\begin{aligned} & \\Delta^L(Y(d))=\\int t d F_{\\Delta \\mid Y(d)}^U(t \\mid Y(d)) \\\\ & \\Delta^U(Y(d))=\\int t d F_{\\Delta \\mid Y(d)}^L(t \\mid Y(d))\\end{aligned}\\)\n\\(\\begin{aligned} & \\hat{F}_{\\Delta \\mid 0, X}^L\\left(t \\mid Y_j(0), X_j\\right):=\\max \\left\\{0, \\frac{\\hat{F}_{1 \\mid X}\\left(Y_j(0)+t \\mid X_j\\right)-\\hat{F}_{0 \\mid X}\\left(Y_j(0) \\mid X_j\\right)}{1-\\hat{F}_{0 \\mid X}\\left(Y_j(0) \\mid X_j\\right)}\\right\\} \\\\ & \\hat{F}_{\\Delta \\mid 0, X}^U\\left(t \\mid Y_j(0), X_j\\right):=\\min \\left\\{1, \\frac{\\hat{F}_{1 \\mid X}\\left(Y_j(0)+t \\mid X_j\\right)}{\\hat{F}_{0 \\mid X}\\left(Y_j(0) \\mid X_j\\right)}\\right\\} .\\end{aligned}\\)\n\ni1 &lt;-  # index of treated observations\n  df %&gt;% \n  mutate(i = row_number()) %&gt;% \n  filter(D==1) %&gt;% \n  pull(i)\n\ni0 &lt;-  # index of untreated observations\n  df %&gt;% \n  mutate(i = row_number()) %&gt;% \n  filter(D==0) %&gt;% \n  pull(i)\n\nX1 &lt;- # X values of treated observations\n  df %&gt;%\n  filter(D==1) %&gt;%\n  pull(X)\n\nX0 &lt;- # X values of untreated observations\n  df %&gt;% \n  filter(D==0) %&gt;% \n  pull(X)\n\nWe next create conditional CDFs, with a different CDF constructed for each untreated group \\(X\\) value.\nThe short way uses parametric quantile regression (rq()). This specification assumes a model that is linear in parameters.\n\ntaus0 &lt;- sort(ecdf(y0)(y0))\nquantreg_fit &lt;- quantreg::rq(Y ~ X, tau = taus0, data = df %&gt;% filter(D==0))\npvals &lt;- predict(quantreg_fit,newdata = data.frame(X=X0), stepfun=TRUE)\nhatF0X &lt;- pvals %&gt;% map(~(.x(taus0))) %&gt;% \n  map(~(BMisc::makeDist(.x,taus0)))\n\n\ntaus1 &lt;- sort(ecdf(y1)(y1))\nquantreg_fit &lt;- quantreg::rq(Y ~ X, tau = taus0, data = df %&gt;% filter(D==1))\npvals &lt;- predict(quantreg_fit,newdata = data.frame(X=X0), stepfun=TRUE)\nhatF1X &lt;- pvals %&gt;% map(~(.x(taus0))) %&gt;% \n  map(~(BMisc::makeDist(.x,taus0)))\n\nA (much) longer, but nonparametric approach, is to fit a nonparametric regression. In this example code, we fit a generalized additive model (GAM) with a logit link (for the constructed binary outcome needed to estimate the CDF).Note that the treatment effect bounds calcualted under a GAM vs. a parametric quantile regression approach for the condtiional CDFs are nearly identical in this example—though this will not generally be true!\n\n\nCode\n# This version constructs a full CDF for each X value\npb &lt;- progress_bar$new(total = length(y0))\nhatF0X &lt;-\n  map(X0, ~({\n    # for each untreated observation j\n    xx = .x\n    pb$tick()\n    hatF0X_ &lt;-\n      y_ %&gt;% map_dbl( ~({\n        yy = .x\n        # nonparameterically regress an indicator Y_i &lt;= Y_j on X_i in the untreated subsample\n        IY = as.integer(df$Y[i0] &lt;= yy)\n        X &lt;- X0\n        dat &lt;- cbind.data.frame(IY, X) %&gt;%\n          set_names(c(\"IY\", \"X\"))\n        \n        fit &lt;- gam(IY ~ s(X), data = dat, family = \"binomial\")\n        # construct predicted value\n        predict(fit, newdata = data.frame(X = xx), type = \"response\")\n        \n      })) %&gt;%\n      BMisc::makeDist(y_, .) # make this into an ecdf \n    \n    hatF0X_\n  }))\nwrite_rds(hatF0X,\"posts/extending-the-toolkit-experimental/results/hatF0X.rds\")\n\npb &lt;- progress_bar$new(total = length(X0))\nhatF1X &lt;-\n  map(X0, ~ ({\n    # for each untreated observation j\n    xx = .x\n    pb$tick()\n    hatF1X_ &lt;-\n      y_ %&gt;% map_dbl( ~ ({\n        yy = .x\n        # nonparameterically regress an indicator Y_i &lt;= Y_j on X_i in the treated subsample\n        IY = as.integer(df$Y[i1] &lt;= yy)\n        X &lt;- X1\n        dat &lt;- cbind.data.frame(IY, X) %&gt;%\n          set_names(c(\"IY\", \"X\"))\n        \n        fit &lt;- gam(IY ~ s(X), data = dat, family = \"binomial\")\n        # construct predicted value\n        predict(fit, newdata = data.frame(X = xx), type = \"response\")\n        \n      })) %&gt;%\n      BMisc::makeDist(y_, .) # make this into an ecdf\n    hatF1X_\n  }))\nwrite_rds(hatF1X,\"posts/extending-the-toolkit-experimental/results/hatF1X.rds\")\n\n\nWe next plug these condtiional CDFs into the formulas to obtain the CDF of the treatment effect bounds.\n\n\nCode\npb &lt;- progress_bar$new(total = length(delta_))\nF_l_flX_ &lt;- \n  delta_ %&gt;% map(~{ # outer loop is over possible values of the treatment effect\n    delt &lt;- .x\n    pb$tick()\n      map2_dbl(y0,X0,~({\n        y0_ = .x \n        xx_ = .y\n        i = which(X0==xx_); i\n        F1_fl_tmp &lt;- hatF1X[[i]]\n        F0_fl_tmp &lt;- hatF0X[[i]]\n        (F1_fl_tmp(y0_ + delt)-F0_fl_tmp(y0_))/(1-F0_fl_tmp(y0_))\n      }))  %&gt;% \n      map_dbl(~(max(0,.x,na.rm=TRUE))) %&gt;% \n      mean(.)\n  }) %&gt;% \n  unlist()\n# Make it into a proper eCDF object.\nF.flX.l &lt;- approxfun(delta_,  F_l_flX_, method = \"constant\", yleft = 0, yright = 1, \n                    f = 0, ties = \"ordered\")\nclass(F.flX.l) &lt;- c(\"ecdf\", \"stepfun\", class(F.flX.l))\nassign(\"nobs\", length(delta_), envir = environment(F.flX.l))\n\npb &lt;- progress_bar$new(total = length(delta_))\nF_u_flX_ &lt;- \n  delta_ %&gt;% \n  map(~{ # outer loop is over possible values of the treatment effect\n    delt &lt;- .x\n    pb$tick()\n    \n      map2_dbl(y0,X0,~({\n        y0_ = .x \n        xx_ = .y\n        i = which(X0==xx_); i\n        F1_fl_tmp &lt;- hatF1X[[i]]\n        F0_fl_tmp &lt;- hatF0X[[i]]\n        \n        (F1_fl_tmp(y0_+delt))/(F0_fl_tmp(y0_))\n      }))  %&gt;% \n      map_dbl(~(min(1,.x,na.rm=TRUE))) %&gt;% \n      mean(.)\n  }) %&gt;% \n  unlist()\n# Make it into a proper eCDF object. \nF.flX.u &lt;- approxfun(delta_,  F_u_flX_, method = \"constant\", yleft = 0, yright = 1, \n                    f = 0, ties = \"ordered\")\nclass(F.flX.u) &lt;- c(\"ecdf\", \"stepfun\", class(F.flX.u))\nassign(\"nobs\", length(delta_), envir = environment(F.flX.u))\n\n\nFirst, let’s take a look at bounds on various quantiles of the treatment effect (QoTT):\n\n\nCode\nqflXu &lt;- quantile(F.flX.l, tau, type=1)\nqflXl &lt;- quantile(F.flX.u, tau, type=1)\n\ndf_flX &lt;- \n  data.frame(tau = c(tau,tau), bound = c(qflXu,qflXl), type=c(rep(\"upper\",length(qflXu)),rep(\"lower\",length(qflXl)))) %&gt;% \n  mutate(method = \"Frandsen & Lefgrens (2021) Covariates\") %&gt;% \n  mutate(label = ifelse(type==\"upper\",\"Frandsen & Lefgrens (2021)\\nWith Covariates\",\"\")) \n\n\n\n\nCode\ncol_scheme &lt;- c(\"#0A2E36\" ,# Frandsen & Lefgrens (No X)\n                \"#7DC4CC\", # Frandsen & Lefgrens (X)\n                \"#FF5733\" ) # Williamson and Downs\n\ndf_fl %&gt;% \n  bind_rows(df_flX) %&gt;% \n  bind_rows(df_wd) %&gt;%  \n  mutate(method = factor(method, levels = c(\"Frandsen & Lefgrens (2021)\"     ,       \"Frandsen & Lefgrens (2021) Covariates\", \"Worst-Case\\n[Williamson-Downs (1990)]\"))) %&gt;% \n  mutate(type = paste0(type,method)) %&gt;% \n  ggplot(aes(x = tau, y = bound, group = type, colour = method)) + \n  geom_line(lwd=1.25) + \n  geom_hline(aes(yintercept = params$delta), colour = \"darkred\",lwd=1.25) + \n  scale_color_manual(values=col_scheme) + \n  geom_dl(method = list(\"last.points\",hjust=1),aes(label = label)) +\n  scale_x_continuous(breaks = seq(0,1,0.1)) +\n  theme(legend.position = \"none\") +\n  annotate(\"text\",x = 0.5, y = params$delta, label = \"True Treatment Effect\",vjust=-1,colour = \"darkred\") + \n  scale_y_continuous(limits = c(-5,5),breaks = seq(-5,5,1))\n\n\n\n\n\n\n\n\nFigure 3: Treatment Effect Distribution Bounds with Covariates"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html",
    "href": "blog/drafts/transfinite/transfinite.html",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "",
    "text": "We have defined our underlying model (either from bottom up or through backwards conversion) but need to define PSA distributions for model parameters.\nModel draws on literature-based parameters that are reported as means, standard deviations, interquartile ranges, 95% confidence intervals, etc."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#a-common-issue",
    "href": "blog/drafts/transfinite/transfinite.html#a-common-issue",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "",
    "text": "We have defined our underlying model (either from bottom up or through backwards conversion) but need to define PSA distributions for model parameters.\nModel draws on literature-based parameters that are reported as means, standard deviations, interquartile ranges, 95% confidence intervals, etc."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#a-common-issue-1",
    "href": "blog/drafts/transfinite/transfinite.html#a-common-issue-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "A Common Issue",
    "text": "A Common Issue\n\nStraightforward to obtain base case values from literature.\nBut how can we define PSA distributions based on limited information?"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#psa-distributions",
    "href": "blog/drafts/transfinite/transfinite.html#psa-distributions",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "PSA Distributions",
    "text": "PSA Distributions\n\n\n\nParameter Type\nDistribution\n\n\n\n\nProbability\nbeta\n\n\nRate\ngamma\n\n\nUtility weight\nbeta\n\n\nRight skew (e.g., cost)\ngamma, lognormal\n\n\nRelative risks or hazard ratios\nlognormal\n\n\nOdds Ratio\nlogistic"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#example",
    "href": "blog/drafts/transfinite/transfinite.html#example",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Example",
    "text": "Example\n\nCost parameter reported in literature has interquartile range of $300-$750.\nWhat are the parameters of a PSA distribution such that the 25th percentile is $300 and the 75th percentile is $750?"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#some-options",
    "href": "blog/drafts/transfinite/transfinite.html#some-options",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Some Options",
    "text": "Some Options\n\nAnalytic formulas for some distributions (normal, gamma, beta).\nFormulas take as their inputs the two values (\\(x_1\\), \\(x_2\\)) and their associated quantiles (\\(p_1\\),\\(p_2\\)).\nFormulas return the PSA distribution parameters that match up to these values."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#some-options-1",
    "href": "blog/drafts/transfinite/transfinite.html#some-options-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Some Options",
    "text": "Some Options\n\nParameterSolver implemented in Windows, Link\nSee Cook (2010) and Vasco Grilo’s blog post for more.\nThe next few slides provide you with nearly all the tools you’ll need, however."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#example-cost-psa-distribution",
    "href": "blog/drafts/transfinite/transfinite.html#example-cost-psa-distribution",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Example: Cost PSA Distribution",
    "text": "Example: Cost PSA Distribution\n\nSuppose the interquartile range for a key cost variable is [300,750]\nWe may have obtained this from the literature, from tabulating cost data, or from expert opinions."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#example-cost-psa-distribution-1",
    "href": "blog/drafts/transfinite/transfinite.html#example-cost-psa-distribution-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Example: Cost PSA Distribution",
    "text": "Example: Cost PSA Distribution\n\n\nSuppose the interquartile range for a key cost variable is [300,750]\nWe may have obtained this from the literature, from tabulating cost data, or from expert opinions.\n\n\n\nx1 = 300\np1 = 0.25\n\nx2 = 750\np2 = 0.75"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Uniform PSA",
    "text": "Analytic Solution: Uniform PSA\nFor a uniform distribution with minimum \\(a\\) and maximum \\(b\\)\n\\[\na = \\frac{p_2x_1 - p_1x_2}{p_2-p_1}\n\\] \\[\nb = \\frac{(1-p_1)x_2-(1-p_2)x_1}{p_2-p_1}\n\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa-1",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Uniform PSA",
    "text": "Analytic Solution: Uniform PSA\n\na = ((p2*x1) - (p1 * x2)) / (p2 - p1)\na\n\n[1] 75\n\nb = ((1 - p1)*x2 - (1 - p2)*x1) / (p2 - p1)\nb\n\n[1] 975"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa-2",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-uniform-psa-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Uniform PSA",
    "text": "Analytic Solution: Uniform PSA\n\nqunif(0.25, min = 75, max = 975)\n\n[1] 300\n\nqunif(0.75, min = 75, max = 975)\n\n[1] 750"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Normal PSA",
    "text": "Analytic Solution: Normal PSA\n\\[\n\\sigma = \\frac{x_2 - x_1}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]\n\\[\n\\mu = \\frac{x_1\\Phi^{-1}(p_2)-x_2\\Phi^{-1}(p_1)}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa-1",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Normal PSA",
    "text": "Analytic Solution: Normal PSA\n\nmu = (qnorm(p2)*x1 - qnorm(p1)*x2) / (qnorm(p2)-qnorm(p1))\nmu\n\n[1] 525\n\nsigma = (x2 - x1) / (qnorm(p2) - qnorm(p1))\nsigma\n\n[1] 333.5855"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa-2",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-normal-psa-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Normal PSA",
    "text": "Analytic Solution: Normal PSA\n\nqnorm(0.25, mean = 525, sd = 333.59)\n\n[1] 299.997\n\nqnorm(0.75, mean = 525, sd = 333.59)\n\n[1] 750.003"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Lognormal PSA",
    "text": "Analytic Solution: Lognormal PSA\n\nJust take log of \\(x_1\\) and \\(x_2\\)\n\n\\[\n\\sigma = \\frac{\\ln(x_2) - \\ln(x_1)}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]\n\\[\n\\mu = \\frac{\\ln(x_1)\\Phi^{-1}(p_2)-\\ln(x_2)\\Phi^{-1}(p_1)}{\\Phi^{-1}(p_2)-\\Phi^{-1}(p_1)}\n\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa-1",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Lognormal PSA",
    "text": "Analytic Solution: Lognormal PSA\n\nmu = (qnorm(p2)*log(x1) - qnorm(p1)*log(x2)) / (qnorm(p2)-qnorm(p1))\nmu\n\n[1] 6.161928\n\nsigma = (log(x2) - log(x1)) / (qnorm(p2) - qnorm(p1))\nsigma\n\n[1] 0.6792473"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa-2",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-lognormal-psa-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Lognormal PSA",
    "text": "Analytic Solution: Lognormal PSA\n\nqlnorm(0.25, mean = 6.1619, sd = 0.67925)\n\n[1] 299.9911\n\nqlnorm(0.75, mean = 6.1619, sd = 0.67925)\n\n[1] 749.9805"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\nA bit more involved as it involves finding the root of a function."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-1",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\n\nA bit more involved as it involves finding the root of a function.\n\n\n\ngamma_fn &lt;- function(alpha) {\n    x1*qgamma(p2,shape = alpha, scale =1) - x2 * qgamma(p1, shape = alpha, scale = 1)\n}\ncurve(gamma_fn, xlim = c(1,10), col = \"blue\", lwd = 1.5, lty=2)\nabline(a=0,b=0)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-2",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\n\nRoot (i.e., point where the function crosses the zero line) seems to be between 2 and 4.\n\n\n\ngamma_fn &lt;- function(alpha) {\n    x1*qgamma(p2,shape = alpha, scale =1) - x2 * qgamma(p1, shape = alpha, scale = 1)\n}\ncurve(gamma_fn, xlim = c(1,10), col = \"blue\", lwd = 1.5, lty=2)\nabline(a=0,b=0)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-3",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-3",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\n\nWe’ll search in this range for our \\(\\alpha\\) value.\n\n\n\ngamma_fn &lt;- function(alpha) {\n    x1*qgamma(p2,shape = alpha, scale =1) - x2 * qgamma(p1, shape = alpha, scale = 1)\n}\ncurve(gamma_fn, xlim = c(1,10), col = \"blue\", lwd = 1.5, lty=2)\nabline(a=0,b=0)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-4",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-4",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\nalpha_ &lt;- uniroot(gamma_fn,c(2,4))$root\nalpha_\n\n[1] 2.455801\n\ncalc_beta &lt;- function(x1,p1,alpha) {\n    x1 / qgamma(p1,alpha,1)\n}\n\nbeta_ &lt;- calc_beta(x1 = x1,  p1 = p1, alpha = alpha_)\nbeta_\n\n[1] 230.1627"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-5",
    "href": "blog/drafts/transfinite/transfinite.html#analytic-solution-gamma-psa-5",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Analytic Solution: Gamma PSA",
    "text": "Analytic Solution: Gamma PSA\n\nqgamma(0.25,shape = 2.4558, scale = 230.16)\n\n[1] 299.9963\n\nqgamma(0.75,shape = 2.4558, scale = 230.16)\n\n[1] 749.9956"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#alternative-optimization",
    "href": "blog/drafts/transfinite/transfinite.html#alternative-optimization",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Alternative: Optimization",
    "text": "Alternative: Optimization\n\n\nGeneral solution that can be used to solve for parameters of many common PSA distributions (e.g., beta, gamma, etc.).\n\n\n\\[\\min_{\\vec{\\theta} \\in R}\\,\\, (F(x_1|\\vec{\\theta})-p_1)^2+(F(x_2|\\vec{\\theta})-p_2)^2\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#alternative-optimization-1",
    "href": "blog/drafts/transfinite/transfinite.html#alternative-optimization-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Alternative: Optimization",
    "text": "Alternative: Optimization\n\nRequires cumulative distribution function (CDF), \\(F\\).\nSee Hans W Borchers’ great slides for tips on optimization in R."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#some-advice",
    "href": "blog/drafts/transfinite/transfinite.html#some-advice",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Some Advice",
    "text": "Some Advice\n\nWe have found that while analytically correct, this optimization formula is not numerically stable.\nTransfinite scaling of the probabilities from CDFs \\(F(.)\\) stabilizes optimization."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#some-advice-1",
    "href": "blog/drafts/transfinite/transfinite.html#some-advice-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Some Advice",
    "text": "Some Advice\n\n\nWe have found that while analytically correct, this optimization formula is not numerically stable.\nTransfinite scaling of the probabilities from CDFs \\(F(.)\\) stabilizes optimization.\n\\(g(F(.))\\) vs. \\(F(.)\\)\n\n\n\\[\\min_{\\vec{\\theta} \\in R}\\,\\, (g(F(x_1|\\vec{\\theta}))-p_1)^2+(g(F(x_2|\\vec{\\theta}))-p_2)^2\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#stable-optimization",
    "href": "blog/drafts/transfinite/transfinite.html#stable-optimization",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Stable Optimization",
    "text": "Stable Optimization\n\nFor probabilities, this is the \\(\\text{logit}(p)=\\log \\frac{p}{1-p}=\\log p - \\log (1-p)\\).\nTweaking parameters to converge can still happen.\nExample of theory versus practice."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#stable-optimization-1",
    "href": "blog/drafts/transfinite/transfinite.html#stable-optimization-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Stable Optimization",
    "text": "Stable Optimization\n\n\nFor probabilities, this is the \\(\\text{logit}(p)=\\log \\frac{p}{1-p}=\\log p - \\log (1-p)\\).\nTweaking parameters to converge can still happen.\nExample of theory versus practice.\n\n\n\\[\\min_{\\vec{\\theta} \\in R} \\sum_{i \\in 1,2}\\,\\, (\\text{logit} (F(x_i|\\vec{\\theta}))-\\text{logit} (p_i))^2\\]"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#transfinite-example-part-1",
    "href": "blog/drafts/transfinite/transfinite.html#transfinite-example-part-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Transfinite Example, Part 1",
    "text": "Transfinite Example, Part 1\n\n# Transfinite scaling\nTf &lt;- function(x, shape, rate)\n    pgamma(x,shape,rate,log=TRUE) - \n    pgamma(x,shape,rate,log=TRUE, lower.tail = FALSE)\n\n# Function to minimize\nnorm &lt;- function(x1, p1, x2, p2, shape,rate)\n    (Tf(x1, shape, rate)-(log(p1)-log(1-p1)) )^2 +\n    (Tf(x2, shape, rate)-(log(p2)-log(1-p2)) )^2\n\n# Bundle it all together into a single function.\nfn &lt;- function(x) norm(x1, p1, x2, p2, x[1], x[2])"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#transfinite-example-part-2",
    "href": "blog/drafts/transfinite/transfinite.html#transfinite-example-part-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Transfinite Example, Part 2",
    "text": "Transfinite Example, Part 2\n\n# Run general-purpose optimization on the function.\ngamma_optim &lt;- \n  optim(c(0.5, 0.1), # initial parameter guesses\n    fn,\n    gr = function(x) pracma::grad(fn, x),\n    lower=c(-Inf, 1e-5),\n    method = \"L-BFGS-B\",\n    control=list(factr=1e-10, maxit=100))$par\n\n# Note: gamma_optim$par[2] is 1/beta\ngamma_optim\n\n[1] 2.455855553 0.004344879"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#transfinite-example",
    "href": "blog/drafts/transfinite/transfinite.html#transfinite-example",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Transfinite Example",
    "text": "Transfinite Example\n\n\nOptimization returns \\(\\alpha\\) and \\(1/\\beta\\) for the gamma distribution example.\n\n\n\n# Analytic formula\nalpha_\n\n[1] 2.455801\n\n# Optimization\ngamma_optim[[1]]\n\n[1] 2.455856\n\n\n\n# Analytic formula\nbeta_\n\n[1] 230.1627\n\n# Optimization\n1/gamma_optim[[2]]\n\n[1] 230.156"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions",
    "href": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Optimization for Other Distributions",
    "text": "Optimization for Other Distributions\n\nJust swap in the distribution function for the distribution you want to match to (e.g., pbeta rather than pgamma).\nAlso make sure the supplied parameter names match the distribution you’re aiming for."
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions-1",
    "href": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions-1",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Optimization for Other Distributions",
    "text": "Optimization for Other Distributions\n\n\nJust swap in the distribution function for the distribution you want to match to (e.g., pbeta rather than pgamma).\nAlso make sure the supplied parameter names match the distribution you’re aiming for.\n\n\n\nTf &lt;- function(x, shape, rate)\n    pgamma(x,shape,rate,log=TRUE) - \n    pgamma(x,shape,rate,log=TRUE, lower.tail = FALSE)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions-2",
    "href": "blog/drafts/transfinite/transfinite.html#optimization-for-other-distributions-2",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Optimization for Other Distributions",
    "text": "Optimization for Other Distributions\n\n\nJust swap in the distribution function for the distribution you want to match to (e.g., pbeta rather than pgamma).\nAlso make sure the supplied parameter names match the distribution you’re aiming for.\n\n\n\nTf &lt;- function(x, shape, rate)\n    pgamma(x,shape,rate,log=TRUE) - \n    pgamma(x,shape,rate,log=TRUE, lower.tail = FALSE)"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#a-web-based-shiny-tool",
    "href": "blog/drafts/transfinite/transfinite.html#a-web-based-shiny-tool",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "A Web-Based Shiny Tool",
    "text": "A Web-Based Shiny Tool\nhttps://yuhanxuan.shinyapps.io/shiny4dist/\nAuthor: Hanxuan (Astrid) Yu"
  },
  {
    "objectID": "blog/drafts/transfinite/transfinite.html#summary-on-distribution-fitting",
    "href": "blog/drafts/transfinite/transfinite.html#summary-on-distribution-fitting",
    "title": "Solving for Probabilistic Sensitivity Analysis Parameter Values",
    "section": "Summary on Distribution Fitting",
    "text": "Summary on Distribution Fitting\n\nUse analytical formulas if they exist.\nOptimize on \\(\\text{logit}\\) scale.\nAgain, avoid \\(\\log\\) on probabilities, use log=TRUE.\nPlot results for visual check."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome\nThe Vanderbilt Center for Health Economic Modeling was launched in 2020 to harness the diverse, internationally-recognized expertise of Vanderbilt researchers in modeling the health and economic consequences of health policy and technology changes worldwide.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStructuring Markov Models for Multidimensional Health Outcomes\n\n\n\nCEA\n\n\n\n\n\n\n\nJohn Graves\n\n\nDec 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisability-Adjusted Life Years for Policy and Decision Analysis\n\n\n\nCEA\n\n\n\n\n\n\n\nJohn Graves\n\n\nDec 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Study Design\n\n\n\nCEA\n\n\nMVPF\n\n\n\n\n\n\n\nJohn Graves\n\n\nNov 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Decision Theory\n\n\n\nCEA\n\n\nMVPF\n\n\n\n\n\n\n\nJohn Graves\n\n\nNov 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelfare Analysis Meets Research Prioritization\n\n\n\nCEA\n\n\nMVPF\n\n\n\n\n\n\n\nJohn Graves\n\n\nNov 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]