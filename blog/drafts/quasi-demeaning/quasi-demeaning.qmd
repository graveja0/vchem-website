---
title: "Quasi-Demeaning: The Relationship Between Fixed and Random Effects"
author: John Graves
date: "2022-12-21"
categories: [Econometrics]
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  message: false
  warning: false  
  code-fold: hide
bibliography: "../../../references.bib"
reference-location: margin
self-contained: true
image: "media/spiderman.jpeg"
---

# Setup

Assume the following data generation process:

$$
Y_{it} = \mathbf{X}_{i}'\beta + \tau D_{it} + U_i +\epsilon_{it} 
$$
where $i$ indexes individual units and $t$ indexes time, $\mathbf{X}_i$ are unit-level attributes, $D_{it}$ is a treatment indicator (set to 1 if the observation is treated and in the post-treatment period). Finally, $U_i$ captures unobserved unit-level heterogeneity. 


## Estimation: Random vs. Fixed Effects

- Random effects uses an approach called "quasi-demeaning" or "partial pooling." 

- The random effects model can be represented as:

$$
\begin{align}
(Y_{it}-\theta \bar{Y_i}) = (\mathbf{X}_{it}-\theta \bar{\mathbf{X}_i})'\beta + \tau (D_{it}-\theta \bar{D_i})  + (\epsilon_{it} - \theta \bar{\epsilon_i}) \quad \quad \quad Eq. 9
\end{align}
$$

where 

$$
\theta = 1 - \bigg [\frac{\sigma^2_\epsilon}{(\sigma^2_\epsilon + T\sigma^2_u)}\bigg ]^{1/2}
$$

In the above, $\sigma_u$ is the variance of unit-level heterogeneity, and $\sigma_{\epsilon}$ is the variance of $\epsilon_{it}$. And recall $T$ is the total number of repeated unit-level observations in our panel (e.g., the total number of time periods, the total number of patients for a given physician, etc.)

- When $\theta = 0$, it just reduces pooled regression.

- When $\theta = 1$, it is equivalent to fixed effects regression. This *only* isolates variation within units to estimate the regression coefficients (i.e., units are only compared to themselves, which is why the unobserved heterogeneity is accounted for).

- Essentially, when you fit a random effects regression,  Stata estimates $\theta$ and then plugs that estimate it into the above model. 
  
- (When you fit a fixed effects regression, Stata uses the demeaning approach--unless, of course, you manually fit a dummy variable model)

- Often $0 < \theta < 1$, hence the term "partial-pooling." That is, the regression draws on both variation "within" units and variation "between" units.

- The degree to which within and between variation is used depends on the data context.


- Remember, when $\theta=0$ the random effects regression reduces to pooled OLS. When is this the case?

  - If the term $T\sigma^2_u$ is 0, i.e., $\sigma^2_u=0$ or there is no variation in individual heterogeneity.

- Remember, when $\theta=1$ the random effects regression reduces to fixed effects. When is this the case?

  - If the term $T\sigma^2_u$ gets super large (more formally, it would need to blast off towards infinity...). 
  
  - If we have a very "large" panel of observations on each unit (i.e., large $T$) there is sufficient "within" variation and we really don't need to do any pooling across units. 
  
  
# Setup

```{r setup}
library(tidyverse)
library(lme4)
library(broom)
library(knitr)
theme_set(theme_bw())
```

```{r dgp_panel_setup}
#| echo: true
#| code-fold: true

params_panel <- list(
  N = 1000,
  T = 2,
  tx_time = 2, 
  rho_t = 0.8,
  beta_0 = 0.5,
  beta_1 = 2,
  tau = 0.5,
  p_d = 0.5
)

dgp_panel <- function(params) {
  with(params, {

    # Time effects
    t_ <-
      data.frame(t = 1:T,
                 gamma_t = arima.sim(n=T, list(ar = rho_t, order=c(1,0,0))) %>% as.vector())

    # Individual measures and effects
    i_ <-
      data.frame(
        unit_id = 1:N,
        x_i = rnorm(N, mean = 0, sd = 1),
        u_i = rnorm(N, mean = 0, sd = 1)) %>%
      rowwise() %>% # This allows us to get each value's pr_treated in the line below. 
      mutate(pr_treated = boot::inv.logit(u_i)) %>% 
      ungroup() %>%  # This undoes the rowwise 
      # Treatment indicator
      mutate(d_i = rbinom(N, size = 1, prob = pr_treated)) %>% 
      ungroup()

    crossing(unit_id = i_$unit_id,t = t_$t) %>%
      left_join(i_,"unit_id") %>%
      left_join(t_,"t") %>%
      mutate(d_i = ifelse(t<tx_time,0,d_i)) %>%
      mutate(y_i = beta_0 + beta_1 * x_i + tau * d_i + u_i + gamma_t + rnorm(N, mean = 0, sd = 1)) %>% 
      select(unit_id, t, y_i , x_i, d_i)
  })
}

estimator_fn_re <- function(df) {
  lmer(y_i ~  d_i + (1|unit_id) , df)
}

disc_fn_re <- function(fit) {
  fit %>% summary() %>% pluck("coefficients") %>%
    data.frame() %>%
    rownames_to_column() %>%
    janitor::clean_names() %>%
    filter(rowname=="d_i") %>%
    pull(estimate) %>%
    as.vector()
}

generate_estimate_discriminate_re <- function(params) {
  params %>% # Step 1: Parameterize the problem
      dgp_panel() %>%  # Step 2: Define the data generation process
        estimator_fn_re() %>%  # Step 3: Estimate 
          disc_fn_re() %>% # Step 4: Pull out what you need
            data.frame(tau_hat = .) # store the result as a data frame object
}

construct_dm <- function(df) {
  df_ <- 
    df %>% 
      # mutate(y_i = y_i + mean(y_i),
      #       d_i = d_i + mean(d_i)) %>% 
      #       group_by(t) %>% 
      #       mutate(y_i = y_i - mean(y_i),
      #       d_i = d_i - mean(d_i)) %>% 
            group_by(unit_id) %>% 
            mutate(y_i = y_i - mean(y_i),
            d_i = d_i - mean(d_i))

  return(df_)
}

estimate_dm <- function(df) {
  lm(y_i ~ d_i   , data = df)
}

disc_fn_dm = function(fit) {
  fit_ =broom::tidy(fit)   # This cleans up the fitted regression object
  out =fit_ %>% 
    filter(term=="d_i") %>% 
    pull(estimate)
  
  return(out)
}


set.seed(123)
df_c <- 
  modifyList(params_panel,list(T=400,tx_time=200)) %>% 
  dgp_panel() %>% 
  mutate(index = t-200) %>% 
  mutate(T2= as.integer(index %in% c(-1,0))) %>% 
  mutate(T4 = as.integer(index > -3 & index <2)) %>%
  mutate(T10 = as.integer(index >= -5 & index<5)) %>% 
  mutate(T20 = as.integer(index >= -10 & index <10 )) %>%
  mutate(T50 = 1 ) 

df <- df_c %>% filter(T4==1)

params_panel %>% 
  dgp_panel() %>% 
  head() %>% 
  kable(digits=3)

```

Let's first show the equivalance between the random effect model and a quasi-demeaned linear regression model. We'll do so by focusing on a case where $T=4$. 

```{r}
fit_re <- 
  df %>% 
  estimator_fn_re()

summary(fit_re)
```

- Notice the use of the term "fixed effects" is based on a traditional statistical definition--these are the regression parameters not assumed to come from a stochastic (statsitical) distribution, such as the random effects. 

Let's now extract out the variance parameter estimates $\sigma^2_{\epsilon}$ and $\sigma^2_u$:

```{r}
get_re <- function(fit) {
    x <- VarCorr(fit) %>% data.frame() %>% 
    tibble() %>% 
    select(grp,var1,vcov)
}

re_est <- 
  fit_re %>% 
  get_re()
```

```{r}
#| echo: false

re_est %>% kable()
```

We can then use these to calculatate $\theta$:

```{r}
sigma2_e = fit_re %>% get_re() %>% filter(grp=="Residual") %>% pull(vcov)
sigma2_ui = fit_re %>% get_re() %>% filter(grp=="unit_id") %>% pull(vcov)
theta_i = 1 - sqrt(sigma2_e/(4*sigma2_ui + sigma2_e))

theta_i
```

Next we will create a quasi-demeaned version of our input data: 

```{r}
df_ <- 
  df %>% 
  group_by(unit_id) %>% 
  mutate(y_i = y_i - theta_i * mean(y_i),
         d_i = d_i - theta_i * mean(d_i))
```

We now fit a quasi-demeaned 
```{r}
fit_qdm <- lm(y_i ~ d_i, data = df_)
summary(fit_qdm)

```

Now let's compare:

```{r}
res <- 
  fit_qdm %>% tidy() %>% 
  select(term,estimate_qdm = estimate) 

cbind(res,df %>% estimator_fn_re() %>% summary() %>% pluck("coefficients") %>% 
  data.frame() %>% 
  select(estimate_re = Estimate)) %>% 
  mutate(theta = theta_i) %>% 
  select(term, estimate_re, estimate_qdm, theta) %>% 
  remove_rownames() %>% 
  kable(digits = 3)
```

  
```{r }
#| code-fold: true
#| eval: false

get_theta <- function(fit) {
  sigma2_e = fit %>% get_re() %>% filter(grp=="Residual") %>% pull(vcov)
  sigma2_ui = fit %>% get_re() %>% filter(grp=="unit_id") %>% pull(vcov)
  theta = 1 - sqrt(sigma2_e/(4*sigma2_ui + sigma2_e))
  theta 
}

t_qdm <- tibble(
  T2 = df_c %>% filter(T2==1) %>% estimator_fn_re() %>% disc_fn_re(),
  theta2  = df_c %>% filter(T2==1) %>% estimator_fn_re() %>% get_theta(),
  T2fe = df_c %>% filter(T2==1) %>% construct_dm() %>% estimate_dm() %>% disc_fn_dm()  ,
  T4 = df_c %>% filter(T4==1) %>% estimator_fn_re() %>% disc_fn_re(),
  theta4  = df_c %>% filter(T4==1) %>% estimator_fn_re() %>% get_theta(),
  T4fe = df_c %>% filter(T4==1) %>% construct_dm() %>% estimate_dm() %>% disc_fn_dm()    ,
  T10 = df_c %>% filter(T10==1) %>% estimator_fn_re() %>% disc_fn_re(),
  theta10  = df_c %>% filter(T10==1) %>% estimator_fn_re() %>% get_theta(),  
  T10fe = df_c %>% filter(T10==1) %>% construct_dm() %>% estimate_dm() %>% disc_fn_dm()   ,
  T20 = df_c %>% filter(T20==1) %>% estimator_fn_re() %>% disc_fn_re(),
  theta20  = df_c %>% filter(T20==1) %>% estimator_fn_re() %>% get_theta(),  
  T20fe = df_c %>% filter(T20==1) %>% construct_dm() %>% estimate_dm() %>% disc_fn_dm()  ,
  T400 = df_c %>%  estimator_fn_re() %>% disc_fn_re(),
  theta400 =  df_c %>%  estimator_fn_re() %>% get_theta(),
  T400fe = df_c %>% construct_dm() %>% estimate_dm() %>% disc_fn_dm()
)
  
t_qdm %>% 
  select(-starts_with("theta")) %>% 
  gather(measure,value) %>% 
  mutate(method = ifelse(grepl("fe",measure),"FE","RE")) %>% 
  mutate(measure = gsub("fe","",measure)) %>% 
  mutate(measure = case_when(measure == "T2" ~ "T = 2",
                             measure == "T4" ~ "T = 4",
                             measure == "T10" ~ "T = 10",
                             measure == "T20" ~ "T = 20",
                             measure == "T400" ~ "T = 400")) %>% 
  rename(time_periods = measure) %>% 
  spread(method, value) %>% 
  mutate(time_periods = factor(time_periods, levels = c("T = 2","T = 4", "T = 10","T = 20" , "T = 400"))) %>% 
  arrange(time_periods) %>% 
  kable()

```
 
