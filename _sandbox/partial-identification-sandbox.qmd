---
title: "Partial Identification Sandbox"
subtitle: "Extending the Policy Evaluation Toolkit"
author: John Graves
date: "2022-12-19"
categories: [Partial Identification, Causal Inference]
editor_options: 
  chunk_output_type: console
execute:
  code-fold: true
  message: false
  warning: false  
  cache: true
bibliography: "../references.bib"
reference-location: margin
self-contained: true
editor: 
  markdown: 
    wrap: 72
---

```{r setup, cache = FALSE}
#| echo: true
#| code-fold: true
#| 
library(tidyverse)
library(here)
library(glue)
library(copula)
library(knitr)
library(kableExtra)
library(ggsci)
library(MASS)
library(psych)
library(patchwork)
library(directlabels)
library(progress)
library(latex2exp)
library(copula)
select <- dplyr::select
options("scipen"=100, "digits"=6)
theme_set(hrbrthemes::theme_ipsum() + theme(legend.position = "top", panel.grid.minor.y = element_blank()) )

library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)

get_distribution_function <- function(x,fn = "pdf") {
  n.knots = 20
  dat <-
        tibble(x = x, cdf= ecdf(x)(x)); head(dat)

  n <- length(dat$x)
  fit <- scam::scam(cdf ~ s(x, bs = "mpi", k = n.knots), data = dat,
                    weights = c(n, rep(1, n - 2), 10 * n))
  ## interior knots
  xk <- with(fit$smooth[[1]], knots[4:(length(knots) - 3)])
  ## spline values at interior knots
  yk <- predict(fit, newdata = data.frame(x = xk))
  ## reparametrization into a monotone interpolation spline
  xg <- seq(min(dat$x), max(dat$x), length = 100)
  f <- stats::splinefun(xk, yk, "hyman")
  pcdf <- f(x)
  ppdf <- f(x,1)
  
  if (fn=="pdf") out <- approxfun(x,f(x,1)) 
  if (fn=="cdf") {
    out <- approxfun(x, f(x), 
            method = "constant",
            yleft = 0,
            yright = 1,
            f = 0)
  }
  return(out)
  
}

```

# Outline

0. Introduction
1. Decision-Relevant Quantities of Interest
  - Individual-level treatment effects are of policy interest because they allow us to characterize the distribution of treatment effects, not just some summary (e.g., average) in a population. 
    - What fraction of the population is harmed? 
    - What fraction experiences substantial vs. minimal gain?
    - What is the average treatment response? 
    - What is the median treatment response? The 25th percentile? The 75th percentile?
2. The Perfect Data
3. Credible Identification in the Real World
  - Even if marginal distributions of the outcome are identified (as they are under random assignment or under unconfounded selection), the "copula" that binds them together is unidentified.
  - This section will cover identification under the most ideal (realistic) real-world scenario: an experimental design with perfect compliance.
  - In that case we can identify the marginal distribution of the potential outcomes under treatment and non-treatment. 
4. Expanding the Toolkit via Partial Identification
  - Copulas and the relationship between marginal and joint distributions.
     - Brief theory
     - Simulating from a copula
  - Copulas and the relationship to treatment effects and decision-relevant quantities of interest. 
5. Worst-Case Bounds 
  - Frechet-Hoeffding
  - Komogorov
  - Williamson and Downs
  - Firpo and Ridder? 
6. Tightening the Bounds with Covariates 
  - Constructing conditional eCDFs
7. Tightening the Bounds Using Additional Identifying Assumptions (Experimental Designs)
  - Frandsen and Lefgrens (2021)
8. Partial Identification in Observational Settings
  - Partial Identification with an Exogenous Instrument
    - Frandsen and Lefgrens (2021)  
    - Manski IV bounds
    - Principal Stratification
9. Partial Identification in Observational Settings
  - Changes-in-Changes
  - Callaway (Panel Data)
  - Heckman: Selection
  - Manski: Monotone Treatment Response
  - Manski: Monotone Selection Response


  





```{r}
#| echo: true
#| code-fold: true
#| message: false
#| warning: false


df <- # basic perfect doctor data (from Rubin)
  data.frame(patient = LETTERS[1:10],
            Y_1 = c(7,5,5,7,4,10,1,5,3,9),
             Y_0 = c(5,3,8,8,3,1,6,8,8,4))  %>% 
  mutate(Y_0 = c(1,6,1,8,2,1,10,6,7,8)) %>% 
  mutate(delta = Y_1 - Y_0) %>% 
  mutate(D = c(1,1,1,1,1,0,0,0,0,0)) %>% 
  mutate(Y_obs = case_when(D==1 ~ Y_1, TRUE ~ Y_0)) %>% 
  mutate(sim = 0) %>% 
  mutate(X = rnorm(10,mean = 0, sd = 1)) 

# Simulate additional data from a copula that defines the correlation b/t potential outcomes, and
# between a single covariate X and the potential outcomes. 
m <- 3 # number of columns
n <- 10000-10 # sample size
corXY <- 0.8 # corelation between potential outcomes and X
sigma <- matrix(c(1,0.6,corXY,0.6,1,corXY,corXY,corXY,1),nrow = 3) # correlation matrix

# Sample the joint CDF quantiles from a multivariate normal centered at 0
set.seed(100)
z <- mvrnorm(n,mu=rep(0, m),Sigma=sigma,empirical=T) 
u <- pnorm(z) # get the quantiles associated with each value

X <-  # a single covariate that is predictive of the outcome. 
  qnorm(u[,3],mean = 0, sd = 1)

# Generate the variables
delta <-   #Treatment effect varies, but has mean 2 and SD 1. 
  rnorm(n,mean = 2, sd = 1)

delta <-
  1 + ((X - mean(X)) / ( sd(X)))

sY_0 <- # simulated potential outcome under non-Tx
  qpois(u[,2],lambda=mean(df[df$D==1,]$Y_1)) + rnorm(n=n)

sY_1 <- # simulated potential outcome under Tx
  qpois(u[,1],lambda = mean(df[df$D==1,]$Y_1)) + delta

df_sim <- # Construct the final data. 
  tibble(patient = glue("sim{1:n}")) %>% 
  mutate(Y_1 = sY_1,
         Y_0 = sY_0,
         X = X) %>% 
  mutate(delta = Y_1 - Y_0) %>% 
  mutate(D = as.integer(runif(nrow(.))<.5)) %>%
  mutate(U = rnorm(nrow(.))) %>% 
  #mutate(D = as.integer(Y_1>=Y_0)) %>% 
  mutate(sim = 1)

df <- # Bind it with the general example rows (10 rows)
  df %>% 
  bind_rows(df_sim) %>% 
  mutate(Y = case_when(D==1 ~ Y_1, TRUE ~ Y_0)) 

# corUY <- 0.3
# 
# params <-
#     list(
#         n = 1e4,
#         sigma = matrix(c(1,0.8,0.9,corUY,
#                          0.8,1,0.9,corUY,
#                          0.9,0.9,1,.2,
#                          corUY,corUY,0.2,1), nrow = 4, ncol = 4, byrow = TRUE,
#                        dimnames = list(c("Y1","Y0","X1","U"),c("Y1","Y0","X1","U"))),
#         lambda = 15,
#         delta = 2
#     )
# 
# m <- ncol(params$sigma)
# 
# # Simulate from a copula
# set.seed(123)
# z <- # Draw from a multivariate normal distribution with covariance matrix sigma 
#     mvrnorm(params$n,mu=rep(0, m),Sigma=params$sigma,empirical=T) 
# u <- # obtain the quantiles associated with each value
#     pnorm(z) 
# 
# Y_0 <- 
#     qpois(u[,1], params$lambda) + rnorm(n = params$n, mean = 0, sd = 1) 
# 
# U <-
#     qnorm(u[,4], mean = 0, sd = 1)
# 
# tmp_ <- 1  +  (Y_0 - mean(Y_0)) / (1*sd(Y_0))
# 
# tmp_ <- 1  +  (U - mean(U)) / (1*sd(U))
# 
# Y_1 <- 
#     Y_0 + rpois(n = params$n, lambda = params$delta) * tmp_  + U
# 
# X1 <- 
#     qnorm(u[,3], mean = 0, sd = 1)
# 
# df <- 
#     tibble(study_id = paste0("ID",1:params$n), Y_0 = Y_0, Y_1 = Y_1, X1 = X1, U = U)
# 
df %>%
    head(n = 10) %>%
    select(patient, Y_0, Y_1) %>%
    kable(digits = 2) %>%
    kable_styling()

```

```{r}
#| echo: true
#| code-fold: true
#| label: fig-scatter
#| fig-cap: Scatterplot of Potential Outcomes with 95% Ellipse
#| fig-height: 5
#| fig-width: 5
df %>% 
    filter(row_number() %in% sample(1:nrow(.),replace = FALSE)) %>% 
    ggplot(aes(x = Y_0, y = Y_1)) + stat_ellipse() + 
    geom_point()
```

Because we can calculate $Y_i(1)-Y_i(0)$ directly, we can plot its
distribution:

```{r}
#| fig-cap: Distribution of the Treatment Effect (delta)
#| label: fig-test
#| fig-height: 6
#| fig-width: 7
#| echo: true
#| code-fold: true
df %>% 
  ggplot(aes(x = delta)) + geom_density() +
  labs(x = TeX("$\\Delta$"), y = "Density")+
  geom_vline(aes(xintercept =  mean(delta)),lty=2,lwd=1.1, col = "darkred") + 
  annotate("text", x = mean(delta), y = .1, hjust=-.1, label = "Avg. Treatment Effect", col = "darkred") + 
  scale_x_continuous(limits = c(min(df$delta),max(df$delta)),breaks = seq(-8,10,2)) + 
  geom_vline(aes(xintercept = 0),lty=3) 
```

We can also explore whether the treatment effect magnitude varies by
some covariate $X1$. In @fig-deltabyX, we see that the treatment effect
tends to be larger for larger values of $X1$.

```{r}
#| fig-cap: Treatment Response by Covariate Value
#| label: fig-deltabyX
#| fig-height: 8
#| fig-width: 7
#| echo: true
#| code-fold: true
#| warning: false
#| message: false

# Source: https://stackoverflow.com/questions/61589781/plot-vertical-density-of-normal-distribution-in-r-and-ggplot2

taus <- seq(0,1,0.01) 
quantreg_fit <- 
  quantreg::rq(delta ~ X, tau = taus, data = df)
pvals <- predict(quantreg_fit, stepfun=TRUE)
X <- df$X

get_delta_dist <- function(qq, scaling = 10) {
  qq %>% map_df(~({
    delta_ <- seq(min(df$delta), max(df$delta), length.out = 1e4)
    hatF <- pvals[[which(abs(ecdf(X)(X) - .x) < 0.01)[1]]]
    pdfX <- get_distribution_function(hatF(taus),  fn = "pdf")
    pdf_ <-
      tibble(y = delta_, x = 
                pdfX(delta_)) %>%
      na.omit()
    
    pdf_norm <- # PDF must integrate to one but sometimes its a bit off. 
      # So we can re-normalize to integrate to one. 
      sum(c(0,diff(delta_))*pdfX(delta_),na.rm=TRUE)
    
    mm <- 
      sum(delta_ * c(0,diff(delta_))* (pdfX(delta_)/pdf_norm),na.rm=TRUE)
  

    pdf_ %>% mutate(X = X[which(abs(ecdf(X)(X) - .x) < 0.01)[1]]) %>% 
      mutate(tau = .x) %>% 
      mutate(mean_delta = mm)
  })) %>% 
  mutate(max = max(x)) %>% 
  mutate(x = (x))
  
}

df_condpdf <- 
  get_delta_dist(c(.01,0.05,0.25,0.5,0.75,0.95)) %>% 
  mutate(x = X + x * 10)  %>% 
  mutate(X_ = X) %>% 
  mutate(X = factor(X, labels = unique(.$tau))) %>% 
  filter(abs(x-X_)>0.03)

df %>% 
  ggplot(aes(x= X, y = delta)) + geom_point(alpha = 0.25) + 
  geom_path(data = df_condpdf, aes(x=x,y=y, colour = X),lwd=2)  + 
  scale_x_continuous(breaks = round(unique(df_condpdf$X_),2)) +
  scale_y_continuous(breaks = c(seq(-20,20,10),round(unique(df_condpdf$mean_delta),2)),guide = guide_axis(n.dodge=2)) + 
  scale_color_aaas(name="Quantile of X") + 
  theme(legend.position = "top", panel.grid.minor.y = element_blank()) +
  labs(y = TeX("$\\Delta$"), y = "Covariate (X) Value") +
  geom_hline(aes(yintercept = 0),lwd=1.25)

```

We can also plot the cumulative distribution function of the treatment
response. This is shown in @fig-distdelta.

```{r figdelta}
#| fig-cap: Cumulative Distribution Function of the Treatment Effect (delta)
#| label: fig-distdelta
#| fig-height: 6
#| fig-width: 7
#| echo: true
#| code-fold: true

delta_ <- sort(df %>%  pull(delta)) 
df_ <- data.frame(x = delta_, y = seq_along(delta_)/length(delta_), region = delta_ < 0 )

br0_ <- unique(sort(c(seq(0,1,0.2),ecdf(delta_)(0))))
br0_l <- paste0(round(br0_,2))

figdelta <- 
  ggplot(df_, aes(x, y)) +
  geom_area(aes(fill = region)) +
  geom_line() +
  labs(x = "x = Treatment Effect", y = TeX("$Pr(\\Delta$<=x)"))+
  scale_fill_manual(values = c('lightgrey', '#C14E4295'), guide = "none") +
  annotate('text', x = 0, y = 0.08, label = 'Harmed', col = "black",size = 4, hjust=1.1) +
   geom_vline(aes(xintercept = 2),lty=2,lwd=1.1, col = "darkred") + 
  annotate("text", x = 1.5, y = 0.8, hjust=1, label = "Avg. Treatment Effect", col = "darkred", size = 4) +
  scale_y_continuous(breaks = br0_, labels = br0_l) +
  geom_point(data = tibble(x = 0, y = ecdf(delta_)(0)), aes(x = x, y = y),size=5, pch=10) 

figdelta
```

# Decision-Relevant Quantities of Interest

@tbl-decisionquant summarizes various quantities of interest we can
calculate with full information on the joint distribution of potential
outcomes.

```{r frac_harmed, echo = FALSE}
#| echo: true
#| code-fold: true
#| warning: false
#| message: false
#| label: tbl-decisionquant
#| tbl-cap: Quantities of Interest
#| tbl-colwidths: [50,30,20]


tx_effect <- 
    df %>%  pull(delta)

delta_ <- 
    seq(floor(min(tx_effect)), ceiling(max(tx_effect)),length.out = 1e6)

avg_delta <- 
    sum(delta_ * c(0,diff(ecdf(tx_effect)(delta_))))

frac_harmed <- 
    ecdf(tx_effect)(-1)

frac_minimal_harm <- 
    ecdf(tx_effect)(0)-ecdf(tx_effect)(-1)

frac_low <- 
    ecdf(tx_effect)(1)-ecdf(tx_effect)(0)

frac_high <- 
    1 - ecdf(tx_effect)(1)

q_delta  <- 
    quantile(ecdf(tx_effect),c(0.1,0.5,0.75))

quantities <- 
    tibble(average = avg_delta,
           q10 = q_delta[1],
           q50 = q_delta[2],
           q75 = q_delta[3],
           harm = 100* frac_harmed,
           minimal_harm = 100* frac_minimal_harm,
           low = 100*frac_low,
           high= 100*frac_high) %>% 
    gather(quantity,value) %>% 
    mutate(quantity = factor(quantity, levels = c("average","q10","q50","q75","harm","minimal_harm","low","high"),
                             labels = c("Average Treatment Response",
                                        "25th %ile of Tx Response",
                                        "50th %ile of Tx Response",
                                        "75th %ile of Tx Reponse",
                                        "Percent with Substantial Harm",
                                        "Percent with Minimal Harm",
                                        "Percent with Low Benefit",
                                        "Percent with High Benefit"))) %>% 
    mutate(formula = c("$\\int t d \\hat  F_{\\Delta}(t)$","$\\hat  F^{-1}_{\\Delta}(0.25)$","$\\hat F^{-1}_{\\Delta}(0.50)$","$\\hat F^{-1}_{\\Delta}(0.75)$","$\\hat F_{\\Delta}(-1)$",
                       "$\\hat F_{\\Delta}(0)-\\hat F_{\\Delta}(-1)$","$\\hat F_{\\Delta}(1)-\\hat F_{\\Delta}(0)$","$1 - \\hat F_{\\Delta}(1)$"))

quantities %>% 
    select(quantity,formula,value) %>% 
    kable(booktabs = T ,escape = F, align = 'l', format = "markdown",
          col.names = c("Quantity of Interest","Estimator","Value"), digits =2) %>%
    kable_classic(full_width = F,
                  position = "center",font_size = 35) 

```

## What Can We Point Identify in an Experimental Study?

```{r}
#| echo: true
#| code-fold: true
#| message: false
#| warning: false

df_exp <- 
    df %>% 
    select(patient, Y, X, D)

df_exp %>%
    head(n = 10) %>%
    kable(digits = 2) %>%
    kable_styling()
```

We can plot the empirical CDF of the treated and control groups. Notice
in @fig-ecdfTxCx that the curves cross. This provides suggestive
evidence that there is heterogeneity in treatment effects.

```{r}
#| echo: true
#| code-fold: true
#| message: false
#| warning: false
#| fig-cap: eCDFs of Treated and Control Groups
#| label: fig-ecdfTxCx

Y_Tx <- df_exp %>% filter(D==1) %>% pull(Y)
Y_Cx <- df_exp %>% filter(D==0) %>% pull(Y)
D <- df_exp %>% pull(D)
Y <- df_exp %>% pull(Y)

ate <- 
    mean(Y[D==1]) - mean(Y[D==0])

qte_q <- 
  c(0.1,0.25,0.5,0.75,0.9) %>% map_dbl(~(quantile(ecdf(Y_Tx),.x) - quantile(ecdf(Y_Cx),.x)))

p <- 
    df_exp %>% 
    mutate(D = factor(D, labels = c("Cx","Tx")))  %>% 
    ggplot(aes(x = Y, colour = D)) + stat_ecdf() + 
    scale_colour_aaas(name="")  +
    theme(legend.position = "top")
p
```

If $F_{Y_1|D=1}$ and $F_{Y_0|D=1}$ are identified, we can use the
marginal distribution of the outcome among the treated and control units
to calculate the **Average Treatment Effect on the Treated (ATT)** and
the **Quantile Treatment Effect on the Treated (QTT)**:

The ATT is given by:

$$
ATT=E\left[Y_{1}-Y_{0} \mid D=1\right]
$$

And the QTT is given by:

$$
Q T T(\tau)=F_{Y_{1} \mid D=1}^{-1}(\tau)-F_{Y_{0} \mid D=1}^{-1}(\tau)
$$

```{r}
#| fig-cap: Quantile Treatment Effect on the Treated
#| label: fig-qtt
#| fig-height: 6
#| fig-width: 7
#| echo: true
#| code-fold: true
#| warning: false
#| message: false

fig_qtt <- 
  tibble(x = 1:49/50, y =  (1:49/50) %>% map_dbl(~(quantile(ecdf(Y_Tx),.x) - quantile(ecdf(Y_Cx),.x)))) %>% 
  ggplot(aes(x = x, y = y)) + geom_point(size=3,pch=19) +
  labs(x = TeX("$\\tau$"),y=TeX("$\\hat{F}^{-1}_{Y_1|D=1}(\\tau) - \\hat{F}^{-1}_{Y_0|D=1}(\\tau)$")) + 
  geom_hline(aes(yintercept = 0), lwd=1.25) +
   scale_y_continuous(limits = c(-2,8),breaks = seq(-2,8,2))


fig_qtt 
```

We can estimate the ATT and QTT using linear regression (e.g., OLS) and
quantile regression, respectively. @fig-qtt-qreg overlays the estimate
ATT (red) and QTT estimates (dark blue) based on OLS and quantile
regression fit to the experimental data generated above.

```{r}
#| fig-cap: Average and Quantile Treatment Effect on the Treated
#| label: fig-qtt-qreg
#| fig-height: 6
#| fig-width: 7
#| echo: true
#| code-fold: true
#| warning: false
#| message: false


# Source: https://stackoverflow.com/questions/59348163/plotting-quantile-regression-sensitivity-in-ggplot
# OLS
lm <- lm(data= df_exp, 
         formula =  Y ~  D)

ols <- as.data.frame(coef(lm))
ols.ci <- as.data.frame(confint(lm))
ols2 <- cbind(ols, ols.ci)
ols2 <- tibble::rownames_to_column(ols2, var="term") %>% 
  filter(term=="D")

# Quantile Regression
quantreg_fit <- 
  quantreg::rq(Y ~ D, tau = 1:45/50, data = df_exp)

p_exp <- 
  quantreg_fit %>% 
  broom::tidy() %>%
  filter(term=="D") %>% 
  ggplot(aes(x=tau,y=estimate))+
  geom_point(data =  tibble(tau = 1:49/50, estimate =  (1:49/50) %>% map_dbl(~(quantile(ecdf(Y_Tx),.x) - quantile(ecdf(Y_Cx),.x)))),size=3,pch=19) + 
  # quantilie results
  geom_point(color="#27408b", size = 3)+ 
  geom_line(color="#27408b", size = 1)+ 
  geom_ribbon(aes(ymin=conf.low,ymax=conf.high),alpha=0.25, fill="#27408b")+

  # OLS results
  geom_hline(data = ols2, aes(yintercept= `coef(lm)`), lty=1, color="red", size=1)+
  geom_hline(data = ols2, aes(yintercept= `2.5 %`), lty=2, color="red", size=1)+
  geom_hline(data = ols2, aes(yintercept= `97.5 %`), lty=2, color="red", size=1) + 
  geom_hline(aes(yintercept = 0), lwd=1.25) +
  scale_y_continuous(limits = c(-2,8),breaks = seq(-2,8,2))

p_exp 

```

## Can We Partially Identify Other Quantities of Interest?

## Simulating from a Copula


```{r, eval = FALSE}

######################################
## Option 1: Cholesky Decomposition
######################################
# Source: Coping with Copulas Sec 5.1

# 1. Define the correlation matrix
  rho <- 0.6
  sigma <- matrix(c(1,rho,rho,1),nrow = 2, byrow=TRUE)

# 2. Perform a cholesky decomposition
  A = chol(sigma)

# 3. Generate iid standard normal pseudo random variables
  tildeY0 <- rnorm(n = 1e6, mean = 0, sd = 1)
  tildeY1 <- rnorm(n = 1e6, mean = 0, sd = 1)
  tildeY <- cbind(tildeY0,tildeY1)

  # Collect them 
  tildeY <- tildeY %*% A

# Use the standard normal disribution function to return the quantiles
  U <- pnorm(tildeY)

# Use the inverse distribution function to return the values
  Y <- U 
  Y[,1] <- qpois(U[,1],lambda = 10)
  Y[,2] <- qpois(U[,2],lambda = 12)

# Confirm the correct correlation 
cor(Y[,1],Y[,2])
```

```{r, eval = FALSE}
##########################
## Option 2: Use MVRNORM
##########################
U_ <- pnorm(mvrnorm(n = 1e6, Sigma = sigma, mu = c(0,0)))
Y_ <- U_
Y_[,1] <- qpois(U_[,1],lambda = 10)
Y_[,2] <- qpois(U_[,2],lambda = 12)

cor(Y_[,1],Y_[,2])

```


Sklar (1959) demonstrates that the joint distribution can be represented
as

$$
\mathrm{F}_{Y_{1}, Y_{0} \mid D=1}\left(y_1, y_0\right)=C_{Y_{1}, Y_{0} \mid D=1}\left(\mathrm{~F}_{Y_{1} \mid D=1}\left(y_1\right), \mathrm{F}_{Y_{0} \mid D=1}\left(y_0\right)\right)
$$ The copulas are given by $$
M(y_1,y_0)=\min \left\{y_1,y_0\right\}
$$ for extreme positive dependence and

$$
W\left(y_1, y_0\right)=\max \left\{y_1+y_0-1,0\right\}
$$ for perfect negative dependence.

We can use this to form bounds on the joint distribution ($H(y_1, y_2)$)
based on the marginals:

$$
\max [F(y_1)+G(y_0)-1,0] \leq H(y_1, y_0) \leq \min [F(y_1), G(y_0)]
$$

Williamson and Downs (199) use this relationship to solve for bounds on
the difference between two variables:

## Worst-Case Bounds


[![Source: Rank, Jörn, ed. Copulas: From theory to application in finance. Vol. 108. Bloomberg Press, 2007.](../media/copula-triangle.png){fig-align="center"
width="1000"}](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiNqKTPnJr-AhXWk2oFHfsvBnAQFnoECA4QAQ&url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F228876267_Coping_with_copulas&usg=AOvVaw1Hrg1isAmzRwbljvOV-3J6)

Nice
[slides](http://www.columbia.edu/~mh2078/QRM/Copulas_MasterSlides.pdf)
on copulas.

-   Frechet-Hoeffding lower bounds corresponds to case with perfect
    anticorrelation between potential outcomes.
-   Upper bounds corresponds to case with perfect correlation between
    potential outcomes.
-   They are distributions of perfectly negatively dependent and
    perfectly positively dependent random variables respectively, see
    Joe (1997) and Nelsen (1999) for more discussions.

[Here is the
paper](http://public.econ.duke.edu/~ap172/Copula-Fan-Patton-Oct7-2013.pdf)
on copulas in econometrics.

> Sharp bounds on the joint distribution of the potential outcomes with
> identiÖed marginals are given by the Frechet-Hoe§ding lower and upper
> bound distributions, see Heckman and Smith (1993), Heckman, Smith, and
> Clements (1997), and Manski (1997b) for their applications in program
> evaluation. For randomized experiments, Heckman, Smith, and Clements
> (1997) proposed nonparametric estimates of the FrÈchet-Hoe§ding
> distribution bounds and developed a test for the ìcommon e§ectî model
> by testing the lower bound of the variance of the treatment e§ect.
> They also suggested an alternative test based on the di§erence between
> the quantile functions of the marginal distributions of the potential
> outcomes referred to as the quantile treatment e§ect (QTE), see Firpo
> (2005) or Section 2 for more references. Sharp bounds on the
> distribution of the treatment e§ectó the di§erence between two
> potential outcomes with identiÖed marginalsó are known in the
> probability literature. A.N. Kolmogorov posed the question of Önding
> sharp bounds on the distribution of a sum of two random variables with
> Öxed marginal distributions. It was Örst solved by Makarov (1981) and
> later by R¸schendorf (1982) and Frank, Nelsen, and Schweizer (1987)
> using di§erent techniques. Frank, Nelsen, and Schweizer (1987) showed
> that their proof based on copulas can be extended to more general
> functions than the sum. Sharp bounds on the respective distributions
> of a di§erence, a product, and a quotient of two random variables with
> Öxed marginals can be found in Williamson and Downs (1990). More
> recently, Denuit, Genest, and Marceau (1999) extended the bounds for
> the sum to arbitrary dimensions and provided some applications in
> Önance and risk management, see Embrechts, Hoeing, and Juri (2003) and
> McNeil, Frey, and Embrechts (2005) for more discussions and additional
> references.

[Source](https://www.princeton.edu/~erp/Econometrics/Old%20Pdfs/fan.pdf)


```{r}
#| column: screen-inset-shaded
#| label: fig-fh
#| fig-cap: "Copluas for Frechet-Hoeffding Bounds"
#| fig-subcap: 
#|   - "Lower Bound"
#|   - "Upper Bound"
#| layout-ncol: 2
#| echo: false
#| code-fold: true

wireframe2(lowfhCopula(dim = 2), pCopula)
wireframe2(upfhCopula(dim = 2), pCopula)
```


```{r bounds1}
#| echo: false
#| message: false
#| warning: false
#| 
y1 <- # Vector of treated outcomes
    df_exp %>% filter(D==1) %>% pull(Y) %>% na.omit()
F1 <- # Empirical CDF of treated outcome vector
    ecdf(y1)

y0 <- # Vector of untreated outcomes
    df_exp %>% filter(D==0) %>% pull(Y)
F0 <- # Empirical CDF of untreated outcome vector
    ecdf(y0)

delta_ <- # Vector of hypothetical treatment effects
    seq(min(df$delta), max(df$delta), length.out =1000)
y_ <- # Vector of the support of the outcome, with 100 evenly-spaced values along it. 
    seq(floor(min(y0,y1))-1,ceiling(max(y0,y1))+1, length.out = 1000)

tau <-  # Quantiles of the treatment effect distribution to obtain 
    seq(.01,.99,.01)

X <- # X values of treated observations
  df %>%
  filter(D==1) %>%
  pull(X)

X0 <- # X values of untreated observations
  df %>% 
  filter(D==0) %>% 
  pull(X)
```

```{r boundsWD}
#| echo: false
#| message: false
#| warning: false

library(furrr)
library(tictoc)
#plan(multisession)

F_l_wd_ <- # Lower bound
  delta_ %>% future_map(~{ # Outer loop is over possible values of the treatment effect
    delta <- .x
    y0 %>% # Inner loop is over y0
      map_dbl(~{
        y <- .x
        (F1(y) - F0(y-delta)) %>% max(.,0)
      })
  }) %>% 
  map_dbl(~(max(.))) # sup in formula


# Turn it into an eCDF object
  F.wd.l <- approxfun(delta_,  F_l_wd_, method = "constant", yleft = 0, yright = 1, 
            f = 0, ties = "ordered")
  class(F.wd.l) <- c("ecdf", "stepfun", class(F.wd.l))
  assign("nobs", length(delta_), envir = environment(F.wd.l))

F_u_wd_ <- # Upper bound
  delta_ %>% future_map(~{ # Outer loop is over possible values of the treatment effect
    delta <- .x
    y0 %>% # Inner loop is over y0
      map_dbl(~{
        y <- .x
        (F1(y) - F0(y-delta)) %>% min(.,0)
      })
  }) %>% 
  map(~(min(.))) %>% # inf in formula
  map_dbl(~(1+.x)) # add one per formula

# Turn it into an eCDF object
  F.wd.u <- approxfun(delta_,  F_u_wd_, method = "constant", yleft = 0, yright = 1, 
                      f = 0, ties = "ordered")
  class(F.wd.u) <- c("ecdf", "stepfun", class(F.wd.u))
  assign("nobs", length(delta_), envir = environment(F.wd.u))
  
df_bounds <- 
  tibble(x = delta_, ymax = F.wd.u(delta_), ymin = F.wd.l(delta_)) %>% 
            mutate(region = x<0)

qwdu <- quantile(F.wd.l, tau, type=1)
qwdl <- quantile(F.wd.u, tau, type=1)

df_wd <- 
  data.frame(tau = c(tau,tau), bound = c(qwdu,qwdl), type=c(rep("upper",length(qwdu)),rep("lower",length(qwdl)))) %>% 
  mutate(method = "Worst-Case\n[Williamson-Downs (1990)]") %>% 
  mutate(label = ifelse(type=="upper","Worst-Case\n[Williamson-Downs (1990)]","")) 

col_scheme <- c("#7DC4CC","#0A2E36","#FF5733")

```

```{r plotWD}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Bounds on the Cumulative Distribution Function of the Treatment Effect (delta)
#| label: fig-bounddistdelta
#| fig-height: 6
#| fig-width: 7

br_ <- sort(c(seq(0,1,0.25),F.wd.u(0),F.wd.l(0)))
br_l <- paste0(round(br_,2))

ggplot() +
  geom_line(data = df_, aes(x, y),lwd=1.5, col = "darkred") +
  annotate("text",x=10, y = .3, label = "True treatment effect CDF\nshown as dark red line.",hjust=0,size = 4) +
  labs(x = "x = Treatment Effect", y = TeX("$Pr(\\Delta$<=x)"))+
  scale_fill_manual(values = c('lightgrey', '#C14E4295'), guide = "none") +
  geom_ribbon(data = df_bounds , 
              aes(x = x, ymin = ymin, ymax=ymax, fill = region), alpha = 0.5)  +
  geom_line(data = df_bounds, aes(x = x, y = ymin), alpha = 1,lwd=1.25) +
  geom_line(data = df_bounds, aes(x = x, y = ymax), alpha = 1,lwd=1.25) + 
  scale_y_continuous(breaks = br_, labels = br_l) +
  geom_point(data = tibble(x = 0, y = F.wd.u(0)), aes(x = x, y = y),size=5, pch=10) +
  geom_point(data = tibble(x = 0, y = F.wd.l(0)), aes(x = x, y = y),size=5, pch=10) 
  
```

```{r}
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
#| label: fig-bounds-wd
#| fig-cap: Worst-Case Treatment Effect Distribution Bounds 
#| fig-width: 10
#| fig-height: 8

#col_scheme <- c("#FF5733" ) # Williamson and Downs

df_wd  %>% 
  mutate(method = factor(method, levels = c("Frandsen & Lefgrens (2021)"     ,       "Frandsen & Lefgrens (2021) Covariates", "Worst-Case\n[Williamson-Downs (1990)]"))) %>% 
  mutate(type = paste0(type,method)) %>% 
  ggplot() + 
  geom_line(aes(x = tau, y = bound, group = type, colour = method),lwd=1.5,colour = "#FF5733") + 
  geom_dl(method = list("last.points",hjust=1),aes(label = label,x = tau, y = bound, group = type, colour = method)) +
  scale_x_continuous(breaks = seq(0,1,0.1)) +
  theme(legend.position = "none")  +
  scale_colour_manual(values = col_scheme[3]) +
  labs(x = TeX("$$\\tau$$"),y=TeX("QoTT($$\\tau$$)")) +
  geom_point(data =  tibble(type = "test", bound = "truth", method = "foo",tau = 1:49/50, estimate =  (1:49/50) %>% map_dbl(~(quantile(ecdf(Y_Tx),.x) - quantile(ecdf(Y_Cx),.x)))),size=3,pch=19,
             aes(x = tau, y = estimate))
  # geom_point(data =  tibble(tau = taus, qtt = QTT, type = "True Values", method = "True Values"), aes(x = tau, y = qtt ),
  #            col="darkred") 


```

## Frandsen and Lefgrens


We'll next construct bounds based on
@frandsenPartialIdentificationDistribution2021.

## Bound Distributions for a Single Y Value

Our first objective is to simply plot the PDF of the untreated group. We'll obtain this by differentiating the empirical CDF and fitting a smooth function to it.

```{r}

gen_pdf <- function(F,x, n.knots = 20) {
    dat <-
        tibble(x, cdf=F(x))
    
    n <- length(dat$x)
    fit <- scam::scam(cdf ~ s(x, bs = "mpi", k = n.knots), data = dat,
                      weights = c(n, rep(1, n - 2), 10 * n))
    ## interior knots
    xk <- with(fit$smooth[[1]], knots[4:(length(knots) - 3)])
    ## spline values at interior knots
    yk <- predict(fit, newdata = data.frame(x = xk))
    ## reparametrization into a monotone interpolation spline
    xg <- seq(min(dat$x), max(dat$x), length = 100)
    f <- stats::splinefun(xk, yk, "hyman")
    dat$pdens = f(x,1)
    dat <- dat %>% 
        mutate(dt = c(0,diff(x,1)),
               dy = c(0,diff(cdf,1))) %>% 
        mutate(dydt = dy/dt)
    
    return(dat)
}

Y0 <- 4
y0_ <- df %>% filter(D==0) %>% pull(Y) 
y1_ <- df %>% filter(D==1) %>% pull(Y) 

df_pdf0 <-
    gen_pdf(F = F0,x = sort(c(Y0,y0_))) %>%
    na.omit()

df_pdf1 <-
    gen_pdf(F = F1,x = sort(c(Y0,y1_))) %>%
    na.omit()

```

```{r, echo = FALSE}
tmp_ <- 
    df_pdf0 %>% 
    filter(x==Y0) %>% 
    mutate(xend = Y0) %>% 
    mutate(y = 0, yend = pdens)
    

f1A <- 
    df_pdf0 %>% 
    filter(dydt<max(pdens)*2) %>% 
    ggplot(aes(x = x, y = pdens)) + geom_line() + #geom_point(aes(y = dydt),alpha=0.1) + 
    geom_segment(data = tmp_, aes(x = x, xend = xend, y = y, yend = yend)) + 
    scale_x_continuous(limits = range(c(y1_,y0_)), breaks = sort(c(Y0,as.integer(seq(min(c(y1_,y0_)),max(c(y1_,y0_)),length.out=5)*2)/2)),guide = guide_axis(n.dodge=2)) + 
       labs(x="Y",y="Density") +
  theme(panel.grid.minor.x = element_blank())
f1A
```

We next need to find the y value in the treated distribution that maps to the quantile value in the untreated distribution at -1.

```{r, echo = FALSE,fig.height=6,fig.width=10}
# Empirical CDF and inverse CDF for the untreated and treated groups
F0 <- df %>% filter(D==0) %>% pull(Y) %>% ecdf()
invF0 <- edfun::edfun(df %>% filter(D==0) %>% pull(Y))$qfun
F1 <- df %>% filter(D==1) %>% pull(Y) %>% ecdf()
invF1 <- edfun::edfun(df %>% filter(D==1) %>% pull(Y))$qfun

yy <- invF1(F0(Y0))

df_pdf1 <- 
    gen_pdf(F = F1,x = sort(c(yy,y1_))) %>% 
    na.omit()

fdens1 <- approxfun(df_pdf1$x,df_pdf1$pdens)

f1B <- 
    df_pdf1 %>% 
    ggplot(aes(x = x, y = pdens)) + geom_line() + #geom_point(aes(y = dydt)) +
    stat_function(fun=fdens1, xlim = c(min(y1_),yy), geom="area") +
    scale_x_continuous(limits = range(c(y1_,y0_)), breaks = sort(c(Y0,as.integer(seq(min(c(y1_,y0_)),max(c(y1_,y0_)),length.out=5)*2)/2)),guide = guide_axis(n.dodge=2)) + 
    labs(x="Y",y="Density") 

f1C <- 
    df_pdf1 %>% 
    ggplot(aes(x = x, y = pdens)) + geom_line() + #geom_point(aes(y = dydt)) +
    stat_function(fun=fdens1, xlim = c(yy,max(y1_)), geom="area") +
    scale_x_continuous(limits = range(c(y1_,y0_)), breaks = sort(c(Y0,as.integer(seq(min(c(y1_,y0_)),max(c(y1_,y0_)),length.out=5)*2)/2)),guide = guide_axis(n.dodge=2)) + 
       labs(x="Y",y="Density")


(f1A + f1A) / (f1B + f1C)

```

Let's now define conditional PDFs for the best and worst case

```{r}
df_condpdf_worst <- 
    df_pdf1 %>% 
    mutate(pdens = ifelse(x<=yy,pdens,0)) %>% 
    # Normalize so the PDF integrates to one.
    mutate(pdens = (pdens) / sum(pdens * dt))

df_condpdf_best <- 
    df_pdf1 %>% 
    mutate(pdens = ifelse(x>yy,pdens,0)) %>% 
    # Normalize so the PDF integrates to one.
    mutate(pdens = (pdens) / sum(pdens * dt))

f2A <- 
    df_condpdf_worst %>% 
    ggplot(aes(x = x, y = pdens)) + geom_point() #+
        #scale_y_continuous(limits = c(0,0.5))

f2B <- 
    df_condpdf_best %>% 
    ggplot(aes(x = x, y = pdens)) + geom_point() #+
        #scale_y_continuous(limits = c(0,0.5))

```

```{r, echo = FALSE, fig.cap="Empirical Density for Worst and Best Case",fig.height=4,fig.width=10}
#
f2A + f2B

```

The rightmost panel of the figure shows that an individual with the given Y value has zero probability of drawing a $Y(1)$ *below* his or her rank in the control state. Instead, her draws is from the truncated distribution of $Y(1)$ ranks *above* her rank in the control state. As noted in the paper, "the best case corresponds to the lower-bound CDF given in equation (1)."
scratch ends here

```{r FLbounds1, echo = FALSE}
i1 <- # Index of treated observations
  df_exp %>% 
  mutate(i = row_number()) %>% 
  filter(D==1) %>% 
  pull(i)

i0 <- # index of untreated observations
  df_exp %>% 
  mutate(i = row_number()) %>% 
  filter(D==0) %>% 
  pull(i)


F0_fl <-# ecdf for untreated defined across the support of y
  y_ %>% map_dbl(~({
    .y = .x
    mean(df_exp$Y[i0] <= .y)
  })) %>% BMisc::makeDist(y_, .)


F1_fl <-# ecdf for treated defined across the support of y
  y_ %>% map_dbl(~({
    .y = .x
    mean(df_exp$Y[i1] <= .y )
  })) %>% BMisc::makeDist(y_, .)

# Construct bounds

#pb <- progress_bar$new(total = length(delta_))
F_l_fl_ <- # Lower bound
  delta_ %>% future_map(~{ # outer loop is over possible values of the treatment effect
    delt <- .x
    #pb$tick()
    y0 %>% # inner loop is over observed outcome values among untreated
      map_dbl(~({
        y0_ = .x 
        (F1_fl(y0_ + delt)-F0_fl(y0_))/(1-F0_fl(y0_))
      }))  %>% 
      map_dbl(~(max(0,.x,na.rm=TRUE))) %>% 
      mean(.)
  }) %>% 
  unlist()

#pb <- progress_bar$new(total = length(delta_))
F_u_fl_ <-  # Upper bound
  delta_ %>% future_map(~{ # outer loop is over possible values of the treatment effect
    delt <- .x
    #pb$tick()
    y0 %>% # inner loop is over observed outcome values among untreated 
      map_dbl(~({
        y0_ = .x 
        (F1_fl(y0_+delt))/(F0_fl(y0_))
      }))  %>% 
      map_dbl(~(min(1,.x,na.rm=TRUE))) %>% 
      mean(.)
  }) %>% 
  unlist()


# Convert into an ECDF
F.fl.l <- approxfun(delta_,  F_l_fl_, method = "constant", yleft = 0, yright = 1, 
                    f = 0, ties = "ordered")
class(F.fl.l) <- c("ecdf", "stepfun", class(F.fl.l))
assign("nobs", length(delta_), envir = environment(F.fl.l))

F.fl.u <- approxfun(delta_,  F_u_fl_, method = "constant", yleft = 0, yright = 1, 
                    f = 0, ties = "ordered")
class(F.fl.u) <- c("ecdf", "stepfun", class(F.fl.u))
assign("nobs", length(delta_), envir = environment(F.fl.u))

df_bounds_fl <- 
  tibble(x = delta_, ymax = F.fl.u(delta_), ymin = F.fl.l(delta_)) %>% 
            mutate(region = x<0)

qflu <- quantile(F.fl.l, tau, type=1)
qfll <- quantile(F.fl.u, tau, type=1)

df_fl <- 
  data.frame(tau = c(tau,tau), bound = c(qflu,qfll), type=c(rep("upper",length(qflu)),rep("lower",length(qfll)))) %>% 
  mutate(method = "Frandsen & Lefgrens (2021)") %>% 
  mutate(label = ifelse(type=="upper","Frandsen & Lefgrens (2021)","")) 

```

```{r FLboundsplot}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Frandsen-Lefgren (2021) Bounds on the Cumulative Distribution Function of the Treatment Effect (delta)
#| label: fig-flbounddistdelta
#| fig-height: 6
#| fig-width: 7


br_wd <- sort(c(seq(0,1,0.25),F.wd.u(0),F.wd.l(0),F.fl.u(0),F.fl.l(0)))
br_wd_l <- paste0(round(br_wd,2))

ggplot() +
  geom_line(data = df_, aes(x, y),lwd=1.5, col = "darkred") +
  annotate("text",x=4.5, y = .3, label = "True treatment effect CDF\nshown as dark red line.",hjust=0,size = 4) +
   labs(x = "x = Treatment Effect", y = TeX("$Pr(\\Delta$<=x)"))+
  scale_fill_manual(values = c('lightgrey', '#C14E4295'), guide = "none") +
  #geom_line(data = tibble(x = delta_, y = F.wd.l(delta_))) +
  #geom_line(data = tibble(x = delta_, y = F.wd.u(delta_))) +
  geom_ribbon(data = df_bounds_fl , 
              aes(x = x, ymin = ymin, ymax=ymax, fill = region), alpha = 0.5) +
  hrbrthemes::theme_ipsum() + 
  geom_line(data = df_bounds, aes(x = x, y = ymin), alpha = 0.5) +
  geom_line(data = df_bounds, aes(x = x, y = ymax), alpha = 0.5) +
  geom_line(data = df_bounds_fl, aes(x = x, y = ymin), alpha = 1,lwd=1.25) +
  geom_line(data = df_bounds_fl, aes(x = x, y = ymax), alpha = 1,lwd=1.25) +
    scale_y_continuous(breaks = br_wd, labels = br_wd_l) + 
  geom_point(data = tibble(x = 0, y = F.fl.u(0)), aes(x = x, y = y),size=5, pch=10) +
  geom_point(data = tibble(x = 0, y = F.fl.l(0)), aes(x = x, y = y),size=5, pch=10)
  

```

```{r}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Worst-Case Bounds on the Average Treatment Effect on the Treated, by Method
#| label: fig-boundwdattfl
#| fig-height: 3
#| fig-width: 7


attfl <- tibble(delta = delta_,
       FU = F.fl.l(delta_),
       FL = F.fl.u(delta_)) %>% 
  mutate(diffU = c(0,diff(FU)),
         diffL = c(0,diff(FL))) %>% 
  summarise(upper = sum(delta*diffU),
            lower = sum(delta*diffL)) %>% 
  mutate(method = "Frandsen & Lefgrens (2021)" ) %>% 
  mutate(size = 2) 

attwd <- tibble(delta = delta_,
       FU = F.wd.l(delta_),
       FL = F.wd.u(delta_)) %>% 
  mutate(diffU = c(0,diff(FU)),
         diffL = c(0,diff(FL))) %>% 
  summarise(upper = sum(delta*diffU),
            lower = sum(delta*diffL)) %>% 
  mutate(method = "Worst-Case\n[Williamson-Downs (1990)]" ) %>% 
  mutate(size =1)

attfl %>% 
  #bind_rows(attwd) %>% 
  mutate(y = 0) %>% 
  mutate(method = factor(method, levels = c("Frandsen & Lefgrens (2021)","Frandsen & Lefgrens (2021) Covariates", "Worst-Case\n[Williamson-Downs (1990)]")))  %>% 
  ggplot() + 
  geom_errorbar(aes(y = 0, xmin = lower, xmax = upper,colour = method),width = 0.8,lwd = 2) + 
  scale_y_continuous(limits = c(-1,1), breaks = NULL) + 
  geom_point(aes(x = mean(df$delta), y = 0), colour = "darkred", size=8, alpha = 0.5) + 
  geom_vline(aes(xintercept = 0), lty=3, col = "darkgrey") + 
  labs(x = "ATT", y = "") +
  scale_colour_manual(values = col_scheme[c(1,3)],name="") +
  theme(legend.position = "bottom")

```

```{r}
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
#| label: fig-bounds-fl
#| fig-cap: Fransden-Lefgren Treatment Effect Distribution Bounds 
#| fig-width: 10
#| fig-height: 8

#col_scheme <- c("#FF5733" ) # Williamson and Downs

df_wd  %>% 
  bind_rows(df_fl) %>% 
  mutate(method = factor(method, levels = c("Frandsen & Lefgrens (2021)"     ,       "Frandsen & Lefgrens (2021) Covariates", "Worst-Case\n[Williamson-Downs (1990)]"))) %>% 
  mutate(type = paste0(type,method)) %>% 
  ggplot(aes(x = tau, y = bound, group = type)) + 
  geom_line(lwd=1.25,aes(colour = method)) + 
  scale_color_manual(values=col_scheme[c(1,3)]) + 
  geom_dl(method = list("last.points",hjust=1),aes(label = label)) +
  scale_x_continuous(breaks = seq(0,1,0.1)) +
  theme(legend.position = "none")  +
   labs(x = TeX("$$\\tau$$"),y=TeX("QoTT($$\\tau$$)"))

```

Let's get it even tighter with covariates. This is an approach based on
@frandsenPartialIdentificationDistribution2021.

```{r FLboundsX}
#| echo: false
#| message: false
#| warning: false
#| code-fold: false

i1 <-  # index of treated observations
  df_exp %>% 
  mutate(i = row_number()) %>% 
  filter(D==1) %>% 
  pull(i)

i0 <-  # index of untreated observations
  df_exp %>% 
  mutate(i = row_number()) %>% 
  filter(D==0) %>% 
  pull(i)

X <- # X values of treated observations
  df_exp %>%
  filter(D==1) %>%
  pull(X)

X0 <- # X values of untreated observations
  df_exp %>% 
  filter(D==0) %>% 
  pull(X)

taus0 <- seq(0,1,0.01) #sort(ecdf(y0)(y0))
quantreg_fit <- quantreg::rq(Y ~ X, tau = taus0, data = df_exp %>% filter(D==0))
pvals <- predict(quantreg_fit,newdata = data.frame(X=X0), stepfun=TRUE)
hatF0X <- pvals %>% map(~(.x(taus0))) %>% 
  map(~(BMisc::makeDist(.x,taus0)))


taus1 <-  seq(0,1,0.01)#sort(ecdf(y1)(y1))
quantreg_fit <- quantreg::rq(Y ~ X, tau = taus0, data = df_exp %>% filter(D==1))
pvals <- predict(quantreg_fit,newdata = data.frame(X=X0), stepfun=TRUE)
hatF1X <- pvals %>% map(~(.x(taus0))) %>% 
  map(~(BMisc::makeDist(.x,taus0)))


#pb <- progress_bar$new(total = length(delta_))
F_l_flX_ <- 
  delta_ %>% future_map(~{ # outer loop is over possible values of the treatment effect
    delt <- .x
    #pb$tick()
      map2_dbl(y0,X0,~({
        y0_ = .x 
        xx_ = .y
        i = which(X0==xx_); i
        F1_fl_tmp <- hatF1X[[i]]
        F0_fl_tmp <- hatF0X[[i]]
        (F1_fl_tmp(y0_ + delt)-F0_fl_tmp(y0_))/(1-F0_fl_tmp(y0_))
      }))  %>% 
      map_dbl(~(max(0,.x,na.rm=TRUE))) %>% 
      mean(.)
  }) %>% 
  unlist()
# Make it into a proper eCDF object.
F.flX.l <- approxfun(delta_,  F_l_flX_, method = "constant", yleft = 0, yright = 1, 
                    f = 0, ties = "ordered")
class(F.flX.l) <- c("ecdf", "stepfun", class(F.flX.l))
assign("nobs", length(delta_), envir = environment(F.flX.l))

#pb <- progress_bar$new(total = length(delta_))
F_u_flX_ <- 
  delta_ %>% 
  future_map(~{ # outer loop is over possible values of the treatment effect
    delt <- .x
    #pb$tick()
    
      map2_dbl(y0,X0,~({
        y0_ = .x 
        xx_ = .y
        i = which(X0==xx_); i
        F1_fl_tmp <- hatF1X[[i]]
        F0_fl_tmp <- hatF0X[[i]]
        
        (F1_fl_tmp(y0_+delt))/(F0_fl_tmp(y0_))
      }))  %>% 
      map_dbl(~(min(1,.x,na.rm=TRUE))) %>% 
      mean(.)
  }) %>% 
  unlist()
# Make it into a proper eCDF object. 
F.flX.u <- approxfun(delta_,  F_u_flX_, method = "constant", yleft = 0, yright = 1, 
                    f = 0, ties = "ordered")
class(F.flX.u) <- c("ecdf", "stepfun", class(F.flX.u))
assign("nobs", length(delta_), envir = environment(F.flX.u))

df_bounds_flX <- 
  tibble(x = delta_, ymax = F.flX.u(delta_), ymin = F.flX.l(delta_)) %>% 
            mutate(region = x<0)

qflXu <- quantile(F.flX.l, tau, type=1)
qflXl <- quantile(F.flX.u, tau, type=1)

df_flX <- 
  data.frame(tau = c(tau,tau), bound = c(qflXu,qflXl), type=c(rep("upper",length(qflXu)),rep("lower",length(qflXl)))) %>% 
  mutate(method = "Frandsen & Lefgrens (2021)\nWith Covariates") %>% 
  mutate(label = ifelse(type=="upper","Frandsen & Lefgrens (2021)\nWith Covariates","")) 

```

```{r FLboudnsXplot}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Frandsen-Lefgren (2021) Bounds on the Cumulative Distribution Function of the Treatment Effect, With Covariates
#| label: fig-flboundXdistdelta
#| fig-height: 6
#| fig-width: 7


br_wdX <- sort(c(seq(0,1,0.25),F.wd.u(0),F.wd.l(0),F.fl.u(0),F.fl.l(0),F.flX.u(0),F.flX.l(0)))
br_wdX_l <- paste0(round(br_wdX,2))

ggplot() +
  geom_line(data = df_, aes(x, y),lwd=1.5, col = "darkred") +
  annotate("text",x=4.5, y = .3, label = "True treatment effect CDF\nshown as dark red line.",hjust=0,size = 4) +
   labs(x = "x = Treatment Effect", y = TeX("$Pr(\\Delta$<=x)"))+
  scale_fill_manual(values = c('lightgrey', '#C14E4295'), guide = "none") +
  #geom_line(data = tibble(x = delta_, y = F.wd.l(delta_))) +
  #geom_line(data = tibble(x = delta_, y = F.wd.u(delta_))) +
  geom_ribbon(data = df_bounds_flX , 
              aes(x = x, ymin = ymin, ymax=ymax, fill = region), alpha = 0.5) +
  geom_line(data = df_bounds, aes(x = x, y = ymin), alpha = 0.5) +
  geom_line(data = df_bounds, aes(x = x, y = ymax), alpha = 0.5) +
  geom_line(data = df_bounds_fl, aes(x = x, y = ymin), alpha = 0.5) +
  geom_line(data = df_bounds_fl, aes(x = x, y = ymax), alpha = 0.5) +
  geom_line(data = df_bounds_flX, aes(x = x, y = ymin), alpha = 1,lwd=1.25) +
  geom_line(data = df_bounds_flX, aes(x = x, y = ymax), alpha = 1,lwd=1.25) +
  geom_point(data = tibble(x = 0, y = F.flX.u(0)), aes(x = x, y = y),size=5, pch=10) +
  geom_point(data = tibble(x = 0, y = F.flX.l(0)), aes(x = x, y = y),size=5, pch=10) + 
  scale_y_continuous(breaks = br_wdX, labels = br_wdX_l) 
  

```

```{r}
#| echo: false
#| warning: false
#| message: false
#| fig-cap: Worst-Case Bounds on the Average Treatment Effect on the Treated, by Method
#| label: fig-boundwdattflX
#| fig-height: 3
#| fig-width: 7


attfl <- tibble(delta = delta_,
       FU = F.fl.l(delta_),
       FL = F.fl.u(delta_)) %>% 
  mutate(diffU = c(0,diff(FU)),
         diffL = c(0,diff(FL))) %>% 
  summarise(upper = sum(delta*diffU),
            lower = sum(delta*diffL)) %>% 
  mutate(method = "Frandsen & Lefgrens (2021)" ) %>% 
  mutate(size = 2) 

attflX <- tibble(delta = delta_,
       FU = F.flX.l(delta_),
       FL = F.flX.u(delta_)) %>% 
  mutate(diffU = c(0,diff(FU)),
         diffL = c(0,diff(FL))) %>% 
  summarise(upper = sum(delta*diffU),
            lower = sum(delta*diffL)) %>% 
  mutate(method = "Frandsen & Lefgrens (2021) Covariates" ) %>% 
  mutate(size = 2) 

attwd <- tibble(delta = delta_,
       FU = F.wd.l(delta_),
       FL = F.wd.u(delta_)) %>% 
  mutate(diffU = c(0,diff(FU)),
         diffL = c(0,diff(FL))) %>% 
  summarise(upper = sum(delta*diffU),
            lower = sum(delta*diffL)) %>% 
  mutate(method = "Worst-Case\n[Williamson-Downs (1990)]" ) %>% 
  mutate(size =1)

attfl %>% 
  bind_rows(attflX) %>% 
  bind_rows(attwd) %>% 
  mutate(y = 0) %>% 
  mutate(method = factor(method, levels = c("Frandsen & Lefgrens (2021)","Frandsen & Lefgrens (2021) Covariates", "Worst-Case\n[Williamson-Downs (1990)]")))  %>% 
  ggplot() + 
  geom_errorbar(aes(y = 0, xmin = lower, xmax = upper,colour = method),width = 0.8,lwd = 2) + 
  scale_y_continuous(limits = c(-1,1), breaks = NULL) + 
  geom_point(aes(x = 2, y = 0), colour = "darkred", size=8, alpha = 0.5) + 
  geom_vline(aes(xintercept = 0), lty=3, col = "darkgrey") + 
  labs(x = "ATT", y = "") +
  scale_colour_manual(values = col_scheme,name="") +
  theme(legend.position = "bottom")

```

```{r}
#| echo: true
#| message: false
#| warning: false
#| code-fold: true
#| label: fig-bounds-flX
#| fig-cap: Fransden-Lefgren Treatment Effect Distribution Bounds With Covariates
#| fig-width: 10
#| fig-height: 8

df_wd  %>% 
  bind_rows(df_fl) %>% 
  bind_rows(df_flX) %>% 
  mutate(method = factor(method, levels = c("Frandsen & Lefgrens (2021)"     ,       "Frandsen & Lefgrens (2021)\nWith Covariates", "Worst-Case\n[Williamson-Downs (1990)]"))) %>% 
  mutate(type = paste0(type,method)) %>% 
  ggplot(aes(x = tau, y = bound, group = type)) + 
  geom_line(lwd=1.25,aes(colour = method)) + 
  scale_color_manual(values=col_scheme) + 
  geom_dl(method = list("last.points",hjust=1),aes(label = label,colour = method)) +
  scale_x_continuous(breaks = seq(0,1,0.1)) +
  theme(legend.position = "none")  +
  labs(x = TeX("$$\\tau$$"),y=TeX("QoTT($$\\tau$$)"))
  #annotate("text",x = 0.5, y = 2, label = "True Treatment Effect",vjust=-1,colour = "darkred") 

```
