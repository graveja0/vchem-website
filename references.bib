@article{abbringEconometricEvaluationSocial2007,
  title = {Econometric Evaluation of Social Programs, Part {{III}}: {{Distributional}} Treatment Effects, Dynamic Treatment Effects, Dynamic Discrete Choice, and General Equilibrium Policy Evaluation},
  shorttitle = {Econometric Evaluation of Social Programs, Part {{III}}},
  author = {Abbring, Jaap H. and Heckman, James J.},
  year = {2007},
  journal = {Handbook of econometrics},
  volume = {6},
  pages = {5145--5303},
  publisher = {{Elsevier}},
  file = {/Users/johngraves/Zotero/storage/BRP6LY6M/S1573441207060722.html}
}

@article{baderNewApproachSample2018,
  title = {A New Approach for Sample Size Calculation in Cost-Effectiveness Studies Based on Value of Information},
  author = {Bader, Cl{\'e}ment and Cossin, S{\'e}bastien and Maillard, Aline and B{\'e}nard, Antoine},
  year = {2018},
  month = oct,
  journal = {BMC Medical Research Methodology},
  volume = {18},
  number = {1},
  pages = {113},
  issn = {1471-2288},
  doi = {10.1186/s12874-018-0571-1},
  urldate = {2022-12-28},
  abstract = {Value of information is now recognized as a reference method in the decision process underpinning cost-effectiveness evaluation. The expected value of perfect information (EVPI) is the expected value from completely reducing the uncertainty surrounding the cost-effectiveness of an innovative intervention.},
  keywords = {Clinical trials,Comparative studies,Cost-benefit analysis,Epidemiologic methods,Sample size,Value of information},
  file = {/Users/johngraves/Zotero/storage/2LAR6FDQ/Bader et al. - 2018 - A new approach for sample size calculation in cost.pdf;/Users/johngraves/Zotero/storage/YEEAR7UR/s12874-018-0571-1.html}
}

@article{blancoBoundsAverageQuantile2020,
  title = {Bounds on {{Average}} and {{Quantile Treatment Effects}} on {{Duration Outcomes Under Censoring}}, {{Selection}}, and {{Noncompliance}}},
  author = {Blanco, German and Chen, Xuan and Flores, Carlos A. and {Flores-Lagunes}, Alfonso},
  year = {2020},
  month = oct,
  journal = {Journal of Business \& Economic Statistics},
  volume = {38},
  number = {4},
  pages = {901--920},
  publisher = {{Taylor \& Francis}},
  issn = {0735-0015},
  doi = {10.1080/07350015.2019.1609975},
  urldate = {2023-01-09},
  abstract = {We consider the problem of assessing the effects of a treatment on duration outcomes using data from a randomized evaluation with noncompliance. For such settings, we derive nonparametric sharp bounds for average and quantile treatment effects addressing three pervasive problems simultaneously: self-selection into the spell of interest, endogenous censoring of the duration outcome, and noncompliance with the assigned treatment. Ignoring any of these issues could yield biased estimates of the effects. Notably, the proposed bounds do not impose the independent censoring assumption\textemdash which is commonly used to address censoring but is likely to fail in important settings\textemdash or exclusion restrictions to address endogeneity of censoring and selection. Instead, they employ monotonicity and stochastic dominance assumptions. To illustrate the use of these bounds we assess the effects of the Job Corps (JC) training program on its participants' last complete employment spell duration. Our estimated bounds suggest that JC participation may increase the average duration of the last complete employment spell before week 208 after randomization by at least 5.6 log points (5.8\%) for individuals who comply with their treatment assignment and experience a complete employment spell whether or not they enrolled in JC. The estimated quantile treatment effects suggest the impacts may be heterogeneous, and strengthen our conclusions based on the estimated average effects.},
  keywords = {Duration outcomes,Independent censoring,Job corps,Partial identification,Principal stratification},
  file = {/Users/johngraves/Zotero/storage/EX4AAQYB/Blanco et al. - 2020 - Bounds on Average and Quantile Treatment Effects o.pdf}
}

@misc{BlendedSurvivalCurves,
  title = {Blended {{Survival Curves}}: {{A New Approach}} to {{Extrapolation}} for {{Time-to-Event Outcomes}} from {{Clinical Trials}} in {{Health Technology Assessment}}},
  shorttitle = {Blended {{Survival Curves}}},
  doi = {10.1177/0272989X221134545},
  urldate = {2022-12-12},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/0272989X221134545},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/WGGTVIZH/Blended Survival Curves A New Approach to Extrapo.pdf;/Users/johngraves/Zotero/storage/AZ7VYGTP/0272989X221134545.html}
}

@article{callawayBoundsDistributionalTreatment2021,
  title = {Bounds on Distributional Treatment Effect Parameters Using Panel Data with an Application on Job Displacement},
  author = {Callaway, Brantly},
  year = {2021},
  journal = {Journal of Econometrics},
  volume = {222},
  number = {2},
  pages = {861--881},
  publisher = {{Elsevier}},
  file = {/Users/johngraves/Zotero/storage/582AWV3C/S0304407620302839.html}
}

@article{callawayQuantileTreatmentEffects2019,
  title = {Quantile Treatment Effects in Difference in Differences Models with Panel Data},
  author = {Callaway, Brantly and Li, Tong},
  year = {2019},
  journal = {Quantitative Economics},
  volume = {10},
  number = {4},
  pages = {1579--1618},
  publisher = {{Wiley Online Library}},
  file = {/Users/johngraves/Zotero/storage/V6NYGF52/QE935.html}
}

@misc{Chapter72Econometric,
  title = {Chapter 72 {{Econometric Evaluation}} of {{Social Programs}}, {{Part III}}: {{Distributional Treatment Effects}}, {{Dynamic Treatment Effects}}, {{Dynamic Discrete Choice}}, and {{General Equilibrium Policy Evaluation}} - {{ScienceDirect}}},
  urldate = {2023-03-26},
  howpublished = {https://www.sciencedirect.com/science/article/pii/S1573441207060722?casa\_token=izsFQNcF4HgAAAAA:-7MK5EYyQiwbaXzkYAKFU\_IT6UEUIjsVcwP6EUk8R1eQQ4Lo5lW3QUwIAIVAkhos2H5dyb2smQ},
  file = {/Users/johngraves/Zotero/storage/TUYJJNR7/S1573441207060722.html}
}

@article{ecklesCommentaryCausalDecision2022,
  title = {Commentary on ``{{Causal Decision Making}} and {{Causal Effect Estimation Are Not}} the {{Same}}\ldots{} and {{Why It Matters}}'': {{On Loss Functions}} and {{Bias}}\textendash{{Variance Tradeoffs}} in {{Causal Estimation}} and {{Decisions}}},
  shorttitle = {Commentary on ``{{Causal Decision Making}} and {{Causal Effect Estimation Are Not}} the {{Same}}\ldots{} and {{Why It Matters}}''},
  author = {Eckles, Dean},
  year = {2022},
  journal = {INFORMS Journal on Data Science},
  publisher = {{INFORMS}},
  file = {/Users/johngraves/Zotero/storage/2YHUFQH3/Eckles - 2022 - Commentary on “Causal Decision Making and Causal E.pdf}
}

@misc{EstimatingLifetimeEpisode,
  title = {Estimating Lifetime or Episode-of-illness Costs under Censoring - {{Basu}} - 2010 - {{Health Economics}} - {{Wiley Online Library}}},
  urldate = {2022-12-09},
  howpublished = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hec.1640}
}

@article{fanCopulasEconometrics2014,
  title = {Copulas in Econometrics},
  author = {Fan, Yanqin and Patton, Andrew J.},
  year = {2014},
  journal = {Annual Review of Economics},
  volume = {6},
  number = {1},
  pages = {179--200},
  publisher = {{Annual Reviews}},
  file = {/Users/johngraves/Zotero/storage/RJ7ZMTSM/Fan and Patton - 2014 - Copulas in econometrics.pdf}
}

@article{fernandez-loriaCausalDecisionMaking2022,
  title = {Causal Decision Making and Causal Effect Estimation Are Not the Same\ldots{} and Why It Matters},
  author = {{Fern{\'a}ndez-Lor{\'i}a}, Carlos and Provost, Foster},
  year = {2022},
  journal = {INFORMS Journal on Data Science},
  publisher = {{INFORMS}},
  file = {/Users/johngraves/Zotero/storage/VQKXSPHC/Fernández-Loría and Provost - 2022 - Causal decision making and causal effect estimatio.pdf;/Users/johngraves/Zotero/storage/CQQVJYLJ/ijds.2021.html}
}

@article{finkelsteinSubsidizingHealthInsurance2017,
  title = {Subsidizing {{Health Insurance}} for {{Low-Income Adults}}: {{Evidence}} from {{Massachusetts}}},
  shorttitle = {Subsidizing {{Health Insurance}} for {{Low-Income Adults}}},
  author = {Finkelstein, Amy and Hendren, Nathaniel and Shepard, Mark},
  year = {2017},
  month = aug,
  journal = {National Bureau of Economic Research Working Paper Series},
  number = {w23668},
  publisher = {{National Bureau of Economic Research}},
  urldate = {2020-08-03},
  file = {/Users/johngraves/Zotero/storage/S7UZC8PT/Finkelstein et al. - 2017 - Subsidizing Health Insurance for Low-Income Adults.pdf;/Users/johngraves/Zotero/storage/Z4N7U7V4/w23668.html}
}

@article{finkelsteinSubsidizingHealthInsurance2019,
  title = {Subsidizing Health Insurance for Low-Income Adults: {{Evidence}} from {{Massachusetts}}},
  shorttitle = {Subsidizing Health Insurance for Low-Income Adults},
  author = {Finkelstein, Amy and Hendren, Nathaniel and Shepard, Mark},
  year = {2019},
  journal = {American Economic Review},
  volume = {109},
  number = {4},
  pages = {1530--67},
  file = {/Users/johngraves/Zotero/storage/Q6T7NSY8/Finkelstein et al. - 2019 - Subsidizing health insurance for low-income adults.pdf;/Users/johngraves/Zotero/storage/2FML4YYJ/articles.html}
}

@article{finkelsteinWelfareAnalysisMeets2020,
  title = {Welfare Analysis Meets Causal Inference},
  author = {Finkelstein, Amy and Hendren, Nathaniel},
  year = {2020},
  journal = {Journal of Economic Perspectives},
  volume = {34},
  number = {4},
  pages = {146--67},
  file = {/Users/johngraves/Zotero/storage/N3TATMLM/Finkelstein and Hendren - 2020 - Welfare analysis meets causal inference.pdf;/Users/johngraves/Zotero/storage/8KGDJ58M/articles.html}
}

@article{flightExpectedValueSample2022,
  title = {Expected {{Value}} of {{Sample Information}} to {{Guide}} the {{Design}} of {{Group Sequential Clinical Trials}}},
  author = {Flight, Laura and Julious, Steven and Brennan, Alan and Todd, Susan},
  year = {2022},
  month = may,
  journal = {Medical Decision Making: An International Journal of the Society for Medical Decision Making},
  volume = {42},
  number = {4},
  pages = {461--473},
  issn = {1552-681X},
  doi = {10.1177/0272989X211045036},
  abstract = {INTRODUCTION: Adaptive designs allow changes to an ongoing trial based on prespecified early examinations of accrued data. Opportunities are potentially being missed to incorporate health economic considerations into the design of these studies. METHODS: We describe how to estimate the expected value of sample information for group sequential design adaptive trials. We operationalize this approach in a hypothetical case study using data from a pilot trial. We report the expected value of sample information and expected net benefit of sampling results for 5 design options for the future full-scale trial including the fixed-sample-size design and the group sequential design using either the Pocock stopping rule or the O'Brien-Fleming stopping rule with 2 or 5 analyses. We considered 2 scenarios relating to 1) using the cost-effectiveness model with a traditional approach to the health economic analysis and 2) adjusting the cost-effectiveness analysis to incorporate the bias-adjusted maximum likelihood estimates of trial outcomes to account for the bias that can be generated in adaptive trials. RESULTS: The case study demonstrated that the methods developed could be successfully applied in practice. The results showed that the O'Brien-Fleming stopping rule with 2 analyses was the most efficient design with the highest expected net benefit of sampling in the case study. CONCLUSIONS: Cost-effectiveness considerations are unavoidable in budget-constrained, publicly funded health care systems, and adaptive designs can provide an alternative to costly fixed-sample-size designs. We recommend that when planning a clinical trial, expected value of sample information methods be used to compare possible adaptive and nonadaptive trial designs, with appropriate adjustment, to help justify the choice of design characteristics and ensure the cost-effective use of research funding. HIGHLIGHTS: Opportunities are potentially being missed to incorporate health economic considerations into the design of adaptive clinical trials.Existing expected value of sample information analysis methods can be extended to compare possible group sequential and nonadaptive trial designs when planning a clinical trial.We recommend that adjusted analyses be presented to control for the potential impact of the adaptive designs and to maintain the accuracy of the calculations.This approach can help to justify the choice of design characteristics and ensure the cost-effective use of limited research funding.},
  langid = {english},
  pmcid = {PMC9005835},
  pmid = {34859693},
  keywords = {adaptive designs,bias adjustment,clinical trials,Cost-Benefit Analysis,expected value of sample information,Humans,Research Design,Sample Size,value of information analysis},
  file = {/Users/johngraves/Zotero/storage/GHW2QMHA/Flight et al. - 2022 - Expected Value of Sample Information to Guide the .pdf}
}

@article{frandsenPartialIdentificationDistribution2021,
  title = {Partial Identification of the Distribution of Treatment Effects with an Application to the {{Knowledge}} Is {{Power Program}} ({{KIPP}})},
  author = {Frandsen, Brigham R. and Lefgren, Lars J.},
  year = {2021},
  journal = {Quantitative Economics},
  volume = {12},
  number = {1},
  pages = {143--171},
  publisher = {{Wiley Online Library}},
  file = {/Users/johngraves/Zotero/storage/KDPDX27K/QE1273.html}
}

@article{frankBestpossibleBoundsDistribution1987,
  title = {Best-Possible Bounds for the Distribution of a Sum \textemdash{} a Problem of {{Kolmogorov}}},
  author = {Frank, M. J. and Nelsen, R. B. and Schweizer, B.},
  year = {1987},
  month = jun,
  journal = {Probability Theory and Related Fields},
  volume = {74},
  number = {2},
  pages = {199--211},
  issn = {1432-2064},
  doi = {10.1007/BF00569989},
  urldate = {2023-03-26},
  abstract = {Recently, in answer to a question of Kolmogorov, G.D. Makarov obtained best-possible bounds for the distribution function of the sumX+Y of two random variables,X andY, whose individual distribution functions,FX andFY, are fixed. We show that these bounds follow directly from an inequality which has been known for some time. The techniques we employ, which are based on copulas and their properties, yield an insightful proof of the fact that these bounds are best-possible, settle the question of equality, and are computationally manageable. Furthermore, they extend to binary operations other than addition and to higher dimensions.},
  langid = {english},
  keywords = {Distribution Function,High Dimension,Mathematical Biology,Probability Theory,Stochastic Process}
}

@misc{garciaCriteriaEvaluatingSocial2022,
  title = {On {{Criteria}} for {{Evaluating Social Programs}}},
  author = {Garc{\'i}a, Jorge Luis and Heckman, James J.},
  year = {2022},
  month = apr,
  publisher = {{National Bureau of Economic Research}},
  urldate = {2022-12-22}
}

@misc{garciaThreeCriteriaEvaluating2022,
  type = {Working {{Paper}}},
  title = {Three {{Criteria}} for {{Evaluating Social Programs}}},
  author = {Garc{\'i}a, Jorge Luis and Heckman, James J.},
  year = {2022},
  month = sep,
  series = {Working {{Paper Series}}},
  number = {30507},
  eprint = {30507},
  publisher = {{National Bureau of Economic Research}},
  doi = {10.3386/w30507},
  urldate = {2022-12-22},
  abstract = {This paper examines the economic foundations of three criteria used for evaluating the costs and benefits of social programs. Some criteria do not consider the scale of programs or address the costs associated with programs that expand or contract the total government budget. A recent addition to the list of evaluation criteria\textendash the marginal value of public funds (MVPF)\textendash does not adopt a social optimality perspective. It evaluates the optimality of expenditures assuming a predetermined aggregate budget without considering the social costs of raising that budget.},
  archiveprefix = {National Bureau of Economic Research},
  file = {/Users/johngraves/Zotero/storage/2PV869XZ/García and Heckman - 2022 - Three Criteria for Evaluating Social Programs.pdf}
}

@article{garciaThreeCriteriaEvaluating2022a,
  title = {Three {{Criteria}} for {{Evaluating Social Programs}}},
  author = {Garc{\'i}a, Jorge Luis and Heckman, James Joseph},
  year = {2022/ed},
  journal = {Journal of Benefit-Cost Analysis},
  volume = {13},
  number = {3},
  pages = {281--286},
  publisher = {{Cambridge University Press}},
  issn = {2194-5888, 2152-2812},
  doi = {10.1017/bca.2022.18},
  urldate = {2022-12-22},
  abstract = {This article examines the economic foundations of three criteria used for evaluating the costs and benefits of social programs. Some criteria do not consider the scale of programs or address the costs associated with programs that expand or contract the total government budget. A recent addition to the list of evaluation criteria \textendash{} the marginal value of public funds \textendash{} does not adopt a social optimality perspective. It evaluates the optimality of expenditures assuming a predetermined aggregate budget without considering the social costs of raising that budget.},
  langid = {english},
  keywords = {cost-benefit analysis,D61,marginal value of public funds},
  file = {/Users/johngraves/Zotero/storage/MJYLNZTN/García and Heckman - 2022 - Three Criteria for Evaluating Social Programs.pdf}
}

@article{gravesDifferenceindifferencesCategoricalOutcomes2022,
  title = {Difference-in-Differences for Categorical Outcomes},
  author = {Graves, John A. and Fry, Carrie and McWilliams, J. Michael and Hatfield, Laura A.},
  year = {2022},
  journal = {Health Services Research},
  volume = {57},
  number = {3},
  pages = {681--692},
  publisher = {{Wiley Online Library}},
  file = {/Users/johngraves/Zotero/storage/CG7WFTUF/1475-6773.html}
}

@misc{gravesUnifiedApproachEx2021,
  type = {{{SSRN Scholarly Paper}}},
  title = {A {{Unified Approach}} for {{Ex Ante Policy Evaluation}}},
  author = {Graves, John},
  year = {2021},
  month = nov,
  number = {3957954},
  address = {{Rochester, NY}},
  urldate = {2022-12-05},
  abstract = {I articulate an approach for quantifying the opportunity cost of economic policy decisions made under evidentiary uncertainty. By estimating the expected welfare loss from decisions based on existing knowledge\textemdash which, given current (incomplete) information, may be inconsistent with social preferences\textemdash the approach can both inform current policy decisions and help refine priorities for future research. I use this framework to examine a central question in U.S. health reform debates: what are the comparative coverage and welfare impacts of expansion of in-kind health insurance programs (e.g., Medicaid) versus using tax credits or subsidies to facilitate the purchase of private insurance plans?},
  langid = {english},
  keywords = {decision analysis,Health insurance,health reform,value of information,welfare evaluation},
  file = {/Users/johngraves/Zotero/storage/X37GQ5BT/Graves - 2021 - A Unified Approach for Ex Ante Policy Evaluation.pdf;/Users/johngraves/Zotero/storage/7QVZHHUS/papers.html}
}

@article{heathCalculatingExpectedValue2018,
  title = {Calculating the Expected Value of Sample Information Using Efficient Nested {{Monte Carlo}}: {{A}} Tutorial},
  shorttitle = {Calculating the Expected Value of Sample Information Using Efficient Nested {{Monte Carlo}}},
  author = {Heath, Anna and Baio, Gianluca},
  year = {2018},
  journal = {Value in Health},
  volume = {21},
  number = {11},
  pages = {1299--1304},
  publisher = {{Elsevier}},
  file = {/Users/johngraves/Zotero/storage/QXHMJNZ5/S1098301518322010.html}
}

@article{heathCalculatingExpectedValue2020,
  title = {Calculating the {{Expected Value}} of {{Sample Information}} in {{Practice}}: {{Considerations}} from 3 {{Case Studies}}},
  shorttitle = {Calculating the {{Expected Value}} of {{Sample Information}} in {{Practice}}},
  author = {Heath, Anna and Kunst, Natalia and Jackson, Christopher and Strong, Mark and {Alarid-Escudero}, Fernando and {Goldhaber-Fiebert}, Jeremy D. and Baio, Gianluca and Menzies, Nicolas A. and Jalal, Hawre},
  year = {2020},
  month = apr,
  journal = {Medical Decision Making: An International Journal of the Society for Medical Decision Making},
  volume = {40},
  number = {3},
  pages = {314--326},
  issn = {1552-681X},
  doi = {10.1177/0272989X20912402},
  abstract = {Background. Investing efficiently in future research to improve policy decisions is an important goal. Expected value of sample information (EVSI) can be used to select the specific design and sample size of a proposed study by assessing the benefit of a range of different studies. Estimating EVSI with the standard nested Monte Carlo algorithm has a notoriously high computational burden, especially when using a complex decision model or when optimizing over study sample sizes and designs. Recently, several more efficient EVSI approximation methods have been developed. However, these approximation methods have not been compared, and therefore their comparative performance across different examples has not been explored. Methods. We compared 4 EVSI methods using 3 previously published health economic models. The examples were chosen to represent a range of real-world contexts, including situations with multiple study outcomes, missing data, and data from an observational rather than a randomized study. The computational speed and accuracy of each method were compared. Results. In each example, the approximation methods took minutes or hours to achieve reasonably accurate EVSI estimates, whereas the traditional Monte Carlo method took weeks. Specific methods are particularly suited to problems where we wish to compare multiple proposed sample sizes, when the proposed sample size is large, or when the health economic model is computationally expensive. Conclusions. As all the evaluated methods gave estimates similar to those given by traditional Monte Carlo, we suggest that EVSI can now be efficiently computed with confidence in realistic examples. No systematically superior EVSI computation method exists as the properties of the different methods depend on the underlying health economic model, data generation process, and user expertise.},
  langid = {english},
  pmcid = {PMC7968749},
  pmid = {32297840},
  keywords = {Case-Control Studies,computation methods,Cost-Benefit Analysis,Data Accuracy,expected value of sample information,health economic decision modelling,Humans,Models; Economic,Monte Carlo Method,study design,value of information},
  file = {/Users/johngraves/Zotero/storage/ILFXDFKF/Heath et al. - 2020 - Calculating the Expected Value of Sample Informati.pdf}
}

@article{heathEfficientMonteCarlo2018,
  title = {Efficient {{Monte Carlo Estimation}} of the {{Expected Value}} of {{Sample Information Using Moment Matching}}},
  author = {Heath, Anna and Manolopoulou, Ioanna and Baio, Gianluca},
  year = {2018},
  month = feb,
  journal = {Medical Decision Making},
  volume = {38},
  number = {2},
  pages = {163--173},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X17738515},
  urldate = {2022-12-05},
  abstract = {Background. The Expected Value of Sample Information (EVSI) is used to calculate the economic value of a new research strategy. Although this value would be important to both researchers and funders, there are very few practical applications of the EVSI. This is due to computational difficulties associated with calculating the EVSI in practical health economic models using nested simulations. Methods. We present an approximation method for the EVSI that is framed in a Bayesian setting and is based on estimating the distribution of the posterior mean of the incremental net benefit across all possible future samples, known as the distribution of the preposterior mean. Specifically, this distribution is estimated using moment matching coupled with simulations that are available for probabilistic sensitivity analysis, which is typically mandatory in health economic evaluations. Results. This novel approximation method is applied to a health economic model that has previously been used to assess the performance of other EVSI estimators and accurately estimates the EVSI. The computational time for this method is competitive with other methods. Conclusion. We have developed a new calculation method for the EVSI which is computationally efficient and accurate. Limitations. This novel method relies on some additional simulation so can be expensive in models with a large computational cost.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/EBZ32NXW/Heath et al. - 2018 - Efficient Monte Carlo Estimation of the Expected V.pdf}
}

@article{heathSimulatingStudyData2022,
  title = {Simulating Study Data to Support Expected Value of Sample Information Calculations: A Tutorial},
  shorttitle = {Simulating Study Data to Support Expected Value of Sample Information Calculations},
  author = {Heath, Anna and Strong, Mark and Glynn, David and Kunst, Natalia and Welton, Nicky J. and {Goldhaber-Fiebert}, Jeremy D.},
  year = {2022},
  journal = {Medical Decision Making},
  volume = {42},
  number = {2},
  pages = {143--155},
  publisher = {{SAGE Publications Sage CA: Los Angeles, CA}},
  file = {/Users/johngraves/Zotero/storage/TX4KZXBY/Heath et al. - 2022 - Simulating study data to support expected value of.pdf;/Users/johngraves/Zotero/storage/82B37SQK/0272989X211026292.html}
}

@article{heckmanMakingMostOut1997,
  title = {Making the {{Most Out}} of {{Programme Evaluations}} and {{Social Experiments}}: {{Accounting}} for {{Heterogeneity}} in {{Programme Impacts}}},
  shorttitle = {Making the {{Most Out}} of {{Programme Evaluations}} and {{Social Experiments}}},
  author = {Heckman, James J. and Smith, Jeffrey and Clements, Nancy},
  year = {1997},
  journal = {The Review of Economic Studies},
  volume = {64},
  number = {4},
  eprint = {2971729},
  eprinttype = {jstor},
  pages = {487--535},
  publisher = {{[Oxford University Press, Review of Economic Studies, Ltd.]}},
  issn = {0034-6527},
  doi = {10.2307/2971729},
  urldate = {2023-03-30},
  abstract = {The conventional approach to social programme evaluation focuses on estimating mean impacts of programmes. Yet many interesting questions regarding the political economy of programmes, the distribution of programme benefits and the option values conferred on programme participants require knowledge of the distribution of impacts, or features of it. This paper presents evidence that heterogeneity in response to programmes is empirically important and that classical probability inequalities are not very informative in producing estimates or bounds on the distribution of programme impacts. We explore two methods for supplementing the information in these inequalities based on assumptions about participant decision-making processes and about the strength in dependence between outcomes in the participation and non-participation states. Dependence is produced as a consequence of rational choice by participants. We test for stochastic rationality among programme participants and present and implement methods for estimating the option values of social programmes.},
  file = {/Users/johngraves/Zotero/storage/GHA38XNN/Heckman et al. - 1997 - Making the Most Out of Programme Evaluations and S.pdf}
}

@techreport{hendrenCaseUsingMVPF2022,
  title = {The {{Case}} for {{Using}} the {{MVPF}} in {{Empirical Welfare Analysis}}},
  author = {Hendren, Nathaniel and {Sprung-Keyser}, Ben},
  year = {2022},
  institution = {{National Bureau of Economic Research}},
  file = {/Users/johngraves/Zotero/storage/B2X42TAN/Hendren and Sprung-Keyser - 2022 - The Case for Using the MVPF in Empirical Welfare A.pdf;/Users/johngraves/Zotero/storage/7LZMY4NB/w30029.html}
}

@misc{hendrenCaseUsingMVPF2022a,
  type = {Working {{Paper}}},
  title = {The {{Case}} for {{Using}} the {{MVPF}} in {{Empirical Welfare Analysis}}},
  author = {Hendren, Nathaniel and {Sprung-Keyser}, Ben},
  year = {2022},
  month = may,
  series = {Working {{Paper Series}}},
  number = {30029},
  eprint = {30029},
  publisher = {{National Bureau of Economic Research}},
  doi = {10.3386/w30029},
  urldate = {2022-12-22},
  abstract = {This paper outlines the case for using the Marginal Value of Public Funds (MVPF) in empirical welfare analysis. It compares the MVPF approach with more traditional welfare metrics such as the Cost-Benefit Ratio and the Net Social Benefits criterion. It outlines the advantages of the MVPF approach relative to these metrics. In building the case for the MVPF, this paper also addresses several misconceptions about the MVPF that appear in recent literature.},
  archiveprefix = {National Bureau of Economic Research},
  file = {/Users/johngraves/Zotero/storage/VAXKQI8J/Hendren and Sprung-Keyser - 2022 - The Case for Using the MVPF in Empirical Welfare A.pdf}
}

@article{hendrenMeasuringEconomicEfficiency2020,
  title = {Measuring Economic Efficiency Using Inverse-Optimum Weights},
  author = {Hendren, Nathaniel},
  year = {2020},
  month = jul,
  journal = {Journal of Public Economics},
  volume = {187},
  pages = {104198},
  issn = {0047-2727},
  doi = {10.1016/j.jpubeco.2020.104198},
  urldate = {2022-12-05},
  abstract = {This paper provides a method to measure the traditional Kaldor-Hicks notion of ``economic efficiency'' when taxes affect behavior. In contrast to traditional unweighted surplus, measuring efficiency requires weighting individual benefits (or surplus) by the marginal cost to the government of providing a \$1 transfer at each income level. These weights correspond to the solution to the ``inverse-optimum'' program in the optimal tax literature: they are the social planning weights that would rationalize the status quo tax schedule as optimal. I estimate the weights using the universe of US income tax returns from 2012. The results suggest that measuring economic efficiency requires weighting surplus accruing to the poor roughly 1.5\textendash 2 times more than surplus accruing to the rich. This is because \$1 of surplus to the poor can be turned into roughly \$1.5\textendash\$2 of surplus to the rich by reducing the progressivity of the tax schedule. Following Kaldor and Hicks' original applications, I compare income distributions over time in the US and across countries. The results suggest US economic growth is 15\textendash 20\% lower due to increased inequality than is suggested by changes in GDP. Because of its higher inequality, the U.S. is unable to replicate the income distribution of countries like Austria and the Netherlands, despite having higher national income per capita.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/EBUTL8Q6/Hendren - 2020 - Measuring economic efficiency using inverse-optimu.pdf;/Users/johngraves/Zotero/storage/AM37K73E/S0047272720300621.html}
}

@article{hendrenPolicyElasticity2016,
  title = {The Policy Elasticity},
  author = {Hendren, Nathaniel},
  year = {2016},
  journal = {Tax Policy and the Economy},
  volume = {30},
  number = {1},
  pages = {51--89},
  publisher = {{University of Chicago Press Chicago, IL}},
  file = {/Users/johngraves/Zotero/storage/MK9FZ8RZ/Hendren - 2016 - The policy elasticity.pdf;/Users/johngraves/Zotero/storage/IDFMZQTQ/685593.html}
}

@article{hendrenUnifiedWelfareAnalysis2020,
  title = {A Unified Welfare Analysis of Government Policies},
  author = {Hendren, Nathaniel and {Sprung-Keyser}, Ben},
  year = {2020},
  journal = {The Quarterly Journal of Economics},
  volume = {135},
  number = {3},
  pages = {1209--1318},
  publisher = {{Oxford University Press}},
  file = {/Users/johngraves/Zotero/storage/BEC7R58A/5781614.html;/Users/johngraves/Zotero/storage/VU2LMBMB/5781614.html}
}

@book{imbensCausalInferenceStatistics2015,
  title = {Causal Inference in Statistics, Social, and Biomedical Sciences},
  author = {Imbens, Guido W. and Rubin, Donald B.},
  year = {2015},
  publisher = {{Cambridge University Press}},
  file = {/Users/johngraves/Zotero/storage/X4P8HNMW/Imbens and Rubin - 2015 - Causal inference in statistics, social, and biomed.pdf;/Users/johngraves/Zotero/storage/Y39YDLUR/books.html}
}

@article{jacksonValueInformationAnalysis2022,
  title = {Value of {{Information Analysis}} in {{Models}} to {{Inform Health Policy}}},
  author = {Jackson, Christopher H. and Baio, Gianluca and Heath, Anna and Strong, Mark and Welton, Nicky J. and Wilson, Edward C.F.},
  year = {2022},
  month = mar,
  journal = {Annual review of statistics and its application},
  volume = {9},
  pages = {95--118},
  issn = {2326-8298},
  doi = {10.1146/annurev-statistics-040120-010730},
  urldate = {2022-12-05},
  abstract = {Value of information (VoI) is a decision-theoretic approach to estimating the expected benefits from collecting further information of different kinds, in scientific problems based on combining one or more sources of data. VoI methods can assess the sensitivity of models to different sources of uncertainty and help to set priorities for further data collection. They have been widely applied in healthcare policy making, but the ideas are general to a range of evidence synthesis and decision problems. This article gives a broad overview of VoI methods, explaining the principles behind them, the range of problems that can be tackled with them, and how they can be implemented, and discusses the ongoing challenges in the area.},
  pmcid = {PMC7612603},
  pmid = {35415193},
  file = {/Users/johngraves/Zotero/storage/5E4QAJX8/Jackson et al. - 2022 - Value of Information Analysis in Models to Inform .pdf}
}

@article{kunstComputingExpectedValue2020,
  title = {Computing the {{Expected Value}} of {{Sample Information Efficiently}}: {{Practical Guidance}} and {{Recommendations}} for {{Four Model-Based Methods}}},
  shorttitle = {Computing the {{Expected Value}} of {{Sample Information Efficiently}}},
  author = {Kunst, Natalia and Wilson, Edward C. F. and Glynn, David and {Alarid-Escudero}, Fernando and Baio, Gianluca and Brennan, Alan and Fairley, Michael and {Goldhaber-Fiebert}, Jeremy D. and Jackson, Chris and Jalal, Hawre and Menzies, Nicolas A. and Strong, Mark and Thom, Howard and Heath, Anna},
  year = {2020},
  month = jun,
  journal = {Value in Health},
  volume = {23},
  number = {6},
  pages = {734--742},
  issn = {1098-3015},
  doi = {10.1016/j.jval.2020.02.010},
  urldate = {2022-12-05},
  abstract = {Value of information (VOI) analyses can help policy makers make informed decisions about whether to conduct and how to design future studies. Historically a computationally expensive method to compute the expected value of sample information (EVSI) restricted the use of VOI to simple decision models and study designs. Recently, 4 EVSI approximation methods have made such analyses more feasible and accessible. Members of the Collaborative Network for Value of Information (ConVOI) compared the inputs, the analyst's expertise and skills, and the software required for the 4 recently developed EVSI approximation methods. Our report provides practical guidance and recommendations to help inform the choice between the 4 efficient EVSI estimation methods. More specifically, this report provides: (1) a step-by-step guide to the methods' use, (2) the expertise and skills required to implement the methods, and (3) method recommendations based on the features of decision-analytic problems.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/88DXKIGY/Kunst et al. - 2020 - Computing the Expected Value of Sample Information.pdf;/Users/johngraves/Zotero/storage/BTL5IHPQ/S1098301520301492.html}
}

@article{kunstComputingExpectedValue2020a,
  title = {Computing the {{Expected Value}} of {{Sample Information Efficiently}}: {{Practical Guidance}} and {{Recommendations}} for {{Four Model-Based Methods}}},
  shorttitle = {Computing the {{Expected Value}} of {{Sample Information Efficiently}}},
  author = {Kunst, Natalia and Wilson, Edward C. F. and Glynn, David and {Alarid-Escudero}, Fernando and Baio, Gianluca and Brennan, Alan and Fairley, Michael and {Goldhaber-Fiebert}, Jeremy D. and Jackson, Chris and Jalal, Hawre and Menzies, Nicolas A. and Strong, Mark and Thom, Howard and Heath, Anna and {Collaborative Network for Value of Information}},
  year = {2020},
  month = jun,
  journal = {Value in Health: The Journal of the International Society for Pharmacoeconomics and Outcomes Research},
  volume = {23},
  number = {6},
  pages = {734--742},
  issn = {1524-4733},
  doi = {10.1016/j.jval.2020.02.010},
  abstract = {Value of information (VOI) analyses can help policy makers make informed decisions about whether to conduct and how to design future studies. Historically a computationally expensive method to compute the expected value of sample information (EVSI) restricted the use of VOI to simple decision models and study designs. Recently, 4 EVSI approximation methods have made such analyses more feasible and accessible. Members of the Collaborative Network for Value of Information (ConVOI) compared the inputs, the analyst's expertise and skills, and the software required for the 4 recently developed EVSI approximation methods. Our report provides practical guidance and recommendations to help inform the choice between the 4 efficient EVSI estimation methods. More specifically, this report provides: (1) a step-by-step guide to the methods' use, (2) the expertise and skills required to implement the methods, and (3) method recommendations based on the features of decision-analytic problems.},
  langid = {english},
  pmcid = {PMC8183576},
  pmid = {32540231},
  keywords = {Decision Making,Decision Support Techniques,Humans,Policy Making,Research,Research Design,Software},
  file = {/Users/johngraves/Zotero/storage/BLYJ4BXN/Kunst et al. - 2020 - Computing the Expected Value of Sample Information.pdf}
}

@article{linRegressionAnalysisIncomplete2003,
  title = {Regression Analysis of Incomplete Medical Cost Data},
  author = {Lin, D. Y.},
  year = {2003},
  journal = {Statistics in Medicine},
  volume = {22},
  number = {7},
  pages = {1181--1200},
  issn = {1097-0258},
  doi = {10.1002/sim.1377},
  urldate = {2022-12-09},
  abstract = {The accumulation of medical cost over time for each subject is an increasing stochastic process defined up to the instant of death. The stochastic structure of this process is complex. In most applications, the process can only be observed at a limited number of time points. Furthermore, the process is subject to right censoring so that it is unobservable after the censoring time. These special features of the medical cost data, especially the presence of death and censoring, pose major challenges in the construction of plausible statistical models and the development of the corresponding inference procedures. In this paper, we propose several classes of regression models which formulate the effects of possibly time-dependent covariates on the marginal mean of cost accumulation in the presence of death or on the conditional means of cost accumulation given specific survival patterns. We then develop estimating equations for these models by combining the approach of generalized estimating equations for longitudinal data with the inverse probability of censoring weighting technique. The resultant estimators are shown to be consistent and asymptotically normal with simple variance estimators. Simulation studies indicate that the proposed inference procedures behave well in practical situations. An application to data taken from a large cancer study reveals that the Medicare enrollees who are diagnosed with less aggressive ovarian cancer tend to accumulate medical cost at lower rates than those with more aggressive disease, but tend to have higher lifetime costs because they live longer. Copyright \textcopyright{} 2003 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {censoring,economic evaluation,generalized estimating equations,health care,inverse probability of censoring weighting,pattern-mixture models},
  file = {/Users/johngraves/Zotero/storage/4UPW65YQ/Lin - 2003 - Regression analysis of incomplete medical cost dat.pdf;/Users/johngraves/Zotero/storage/SKUDK2I7/sim.html}
}

@article{manskiMixingProblemProgramme1997,
  title = {The {{Mixing Problem}} in {{Programme Evaluation}}},
  author = {Manski, Charles F.},
  year = {1997},
  journal = {The Review of Economic Studies},
  volume = {64},
  number = {4},
  eprint = {2971730},
  eprinttype = {jstor},
  pages = {537--553},
  publisher = {{[Oxford University Press, Review of Economic Studies, Ltd.]}},
  issn = {0034-6527},
  doi = {10.2307/2971730},
  urldate = {2023-03-30},
  abstract = {A common concern of evaluation studies is to learn the distribution of outcomes when a specified treatment policy, or assignment rule, determines the treatment received by each member of a specified population. Recent studies have emphasized evaluation of policies providing the same treatment to all members of the population. In particular, experiments with randomized treatments have this objective. Social programmes mandating homogeneous treatment of the population are of interest, but so are ones in which treatment varies across the population. This paper examines the use of empirical evidence on programmes with homogeneous treatments to infer the outcomes that would occur if treatment were to vary across the population. Experimental evidence from the Perry Pre-school Project is used to illustrate the inferential problem and the main findings of the analysis.},
  file = {/Users/johngraves/Zotero/storage/VKM9DHPN/Manski - 1997 - The Mixing Problem in Programme Evaluation.pdf}
}

@article{mcfowlandiiiCommentaryCausalDecision2022,
  title = {Commentary on ``{{Causal Decision Making}} and {{Causal Effect Estimation Are Not}} the {{Same}}\ldots{} and {{Why It Matters}}''},
  author = {McFowland III, Edward},
  year = {2022},
  journal = {INFORMS Journal on Data Science},
  publisher = {{INFORMS}},
  file = {/Users/johngraves/Zotero/storage/L3WNC7YX/McFowland III - 2022 - Commentary on “Causal Decision Making and Causal E.pdf}
}

@misc{miratrixBoundingAccessibleMethod2017,
  title = {Bounding, an Accessible Method for Estimating Principal Causal Effects, Examined and Explained},
  author = {Miratrix, Luke and Furey, Jane and Feller, Avi and Grindal, Todd and Page, Lindsay C.},
  year = {2017},
  month = aug,
  number = {arXiv:1701.03139},
  eprint = {arXiv:1701.03139},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1701.03139},
  urldate = {2023-03-30},
  abstract = {Estimating treatment effects for subgroups defined by post-treatment behavior (i.e., estimating causal effects in a principal stratification framework) can be technically challenging and heavily reliant on strong assumptions. We investigate an alternative path: using bounds to identify ranges of possible effects that are consistent with the data. This simple approach relies on fewer assumptions and yet can result in policy-relevant findings. As we show, covariates can be used to substantially tighten bounds in a straightforward manner. Via simulation, we demonstrate which types of covariates are maximally beneficial. We conclude with an analysis of a multi-site experimental study of Early College High Schools. When examining the program's impact on students completing the ninth grade "on-track" for college, we find little impact for ECHS students who would otherwise attend a high quality high school, but substantial effects for those who would not. This suggests potential benefit in expanding these programs in areas primarily served by lower quality schools.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Applications,Statistics - Methodology},
  file = {/Users/johngraves/Zotero/storage/HK7DY9YS/Miratrix et al. - 2017 - Bounding, an accessible method for estimating prin.pdf;/Users/johngraves/Zotero/storage/WC8TBDVW/1701.html}
}

@article{miratrixBoundingAccessibleMethod2018,
  title = {Bounding, {{An Accessible Method}} for {{Estimating Principal Causal Effects}}, {{Examined}} and {{Explained}}},
  author = {Miratrix, Luke and Furey, Jane and Feller, Avi and Grindal, Todd and Page, Lindsay C.},
  year = {2018},
  month = jan,
  journal = {Journal of Research on Educational Effectiveness},
  volume = {11},
  number = {1},
  pages = {133--162},
  publisher = {{Routledge}},
  issn = {1934-5747},
  doi = {10.1080/19345747.2017.1379576},
  urldate = {2023-01-02},
  abstract = {Estimating treatment effects for subgroups defined by posttreatment behavior (i.e., estimating causal effects in a principal stratification framework) can be technically challenging and heavily reliant on strong assumptions. We investigate an alternative path: using bounds to identify ranges of possible effects that are consistent with the data. This simple approach relies on fewer assumptions and yet can result in policy-relevant findings. As we show, even moderately predictive covariates can be used to substantially tighten bounds in a straightforward manner. Via simulation, we demonstrate which types of covariates are maximally beneficial. We conclude with an analysis of a multisite experimental study of Early College High Schools. When examining the program's impact on students completing the ninth grade ``on-track'' for college, we find little impact for ECHS students who would otherwise attend a high-quality high school, but substantial effects for those who would not. This suggests a potential benefit in expanding these programs in areas primarily served by lower quality schools.},
  keywords = {Early College High Schools,Manski bounds,multisite randomized trials,noncompliance,principal stratification},
  file = {/Users/johngraves/Zotero/storage/SN4VPJTE/Miratrix et al. - 2018 - Bounding, An Accessible Method for Estimating Prin.pdf}
}

@article{pauldenCalculatingInterpretingICERs2020,
  title = {Calculating and {{Interpreting ICERs}} and {{Net Benefit}}},
  author = {Paulden, Mike},
  year = {2020},
  month = aug,
  journal = {PharmacoEconomics},
  volume = {38},
  number = {8},
  pages = {785--807},
  issn = {1179-2027},
  doi = {10.1007/s40273-020-00914-6},
  urldate = {2022-12-29},
  abstract = {For several decades, the incremental cost-effectiveness ratio has been routinely used by health technology assessment agencies around the world to summarise the results of economic evaluations of health interventions. Yet reporting and considering incremental cost-effectiveness ratios is unnecessary. Alternative summary measures exist, based on the concept of `net benefit'. The incremental cost-effectiveness ratio and measures of net benefit share several commonalities but some important distinctions. As a result, different methods are required to calculate and interpret incremental cost-effectiveness ratios compared to measures of net benefit. The aim of this practical application is to introduce readers to these methods, using a hypothetical example to illustrate key issues. First, the methods used to calculate each measure are described. Next, for each measure, consideration is made of whether and how each measure may be interpreted to perform the following tasks, each of which may be of interest to health technology assessment agencies: (1) identifying the single most cost-effective strategy; (2) ranking strategies from `most' to `least' cost-effective (on an ordinal scale); (3) determining the magnitude to which a strategy is more or less cost-effective than another strategy (on a cardinal scale); and (4) determining whether a strategy is more or less cost-effective following a sensitivity or scenario analysis. This practical application also introduces a novel approach for visually interpreting measures of net benefit using the cost-effectiveness plane, which addresses a number of limitations of the conventional cost-effectiveness `efficiency frontier'. By the end of this practical application, readers should have an understanding of how to calculate and interpret each measure, as well as the relative strengths and limitations of each.},
  langid = {english}
}

@article{raiffaAppliedStatisticalDecision1961,
  title = {Applied Statistical Decision Theory},
  author = {Raiffa, Howard and Schlaifer, Robert},
  year = {1961},
  publisher = {{Wiley New York}},
  file = {/Users/johngraves/Zotero/storage/EU43TN5I/493564.html}
}

@article{rotheryValueInformationAnalytical2020,
  title = {Value of {{Information Analytical Methods}}: {{Report}} 2 of the {{ISPOR Value}} of {{Information Analysis Emerging Good Practices Task Force}}},
  shorttitle = {Value of {{Information Analytical Methods}}},
  author = {Rothery, Claire and Strong, Mark and Koffijberg, Hendrik Erik and Basu, Anirban and Ghabri, Salah and Knies, Saskia and Murray, James F. and Sanders Schmidler, Gillian D. and Steuten, Lotte and Fenwick, Elisabeth},
  year = {2020},
  month = mar,
  journal = {Value in Health: The Journal of the International Society for Pharmacoeconomics and Outcomes Research},
  volume = {23},
  number = {3},
  pages = {277--286},
  issn = {1524-4733},
  doi = {10.1016/j.jval.2020.01.004},
  abstract = {The allocation of healthcare resources among competing priorities requires an assessment of the expected costs and health effects of investing resources in the activities and of the opportunity cost of the expenditure. To date, much effort has been devoted to assessing the expected costs and health effects, but there remains an important need to also reflect the consequences of uncertainty in resource allocation decisions and the value of further research to reduce uncertainty. Decision making with uncertainty may turn out to be suboptimal, resulting in health loss. Consequently, there may be value in reducing uncertainty, through the collection of new evidence, to better inform resource decisions. This value can be quantified using value of information (VOI) analysis. This report from the ISPOR VOI Task Force describes methods for computing 4 VOI measures: the expected value of perfect information, expected value of partial perfect information (EVPPI), expected value of sample information (EVSI), and expected net benefit of sampling (ENBS). Several methods exist for computing EVPPI and EVSI, and this report provides guidance on selecting the most appropriate method based on the features of the decision problem. The report provides a number of recommendations for good practice when planning, undertaking, or reviewing VOI analyses. The software needed to compute VOI is discussed, and areas for future research are highlighted.},
  langid = {english},
  pmcid = {PMC7373630},
  pmid = {32197720},
  keywords = {Consensus,Cost-Benefit Analysis,decision making,Decision Support Techniques,ENBS,EVPI,EVPPI,EVSI,Health Care Costs,Health Care Rationing,Health Priorities,Health Services Needs and Demand,Humans,Models; Statistical,Needs Assessment,Probability,study design,Technology Assessment; Biomedical,Uncertainty,value of information,value of research},
  file = {/Users/johngraves/Zotero/storage/K2D5VHZU/Rothery et al. - 2020 - Value of Information Analytical Methods Report 2 .pdf}
}

@article{rothWhenParallelTrends2023,
  title = {When Is Parallel Trends Sensitive to Functional Form?},
  author = {Roth, Jonathan and Sant'Anna, Pedro HC},
  year = {2023},
  journal = {Econometrica},
  volume = {91},
  number = {2},
  pages = {737--747},
  publisher = {{Wiley Online Library}},
  file = {/Users/johngraves/Zotero/storage/4HQJE2NH/Roth and Sant'Anna - 2023 - When is parallel trends sensitive to functional fo.pdf;/Users/johngraves/Zotero/storage/9KS8R7MF/ECTA19402.html}
}

@article{rubinTeachingStatisticalInference2004,
  title = {Teaching Statistical Inference for Causal Effects in Experiments and Observational Studies},
  author = {Rubin, Donald B.},
  year = {2004},
  journal = {Journal of Educational and Behavioral Statistics},
  volume = {29},
  number = {3},
  pages = {343--367},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  file = {/Users/johngraves/Zotero/storage/2KYN5ES3/Rubin - 2004 - Teaching statistical inference for causal effects .pdf}
}

@book{schlaiferAppliedStatisticalDecision1961,
  title = {Applied Statistical Decision Theory},
  author = {Schlaifer, Robert and Raiffa, Howard},
  year = {1961},
  file = {/Users/johngraves/Zotero/storage/ZL26RQ4Q/28468.html}
}

@article{shalitCommentaryCausalDecision2022,
  title = {Commentary on ``{{Causal Decision Making}} and {{Causal Effect Estimation Are Not}} the {{Same}}\ldots{} and {{Why It Matters}}''},
  author = {Shalit, Uri},
  year = {2022},
  journal = {INFORMS Journal on Data Science},
  publisher = {{INFORMS}},
  file = {/Users/johngraves/Zotero/storage/HC6WLJ7C/Shalit - 2022 - Commentary on “Causal Decision Making and Causal E.pdf}
}

@misc{SimulatingStudyData,
  title = {Simulating {{Study Data}} to {{Support Expected Value}} of {{Sample Information Calculations}}: {{A Tutorial}} - {{Anna Heath}}, {{Mark Strong}}, {{David Glynn}}, {{Natalia Kunst}}, {{Nicky J}}. {{Welton}}, {{Jeremy D}}. {{Goldhaber-Fiebert}}, 2022},
  urldate = {2023-01-10},
  howpublished = {https://journals.sagepub.com/doi/full/10.1177/0272989X211026292},
  file = {/Users/johngraves/Zotero/storage/3VJXJFLJ/0272989X211026292.html}
}

@misc{SimulatingStudyDataa,
  title = {Simulating {{Study Data}} to {{Support Expected Value}} of {{Sample Information Calculations}}: {{A Tutorial}}},
  shorttitle = {Simulating {{Study Data}} to {{Support Expected Value}} of {{Sample Information Calculations}}},
  doi = {10.1177/0272989X211026292},
  urldate = {2023-01-10},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/0272989X211026292},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/43SA6ZXN/Simulating Study Data to Support Expected Value of.pdf;/Users/johngraves/Zotero/storage/UBQNPA9Q/0272989X211026292.html}
}

@article{strongEstimatingExpectedValue2015,
  title = {Estimating the Expected Value of Sample Information Using the Probabilistic Sensitivity Analysis Sample: A Fast, Nonparametric Regression-Based Method},
  shorttitle = {Estimating the Expected Value of Sample Information Using the Probabilistic Sensitivity Analysis Sample},
  author = {Strong, Mark and Oakley, Jeremy E. and Brennan, Alan and Breeze, Penny},
  year = {2015},
  journal = {Medical Decision Making},
  volume = {35},
  number = {5},
  pages = {570--583},
  publisher = {{SAGE Publications Sage CA: Los Angeles, CA}},
  file = {/Users/johngraves/Zotero/storage/X8ANCIW9/Strong et al. - 2015 - Estimating the expected value of sample informatio.pdf;/Users/johngraves/Zotero/storage/C4N72PUN/0272989X15575286.html}
}

@article{strongEstimatingMultiparameterPartial2014,
  title = {Estimating Multiparameter Partial Expected Value of Perfect Information from a Probabilistic Sensitivity Analysis Sample: A Nonparametric Regression Approach},
  shorttitle = {Estimating Multiparameter Partial Expected Value of Perfect Information from a Probabilistic Sensitivity Analysis Sample},
  author = {Strong, Mark and Oakley, Jeremy E. and Brennan, Alan},
  year = {2014},
  journal = {Medical Decision Making},
  volume = {34},
  number = {3},
  pages = {311--326},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}}
}

@misc{TeachingStatisticalInference,
  title = {Teaching {{Statistical Inference}} for {{Causal Effects}} in {{Experiments}} and {{Observational Studies}} on {{JSTOR}}},
  eprint = {3701358},
  eprinttype = {jstor},
  urldate = {2023-03-28},
  howpublished = {https://www.jstor.org/stable/3701358},
  file = {/Users/johngraves/Zotero/storage/PEV98FWD/3701358.html}
}

@article{weinsteinCriticalRatiosEfficient1973,
  title = {Critical Ratios and Efficient Allocation},
  author = {Weinstein, Milton and Zeckhauser, Richard},
  year = {1973},
  month = apr,
  journal = {Journal of Public Economics},
  volume = {2},
  number = {2},
  pages = {147--157},
  issn = {00472727},
  doi = {10.1016/0047-2727(73)90002-9},
  urldate = {2022-12-29},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/BC2HU6PG/Weinstein and Zeckhauser - 1973 - Critical ratios and efficient allocation.pdf}
}

@article{weltonExpectedValueSample2014,
  title = {Expected Value of Sample Information for Multi-Arm Cluster Randomized Trials with Binary Outcomes},
  author = {Welton, Nicky J. and Madan, Jason J. and Caldwell, Deborah M. and Peters, Tim J. and Ades, Anthony E.},
  year = {2014},
  month = apr,
  journal = {Medical Decision Making: An International Journal of the Society for Medical Decision Making},
  volume = {34},
  number = {3},
  pages = {352--365},
  issn = {1552-681X},
  doi = {10.1177/0272989X13501229},
  abstract = {Expected value of sample information (EVSI) measures the anticipated net benefit gained from conducting new research with a specific design to add to the evidence on which reimbursement decisions are made. Cluster randomized trials raise specific issues for EVSI calculations because 1) a hierarchical model is necessary to account for between-cluster variability when incorporating new evidence and 2) heterogeneity between clusters needs to be carefully characterized in the cost-effectiveness analysis model. Multi-arm trials provide parameter estimates that are correlated, which needs to be accounted for in EVSI calculations. Furthermore, EVSI is computationally intensive when the net benefit function is nonlinear, due to the need for an inner-simulation step. We develop a method for the computation of EVSI that avoids the inner simulation step for cluster randomized multi-arm trials with a binary outcome, where the net benefit function is linear in the probability of an event but nonlinear in the log-odds ratio parameters. We motivate and illustrate the method with an example of a cluster randomized 2 \texttimes{} 2 factorial trial for interventions to increase attendance at breast screening in the UK, using a previously reported cost-effectiveness model. We highlight assumptions made in our approach, extensions to individually randomized trials and inclusion of covariates, and areas for further developments. We discuss computation time, the research-design space, and the ethical implications of an EVSI approach. We suggest that EVSI is a practical and appropriate tool for the design of cluster randomized trials.},
  langid = {english},
  pmid = {24085289},
  keywords = {Bayesian inference,Cluster Analysis,Cost-Benefit Analysis,heterogeneity,optimal trial design,Randomized Controlled Trials as Topic,sample size determination,value of information}
}

@article{williamsonProbabilisticArithmeticNumerical1990,
  title = {Probabilistic Arithmetic. {{I}}. {{Numerical}} Methods for Calculating Convolutions and Dependency Bounds},
  author = {Williamson, Robert C. and Downs, Tom},
  year = {1990},
  journal = {International journal of approximate reasoning},
  volume = {4},
  number = {2},
  pages = {89--158},
  publisher = {{Elsevier}},
  file = {/Users/johngraves/Zotero/storage/7I8P6Q8N/Williamson and Downs - 1990 - Probabilistic arithmetic. I. Numerical methods for.pdf;/Users/johngraves/Zotero/storage/MWTF8YWQ/0888613X9090022T.html}
}

@article{wilsonPracticalGuideValue2015,
  title = {A {{Practical Guide}} to {{Value}} of {{Information Analysis}}},
  author = {Wilson, Edward C. F.},
  year = {2015},
  month = feb,
  journal = {PharmacoEconomics},
  volume = {33},
  number = {2},
  pages = {105--121},
  issn = {1170-7690, 1179-2027},
  doi = {10.1007/s40273-014-0219-x},
  urldate = {2022-12-05},
  abstract = {Value of information analysis is a quantitative method to estimate the return on investment in proposed research projects. It can be used in a number of ways. Funders of research may find it useful to rank projects in terms of the expected return on investment from a variety of competing projects. Alternatively, trialists can use the principles to identify the efficient sample size of a proposed study as an alternative to traditional power calculations, and finally, a value of information analysis can be conducted alongside an economic evaluation as a quantitative adjunct to the `future research' or `next steps' section of a study write up. The purpose of this paper is to present a brief introduction to the methods, a step-by-step guide to calculation and a discussion of issues that arise in their application to healthcare decision making. Worked examples are provided in the accompanying online appendices as Microsoft Excel spreadsheets.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/RMSPMYBZ/Wilson - 2015 - A Practical Guide to Value of Information Analysis.pdf;/Users/johngraves/Zotero/storage/Q4VRI5IU/s40273-014-0219-x.html}
}
