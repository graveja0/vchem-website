@article{abbringEconometricEvaluationSocial2007,
  title = {Econometric Evaluation of Social Programs, Part {{III}}: {{Distributional}} Treatment Effects, Dynamic Treatment Effects, Dynamic Discrete Choice, and General Equilibrium Policy Evaluation},
  shorttitle = {Econometric Evaluation of Social Programs, Part {{III}}},
  author = {Abbring, Jaap H. and Heckman, James J.},
  year = {2007},
  journal = {Handbook of econometrics},
  volume = {6},
  pages = {5145--5303},
  publisher = {{Elsevier}},
  file = {/Users/johngraves/Zotero/storage/BRP6LY6M/S1573441207060722.html}
}

@misc{anandConstructionDALYImplications2019,
  type = {{{SSRN Scholarly Paper}}},
  title = {The {{Construction}} of the {{DALY}}: {{Implications}} and {{Anomalies}}},
  shorttitle = {The {{Construction}} of the {{DALY}}},
  author = {Anand, Sudhir and Reddy, Sanjay G.},
  year = {2019},
  month = aug,
  number = {3451311},
  address = {{Rochester, NY}},
  doi = {10.2139/ssrn.3451311},
  urldate = {2023-06-23},
  abstract = {The disability-adjusted life year (DALY) is a measure of aggregate ill-health whose construction depends on a counterfactual \textendash{} the number of life-years a person could have expected to live had she or he not died.  There are two ways of specifying the DALY counterfactual to estimate years of life lost (YLL) \textendash{} by employing an `exogenous' or an `endogenous' life table.  An exogenous life table is independent of the mortality risks experienced by the population whose health (longevity) is being assessed, whereas an endogenous life table is composed of precisely these risks.  Exogenous life tables have been used to construct the DALY in the Global Burden of Disease (GBD) studies \textendash{} with different exogenous life tables used in the GBD 1990 and GBD 2010 (and later) exercises.  However, an endogenous life table is more appropriate for predicting life-years lost from premature mortality in any given country, and allocating resources through health interventions there on the basis of DALYs averted.  Whether an exogenous or an endogenous life table is used, anomalies can arise.  Furthermore, the approach adopted in GBD 2010 onwards adds special difficulties of its own.  GBD 2010 and later GBDs use an exogenous reference life table which is the same for men and women.  This leads to an underestimation of the disease burden of women relative to that of men.},
  langid = {english},
  keywords = {burden of disease,counterfactual,Disability-adjusted life year (DALY),endogenous,exogenous,gender equity,health equity,health intervention,life expectancy,life table,morbidity,mortality,population health,Quality-adjusted life year (QALY),resource allocation,well-being},
  file = {/Users/johngraves/Zotero/storage/2MYVJDBQ/Anand and Reddy - 2019 - The Construction of the DALY Implications and Ano.pdf}
}

@article{baderNewApproachSample2018,
  title = {A New Approach for Sample Size Calculation in Cost-Effectiveness Studies Based on Value of Information},
  author = {Bader, Cl{\'e}ment and Cossin, S{\'e}bastien and Maillard, Aline and B{\'e}nard, Antoine},
  year = {2018},
  month = oct,
  journal = {BMC Medical Research Methodology},
  volume = {18},
  number = {1},
  pages = {113},
  issn = {1471-2288},
  doi = {10.1186/s12874-018-0571-1},
  urldate = {2022-12-28},
  abstract = {Value of information is now recognized as a reference method in the decision process underpinning cost-effectiveness evaluation. The expected value of perfect information (EVPI) is the expected value from completely reducing the uncertainty surrounding the cost-effectiveness of an innovative intervention.},
  keywords = {Clinical trials,Comparative studies,Cost-benefit analysis,Epidemiologic methods,Sample size,Value of information},
  file = {/Users/johngraves/Zotero/storage/2LAR6FDQ/Bader et al. - 2018 - A new approach for sample size calculation in cost.pdf;/Users/johngraves/Zotero/storage/YEEAR7UR/s12874-018-0571-1.html}
}

@article{blancoBoundsAverageQuantile2020,
  title = {Bounds on {{Average}} and {{Quantile Treatment Effects}} on {{Duration Outcomes Under Censoring}}, {{Selection}}, and {{Noncompliance}}},
  author = {Blanco, German and Chen, Xuan and Flores, Carlos A. and {Flores-Lagunes}, Alfonso},
  year = {2020},
  month = oct,
  journal = {Journal of Business \& Economic Statistics},
  volume = {38},
  number = {4},
  pages = {901--920},
  publisher = {{Taylor \& Francis}},
  issn = {0735-0015},
  doi = {10.1080/07350015.2019.1609975},
  urldate = {2023-01-09},
  abstract = {We consider the problem of assessing the effects of a treatment on duration outcomes using data from a randomized evaluation with noncompliance. For such settings, we derive nonparametric sharp bounds for average and quantile treatment effects addressing three pervasive problems simultaneously: self-selection into the spell of interest, endogenous censoring of the duration outcome, and noncompliance with the assigned treatment. Ignoring any of these issues could yield biased estimates of the effects. Notably, the proposed bounds do not impose the independent censoring assumption\textemdash which is commonly used to address censoring but is likely to fail in important settings\textemdash or exclusion restrictions to address endogeneity of censoring and selection. Instead, they employ monotonicity and stochastic dominance assumptions. To illustrate the use of these bounds we assess the effects of the Job Corps (JC) training program on its participants' last complete employment spell duration. Our estimated bounds suggest that JC participation may increase the average duration of the last complete employment spell before week 208 after randomization by at least 5.6 log points (5.8\%) for individuals who comply with their treatment assignment and experience a complete employment spell whether or not they enrolled in JC. The estimated quantile treatment effects suggest the impacts may be heterogeneous, and strengthen our conclusions based on the estimated average effects.},
  keywords = {Duration outcomes,Independent censoring,Job corps,Partial identification,Principal stratification},
  file = {/Users/johngraves/Zotero/storage/EX4AAQYB/Blanco et al. - 2020 - Bounds on Average and Quantile Treatment Effects o.pdf}
}

@misc{BlendedSurvivalCurves,
  title = {Blended {{Survival Curves}}: {{A New Approach}} to {{Extrapolation}} for {{Time-to-Event Outcomes}} from {{Clinical Trials}} in {{Health Technology Assessment}}},
  shorttitle = {Blended {{Survival Curves}}},
  doi = {10.1177/0272989X221134545},
  urldate = {2022-12-12},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/0272989X221134545},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/WGGTVIZH/Blended Survival Curves A New Approach to Extrapo.pdf;/Users/johngraves/Zotero/storage/AZ7VYGTP/0272989X221134545.html}
}

@misc{CalculatingDisabilityadjustedlifeyearsLost,
  title = {Calculating Disability-Adjusted-Life-Years Lost ({{DALYs}}) in Discrete-Time - {{PMC}}},
  urldate = {2023-06-28},
  howpublished = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3776440/}
}

@article{callawayBoundsDistributionalTreatment2021,
  title = {Bounds on Distributional Treatment Effect Parameters Using Panel Data with an Application on Job Displacement},
  author = {Callaway, Brantly},
  year = {2021},
  journal = {Journal of Econometrics},
  volume = {222},
  number = {2},
  pages = {861--881},
  publisher = {{Elsevier}},
  file = {/Users/johngraves/Zotero/storage/582AWV3C/S0304407620302839.html}
}

@article{callawayQuantileTreatmentEffects2019,
  title = {Quantile Treatment Effects in Difference in Differences Models with Panel Data},
  author = {Callaway, Brantly and Li, Tong},
  year = {2019},
  journal = {Quantitative Economics},
  volume = {10},
  number = {4},
  pages = {1579--1618},
  publisher = {{Wiley Online Library}},
  file = {/Users/johngraves/Zotero/storage/V6NYGF52/QE935.html}
}

@article{caswellHealthyLongevityIncidencebased2021,
  title = {Healthy Longevity from Incidence-Based Models},
  author = {Caswell, Hal and {van Daalen}, Silke},
  year = {2021},
  journal = {Demographic Research},
  volume = {45},
  pages = {397--452},
  publisher = {{JSTOR}},
  file = {/Users/johngraves/Zotero/storage/ZEC5VKZ7/Caswell and van Daalen - 2021 - Healthy longevity from incidence-based models.pdf;/Users/johngraves/Zotero/storage/HVS9B9CR/48640784.html}
}

@article{caswellMatrixMethodsHealth2018,
  title = {Matrix Methods in Health Demography: A New Approach to the Stochastic Analysis of Healthy Longevity and {{DALYs}}},
  shorttitle = {Matrix Methods in Health Demography},
  author = {Caswell, Hal and Zarulli, Virginia},
  year = {2018},
  journal = {Population health metrics},
  volume = {16},
  pages = {1--14},
  publisher = {{Springer}},
  file = {/Users/johngraves/Zotero/storage/EI7P7DWB/s12963-018-0165-5.html}
}

@misc{Chapter72Econometric,
  title = {Chapter 72 {{Econometric Evaluation}} of {{Social Programs}}, {{Part III}}: {{Distributional Treatment Effects}}, {{Dynamic Treatment Effects}}, {{Dynamic Discrete Choice}}, and {{General Equilibrium Policy Evaluation}} - {{ScienceDirect}}},
  urldate = {2023-03-26},
  howpublished = {https://www.sciencedirect.com/science/article/pii/S1573441207060722?casa\_token=izsFQNcF4HgAAAAA:-7MK5EYyQiwbaXzkYAKFU\_IT6UEUIjsVcwP6EUk8R1eQQ4Lo5lW3QUwIAIVAkhos2H5dyb2smQ},
  file = {/Users/johngraves/Zotero/storage/TUYJJNR7/S1573441207060722.html}
}

@article{chhatwalChangingCycleLengths2016,
  title = {Changing {{Cycle Lengths}} in {{State-Transition Models}}: {{Challenges}} and {{Solutions}}},
  shorttitle = {Changing {{Cycle Lengths}} in {{State-Transition Models}}},
  author = {Chhatwal, Jagpreet and Jayasuriya, Suren and Elbasha, Elamin H.},
  year = {2016},
  month = nov,
  journal = {Medical Decision Making},
  volume = {36},
  number = {8},
  pages = {952--964},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X16656165},
  urldate = {2023-05-17},
  abstract = {The choice of a cycle length in state-transition models should be determined by the frequency of clinical events and interventions. Sometimes there is need to decrease the cycle length of an existing state-transition model to reduce error in outcomes resulting from discretization of the underlying continuous-time phenomena or to increase the cycle length to gain computational efficiency. Cycle length conversion is also frequently required if a new state-transition model is built using observational data that have a different measurement interval than the model's cycle length. We show that a commonly used method of converting transition probabilities to different cycle lengths is incorrect and can provide imprecise estimates of model outcomes. We present an accurate approach that is based on finding the root of a transition probability matrix using eigendecomposition. We present underlying mathematical challenges of converting cycle length in state-transition models and provide numerical approximation methods when the eigendecomposition method fails. Several examples and analytical proofs show that our approach is more general and leads to more accurate estimates of model outcomes than the commonly used approach. MATLAB codes and a user-friendly online toolkit are made available for the implementation of the proposed methods.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/ZPACGMKL/Chhatwal et al. - 2016 - Changing Cycle Lengths in State-Transition Models.pdf}
}

@misc{cookDeterminingDistributionParameters2010,
  title = {Determining Distribution Parameters from Quantiles},
  author = {Cook,, John D.},
  year = {2010},
  month = jan,
  publisher = {{Working paper}},
  urldate = {2023-05-18},
  abstract = {Bayesian statistics often requires eliciting prior probabilities from subject matter experts who are unfamiliar with statistics. While most people an intuitive understanding of the mean of a probability distribution, fewer people understand variance as well, particularly in the context of asymmetric distributions. Prior beliefs may be more accurately captured by asking experts for quantiles rather than for means and variances. This note will explain how to solve for parameters so that common distributions satisfy two quantile conditions. We present algorithms for computing these parameters and point to corresponding software. The distributions discussed are normal, log normal, Cauchy, Weibull, gamma, and inverse gamma. The method given for the normal and Cauchy distributions applies more generally to any location-scale family}
}

@article{ecklesCommentaryCausalDecision2022,
  title = {Commentary on ``{{Causal Decision Making}} and {{Causal Effect Estimation Are Not}} the {{Same}}\ldots{} and {{Why It Matters}}'': {{On Loss Functions}} and {{Bias}}\textendash{{Variance Tradeoffs}} in {{Causal Estimation}} and {{Decisions}}},
  shorttitle = {Commentary on ``{{Causal Decision Making}} and {{Causal Effect Estimation Are Not}} the {{Same}}\ldots{} and {{Why It Matters}}''},
  author = {Eckles, Dean},
  year = {2022},
  journal = {INFORMS Journal on Data Science},
  publisher = {{INFORMS}},
  file = {/Users/johngraves/Zotero/storage/2YHUFQH3/Eckles - 2022 - Commentary on “Causal Decision Making and Causal E.pdf}
}

@misc{EstimatingLifetimeEpisode,
  title = {Estimating Lifetime or Episode-of-illness Costs under Censoring - {{Basu}} - 2010 - {{Health Economics}} - {{Wiley Online Library}}},
  urldate = {2022-12-09},
  howpublished = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hec.1640}
}

@article{fanCopulasEconometrics2014,
  title = {Copulas in Econometrics},
  author = {Fan, Yanqin and Patton, Andrew J.},
  year = {2014},
  journal = {Annual Review of Economics},
  volume = {6},
  number = {1},
  pages = {179--200},
  publisher = {{Annual Reviews}},
  file = {/Users/johngraves/Zotero/storage/RJ7ZMTSM/Fan and Patton - 2014 - Copulas in econometrics.pdf}
}

@article{fengUsingQALYsDALYs2020,
  title = {Using {{QALYs}} versus {{DALYs}} to Measure Cost-Effectiveness: {{How}} Much Does It Matter?},
  shorttitle = {Using {{QALYs}} versus {{DALYs}} to Measure Cost-Effectiveness},
  author = {Feng, Xue and Kim, David D. and Cohen, Joshua T. and Neumann, Peter J. and Ollendorf, Daniel A.},
  year = {2020},
  month = apr,
  journal = {International Journal of Technology Assessment in Health Care},
  volume = {36},
  number = {2},
  pages = {96--103},
  publisher = {{Cambridge University Press}},
  issn = {0266-4623, 1471-6348},
  doi = {10.1017/S0266462320000124},
  urldate = {2023-06-16},
  abstract = {ObjectivesQuality-adjusted life-years (QALYs) and disability-adjusted life-years (DALYs) are commonly used in cost-effectiveness analysis (CEA) to measure health benefits. We sought to quantify and explain differences between QALY- and DALY-based cost-effectiveness ratios, and explore whether using one versus the other would materially affect conclusions about an intervention's cost-effectiveness.MethodsWe identified CEAs using both QALYs and DALYs from the Tufts Medical Center CEA Registry and Global Health CEA Registry, with a supplemental search to ensure comprehensive literature coverage. We calculated absolute and relative differences between the QALY- and DALY-based ratios, and compared ratios to common benchmarks (e.g., 1\texttimes{} gross domestic product per capita). We converted reported costs into US dollars.ResultsAmong eleven published CEAs reporting both QALYs and DALYs, seven focused on pharmaceuticals and infectious disease, and five were conducted in high-income countries. Four studies concluded that the intervention was ``dominant'' (cost-saving). Among the QALY- and DALY-based ratios reported from the remaining seven studies, absolute differences ranged from approximately \$2 to \$15,000 per unit of benefit, and relative differences from 6\textendash 120 percent, but most differences were modest in comparison with the ratio value itself. The values assigned to utility and disability weights explained most observed differences. In comparison with cost-effectiveness thresholds, conclusions were consistent regardless of the ratio type in ten of eleven cases.ConclusionsOur results suggest that although QALY- and DALY-based ratios for the same intervention can differ, differences tend to be modest and do not materially affect comparisons to common cost-effectiveness thresholds.},
  langid = {english},
  keywords = {Cost-effectiveness analysis,DALY,Medical-decision,QALY},
  file = {/Users/johngraves/Zotero/storage/KGI4QY3N/Feng et al. - 2020 - Using QALYs versus DALYs to measure cost-effective.pdf}
}

@article{fernandez-loriaCausalDecisionMaking2022,
  title = {Causal Decision Making and Causal Effect Estimation Are Not the Same\ldots{} and Why It Matters},
  author = {{Fern{\'a}ndez-Lor{\'i}a}, Carlos and Provost, Foster},
  year = {2022},
  journal = {INFORMS Journal on Data Science},
  publisher = {{INFORMS}},
  file = {/Users/johngraves/Zotero/storage/VQKXSPHC/Fernández-Loría and Provost - 2022 - Causal decision making and causal effect estimatio.pdf;/Users/johngraves/Zotero/storage/CQQVJYLJ/ijds.2021.html}
}

@article{finkelsteinSubsidizingHealthInsurance2017,
  title = {Subsidizing {{Health Insurance}} for {{Low-Income Adults}}: {{Evidence}} from {{Massachusetts}}},
  shorttitle = {Subsidizing {{Health Insurance}} for {{Low-Income Adults}}},
  author = {Finkelstein, Amy and Hendren, Nathaniel and Shepard, Mark},
  year = {2017},
  month = aug,
  journal = {National Bureau of Economic Research Working Paper Series},
  number = {w23668},
  publisher = {{National Bureau of Economic Research}},
  urldate = {2020-08-03},
  file = {/Users/johngraves/Zotero/storage/S7UZC8PT/Finkelstein et al. - 2017 - Subsidizing Health Insurance for Low-Income Adults.pdf;/Users/johngraves/Zotero/storage/Z4N7U7V4/w23668.html}
}

@article{finkelsteinSubsidizingHealthInsurance2019,
  title = {Subsidizing Health Insurance for Low-Income Adults: {{Evidence}} from {{Massachusetts}}},
  shorttitle = {Subsidizing Health Insurance for Low-Income Adults},
  author = {Finkelstein, Amy and Hendren, Nathaniel and Shepard, Mark},
  year = {2019},
  journal = {American Economic Review},
  volume = {109},
  number = {4},
  pages = {1530--67},
  file = {/Users/johngraves/Zotero/storage/Q6T7NSY8/Finkelstein et al. - 2019 - Subsidizing health insurance for low-income adults.pdf;/Users/johngraves/Zotero/storage/2FML4YYJ/articles.html}
}

@article{finkelsteinWelfareAnalysisMeets2020,
  title = {Welfare Analysis Meets Causal Inference},
  author = {Finkelstein, Amy and Hendren, Nathaniel},
  year = {2020},
  journal = {Journal of Economic Perspectives},
  volume = {34},
  number = {4},
  pages = {146--67},
  file = {/Users/johngraves/Zotero/storage/N3TATMLM/Finkelstein and Hendren - 2020 - Welfare analysis meets causal inference.pdf;/Users/johngraves/Zotero/storage/8KGDJ58M/articles.html}
}

@article{flightExpectedValueSample2022,
  title = {Expected {{Value}} of {{Sample Information}} to {{Guide}} the {{Design}} of {{Group Sequential Clinical Trials}}},
  author = {Flight, Laura and Julious, Steven and Brennan, Alan and Todd, Susan},
  year = {2022},
  month = may,
  journal = {Medical Decision Making: An International Journal of the Society for Medical Decision Making},
  volume = {42},
  number = {4},
  pages = {461--473},
  issn = {1552-681X},
  doi = {10.1177/0272989X211045036},
  abstract = {INTRODUCTION: Adaptive designs allow changes to an ongoing trial based on prespecified early examinations of accrued data. Opportunities are potentially being missed to incorporate health economic considerations into the design of these studies. METHODS: We describe how to estimate the expected value of sample information for group sequential design adaptive trials. We operationalize this approach in a hypothetical case study using data from a pilot trial. We report the expected value of sample information and expected net benefit of sampling results for 5 design options for the future full-scale trial including the fixed-sample-size design and the group sequential design using either the Pocock stopping rule or the O'Brien-Fleming stopping rule with 2 or 5 analyses. We considered 2 scenarios relating to 1) using the cost-effectiveness model with a traditional approach to the health economic analysis and 2) adjusting the cost-effectiveness analysis to incorporate the bias-adjusted maximum likelihood estimates of trial outcomes to account for the bias that can be generated in adaptive trials. RESULTS: The case study demonstrated that the methods developed could be successfully applied in practice. The results showed that the O'Brien-Fleming stopping rule with 2 analyses was the most efficient design with the highest expected net benefit of sampling in the case study. CONCLUSIONS: Cost-effectiveness considerations are unavoidable in budget-constrained, publicly funded health care systems, and adaptive designs can provide an alternative to costly fixed-sample-size designs. We recommend that when planning a clinical trial, expected value of sample information methods be used to compare possible adaptive and nonadaptive trial designs, with appropriate adjustment, to help justify the choice of design characteristics and ensure the cost-effective use of research funding. HIGHLIGHTS: Opportunities are potentially being missed to incorporate health economic considerations into the design of adaptive clinical trials.Existing expected value of sample information analysis methods can be extended to compare possible group sequential and nonadaptive trial designs when planning a clinical trial.We recommend that adjusted analyses be presented to control for the potential impact of the adaptive designs and to maintain the accuracy of the calculations.This approach can help to justify the choice of design characteristics and ensure the cost-effective use of limited research funding.},
  langid = {english},
  pmcid = {PMC9005835},
  pmid = {34859693},
  keywords = {adaptive designs,bias adjustment,clinical trials,Cost-Benefit Analysis,expected value of sample information,Humans,Research Design,Sample Size,value of information analysis},
  file = {/Users/johngraves/Zotero/storage/GHW2QMHA/Flight et al. - 2022 - Expected Value of Sample Information to Guide the .pdf}
}

@article{fox-rushbyCalculatingPresentingDisability2001,
  title = {Calculating and Presenting Disability Adjusted Life Years ({{DALYs}}) in Cost-Effectiveness Analysis},
  author = {{Fox-Rushby}, J. A. and Hanson, K.},
  year = {2001},
  month = sep,
  journal = {Health Policy and Planning},
  volume = {16},
  number = {3},
  pages = {326--331},
  issn = {0268-1080},
  doi = {10.1093/heapol/16.3.326},
  abstract = {Disability adjusted life years (DALYs) are the sum of the present value of future years of lifetime lost through premature mortality, and the present value of years of future lifetime adjusted for the average severity (frequency and intensity) of any mental or physical disability caused by a disease or injury. They have been used as an outcome indicator in micro economic evaluations as well as sectoral prioritization exercises using league tables of cost-effectiveness. However, many of the current analyses are not comparable or transferable because either the assumptions used differ or are unclear, and because results are not presented in a way that allows researchers or policy-makers to re-calculate and re-interpret findings for use in an alternative context. However, at times there have also been miscalculations. This may happen either because evaluators disagree with the assumptions behind DALYs or because the methods of calculation have not been set out clearly. This paper shows how to calculate DALYs for cost-effectiveness analysis using a worked example. It also shows the impact of changing the age weighting and discount rates on estimates of cost-effectiveness, and suggests a set of minimum reporting criteria for using DALYs in cost-effectiveness analysis. Finally, readers are introduced briefly to a selected literature arguing for and against the use of DALYs.},
  langid = {english},
  pmid = {11527874},
  keywords = {Cost-Benefit Analysis,Disabled Persons,Humans,{Models, Statistical},Quality-Adjusted Life Years,United Kingdom,Value of Life},
  file = {/Users/johngraves/Zotero/storage/RW9SPC5P/Fox-Rushby and Hanson - 2001 - Calculating and presenting disability adjusted lif.pdf}
}

@article{frandsenPartialIdentificationDistribution2021,
  title = {Partial Identification of the Distribution of Treatment Effects with an Application to the {{Knowledge}} Is {{Power Program}} ({{KIPP}})},
  author = {Frandsen, Brigham R. and Lefgren, Lars J.},
  year = {2021},
  journal = {Quantitative Economics},
  volume = {12},
  number = {1},
  pages = {143--171},
  publisher = {{Wiley Online Library}},
  file = {/Users/johngraves/Zotero/storage/KDPDX27K/QE1273.html}
}

@article{frankBestpossibleBoundsDistribution1987,
  title = {Best-Possible Bounds for the Distribution of a Sum \textemdash{} a Problem of {{Kolmogorov}}},
  author = {Frank, M. J. and Nelsen, R. B. and Schweizer, B.},
  year = {1987},
  month = jun,
  journal = {Probability Theory and Related Fields},
  volume = {74},
  number = {2},
  pages = {199--211},
  issn = {1432-2064},
  doi = {10.1007/BF00569989},
  urldate = {2023-03-26},
  abstract = {Recently, in answer to a question of Kolmogorov, G.D. Makarov obtained best-possible bounds for the distribution function of the sumX+Y of two random variables,X andY, whose individual distribution functions,FX andFY, are fixed. We show that these bounds follow directly from an inequality which has been known for some time. The techniques we employ, which are based on copulas and their properties, yield an insightful proof of the fact that these bounds are best-possible, settle the question of equality, and are computationally manageable. Furthermore, they extend to binary operations other than addition and to higher dimensions.},
  langid = {english},
  keywords = {Distribution Function,High Dimension,Mathematical Biology,Probability Theory,Stochastic Process}
}

@misc{garciaCriteriaEvaluatingSocial2022,
  title = {On {{Criteria}} for {{Evaluating Social Programs}}},
  author = {Garc{\'i}a, Jorge Luis and Heckman, James J.},
  year = {2022},
  month = apr,
  publisher = {{National Bureau of Economic Research}},
  urldate = {2022-12-22}
}

@misc{garciaThreeCriteriaEvaluating2022,
  type = {Working {{Paper}}},
  title = {Three {{Criteria}} for {{Evaluating Social Programs}}},
  author = {Garc{\'i}a, Jorge Luis and Heckman, James J.},
  year = {2022},
  month = sep,
  series = {Working {{Paper Series}}},
  number = {30507},
  eprint = {30507},
  publisher = {{National Bureau of Economic Research}},
  doi = {10.3386/w30507},
  urldate = {2022-12-22},
  abstract = {This paper examines the economic foundations of three criteria used for evaluating the costs and benefits of social programs. Some criteria do not consider the scale of programs or address the costs associated with programs that expand or contract the total government budget. A recent addition to the list of evaluation criteria\textendash the marginal value of public funds (MVPF)\textendash does not adopt a social optimality perspective. It evaluates the optimality of expenditures assuming a predetermined aggregate budget without considering the social costs of raising that budget.},
  archiveprefix = {National Bureau of Economic Research},
  file = {/Users/johngraves/Zotero/storage/2PV869XZ/García and Heckman - 2022 - Three Criteria for Evaluating Social Programs.pdf}
}

@article{garciaThreeCriteriaEvaluating2022a,
  title = {Three {{Criteria}} for {{Evaluating Social Programs}}},
  author = {Garc{\'i}a, Jorge Luis and Heckman, James Joseph},
  year = {2022/ed},
  journal = {Journal of Benefit-Cost Analysis},
  volume = {13},
  number = {3},
  pages = {281--286},
  publisher = {{Cambridge University Press}},
  issn = {2194-5888, 2152-2812},
  doi = {10.1017/bca.2022.18},
  urldate = {2022-12-22},
  abstract = {This article examines the economic foundations of three criteria used for evaluating the costs and benefits of social programs. Some criteria do not consider the scale of programs or address the costs associated with programs that expand or contract the total government budget. A recent addition to the list of evaluation criteria \textendash{} the marginal value of public funds \textendash{} does not adopt a social optimality perspective. It evaluates the optimality of expenditures assuming a predetermined aggregate budget without considering the social costs of raising that budget.},
  langid = {english},
  keywords = {cost-benefit analysis,D61,marginal value of public funds},
  file = {/Users/johngraves/Zotero/storage/MJYLNZTN/García and Heckman - 2022 - Three Criteria for Evaluating Social Programs.pdf}
}

@misc{globalburdenofdiseasecollaborativenetworkGlobalBurdenDisease2020,
  title = {Global {{Burden}} of {{Disease Study}} 2019 ({{GBD}} 2019) {{Life Tables}} 1950-2019},
  author = {{Global Burden of Disease Collaborative Network}},
  year = {2020},
  publisher = {{Institute for Health Metrics and Evaluation (IHME)}},
  doi = {10.6069/1PF5-1M37},
  urldate = {2023-06-23},
  abstract = {"The Global Burden of Disease Study 2019 (GBD 2019), coordinated by the Institute for Health Metrics and Evaluation (IHME), estimated the burden of diseases, injuries, and risk factors for 204 countries and territories and selected subnational locations. This dataset contains life tables with estimates for life expectancy and probability of death by location, single calendar year, age group, and sex for 1950-2019. The life tables contain both estimates produced including deaths from natural disasters, wars, etc., as well as estimates produced without these types of deaths. Locations covered include both GBD locations and special regions such as World Bank Income Levels. Data used to produce these tables came from vital registration (VR) systems, sample registration systems, household surveys, censuses, disease surveillance, and demographic surveillance systems (DSS). For additional GBD results and resources, visit the GBD 2019 Data Resources page."}
}

@misc{globalburdenofdiseasecollaborativenetworkGlobalBurdenDisease2020a,
  title = {Global {{Burden}} of {{Disease Study}} 2019 ({{GBD}} 2019) {{Results}}.},
  author = {{Global Burden of Disease Collaborative Network}},
  year = {2020},
  publisher = {{Institute for Health Metrics and Evaluation (IHME)}}
}

@misc{globalburdenofdiseasecollaborativenetworkGlobalBurdenDisease2020b,
  title = {Global {{Burden}} of {{Disease Study}} 2019 ({{GBD}} 2019) {{Disability Weights}}},
  author = {{Global Burden of Disease Collaborative Network}},
  year = {2020},
  publisher = {{Institute for Health Metrics and Evaluation (IHME)}},
  doi = {10.6069/1W19-VX76},
  urldate = {2023-06-23},
  abstract = {"The Global Burden of Disease Study 2019 (GBD 2019), coordinated by the Institute for Health Metrics and Evaluation (IHME), estimated the burden of diseases, injuries, and risk factors for 204 countries and territories and selected subnational locations. Disability weights, which represent the magnitude of health loss associated with specific health outcomes, are used to calculate years lived with disability (YLD) for these outcomes in a given population. The weights are measured on a scale from 0 to 1, where 0 equals a state of full health and 1 equals death. This table provides disability weights for the 440 health states (including combined health states) used to estimate nonfatal health outcomes for the GBD 2019 study. For additional GBD results and resources, visit the GBD 2019 Data Resources page."}
}

@misc{globalburdenofdiseasecollaborativenetworkGlobalBurdenDisease2021a,
  title = {Global {{Burden}} of {{Disease Study}} 2019 ({{GBD}} 2019) {{Reference Life Table}}},
  author = {{Global Burden of Disease Collaborative Network}},
  year = {2021},
  publisher = {{Institute for Health Metrics and Evaluation (IHME)}},
  doi = {10.6069/1D4Y-YQ37},
  urldate = {2023-06-23},
  abstract = {The Global Burden of Disease Study 2019 (GBD 2019), coordinated by the Institute for Health Metrics and Evaluation (IHME), estimated the burden of diseases, injuries, and risk factors for 204 countries and territories and selected subnational locations. This reference life table, or theoretical minimum risk life table (TMRLT), is used in GBD to calculate years of life lost (YLLs) due to premature mortality. It was constructed based on the lowest observed age-specific mortality rates by location and sex across all estimation years from all locations with populations over 5 million in 2016. YLLs are computed by multiplying the number of estimated deaths by the reference life table's life expectancy at age of death. The table includes estimates for life expectancy at age x for ages 0 to 95+ at five-year intervals.}
}

@article{gravesDifferenceindifferencesCategoricalOutcomes2022,
  title = {Difference-in-Differences for Categorical Outcomes},
  author = {Graves, John A. and Fry, Carrie and McWilliams, J. Michael and Hatfield, Laura A.},
  year = {2022},
  journal = {Health Services Research},
  volume = {57},
  number = {3},
  pages = {681--692},
  publisher = {{Wiley Online Library}},
  file = {/Users/johngraves/Zotero/storage/CG7WFTUF/1475-6773.html}
}

@misc{gravesUnifiedApproachEx2021,
  type = {{{SSRN Scholarly Paper}}},
  title = {A {{Unified Approach}} for {{Ex Ante Policy Evaluation}}},
  author = {Graves, John},
  year = {2021},
  month = nov,
  number = {3957954},
  address = {{Rochester, NY}},
  urldate = {2022-12-05},
  abstract = {I articulate an approach for quantifying the opportunity cost of economic policy decisions made under evidentiary uncertainty. By estimating the expected welfare loss from decisions based on existing knowledge\textemdash which, given current (incomplete) information, may be inconsistent with social preferences\textemdash the approach can both inform current policy decisions and help refine priorities for future research. I use this framework to examine a central question in U.S. health reform debates: what are the comparative coverage and welfare impacts of expansion of in-kind health insurance programs (e.g., Medicaid) versus using tax credits or subsidies to facilitate the purchase of private insurance plans?},
  langid = {english},
  keywords = {decision analysis,Health insurance,health reform,value of information,welfare evaluation},
  file = {/Users/johngraves/Zotero/storage/X37GQ5BT/Graves - 2021 - A Unified Approach for Ex Ante Policy Evaluation.pdf;/Users/johngraves/Zotero/storage/7QVZHHUS/papers.html}
}

@article{greenHealthEconomicEvaluation2023,
  title = {Health {{Economic Evaluation Using Markov Models}} in {{R}} for {{Microsoft Excel Users}}: {{A Tutorial}}},
  shorttitle = {Health {{Economic Evaluation Using Markov Models}} in {{R}} for {{Microsoft Excel Users}}},
  author = {Green, Nathan and Lamrock, Felicity and Naylor, Nichola and Williams, Jack and Briggs, Andrew},
  year = {2023},
  journal = {PharmacoEconomics},
  volume = {41},
  number = {1},
  pages = {5--19},
  publisher = {{Springer}},
  file = {/Users/johngraves/Zotero/storage/HD98HUYM/s40273-022-01199-7.html}
}

@article{heathCalculatingExpectedValue2018,
  title = {Calculating the Expected Value of Sample Information Using Efficient Nested {{Monte Carlo}}: {{A}} Tutorial},
  shorttitle = {Calculating the Expected Value of Sample Information Using Efficient Nested {{Monte Carlo}}},
  author = {Heath, Anna and Baio, Gianluca},
  year = {2018},
  journal = {Value in Health},
  volume = {21},
  number = {11},
  pages = {1299--1304},
  publisher = {{Elsevier}},
  file = {/Users/johngraves/Zotero/storage/QXHMJNZ5/S1098301518322010.html}
}

@article{heathCalculatingExpectedValue2020,
  title = {Calculating the {{Expected Value}} of {{Sample Information}} in {{Practice}}: {{Considerations}} from 3 {{Case Studies}}},
  shorttitle = {Calculating the {{Expected Value}} of {{Sample Information}} in {{Practice}}},
  author = {Heath, Anna and Kunst, Natalia and Jackson, Christopher and Strong, Mark and {Alarid-Escudero}, Fernando and {Goldhaber-Fiebert}, Jeremy D. and Baio, Gianluca and Menzies, Nicolas A. and Jalal, Hawre},
  year = {2020},
  month = apr,
  journal = {Medical Decision Making: An International Journal of the Society for Medical Decision Making},
  volume = {40},
  number = {3},
  pages = {314--326},
  issn = {1552-681X},
  doi = {10.1177/0272989X20912402},
  abstract = {Background. Investing efficiently in future research to improve policy decisions is an important goal. Expected value of sample information (EVSI) can be used to select the specific design and sample size of a proposed study by assessing the benefit of a range of different studies. Estimating EVSI with the standard nested Monte Carlo algorithm has a notoriously high computational burden, especially when using a complex decision model or when optimizing over study sample sizes and designs. Recently, several more efficient EVSI approximation methods have been developed. However, these approximation methods have not been compared, and therefore their comparative performance across different examples has not been explored. Methods. We compared 4 EVSI methods using 3 previously published health economic models. The examples were chosen to represent a range of real-world contexts, including situations with multiple study outcomes, missing data, and data from an observational rather than a randomized study. The computational speed and accuracy of each method were compared. Results. In each example, the approximation methods took minutes or hours to achieve reasonably accurate EVSI estimates, whereas the traditional Monte Carlo method took weeks. Specific methods are particularly suited to problems where we wish to compare multiple proposed sample sizes, when the proposed sample size is large, or when the health economic model is computationally expensive. Conclusions. As all the evaluated methods gave estimates similar to those given by traditional Monte Carlo, we suggest that EVSI can now be efficiently computed with confidence in realistic examples. No systematically superior EVSI computation method exists as the properties of the different methods depend on the underlying health economic model, data generation process, and user expertise.},
  langid = {english},
  pmcid = {PMC7968749},
  pmid = {32297840},
  keywords = {Case-Control Studies,computation methods,Cost-Benefit Analysis,Data Accuracy,expected value of sample information,health economic decision modelling,Humans,{Models, Economic},Monte Carlo Method,study design,value of information},
  file = {/Users/johngraves/Zotero/storage/ILFXDFKF/Heath et al. - 2020 - Calculating the Expected Value of Sample Informati.pdf}
}

@article{heathEfficientMonteCarlo2018,
  title = {Efficient {{Monte Carlo Estimation}} of the {{Expected Value}} of {{Sample Information Using Moment Matching}}},
  author = {Heath, Anna and Manolopoulou, Ioanna and Baio, Gianluca},
  year = {2018},
  month = feb,
  journal = {Medical Decision Making},
  volume = {38},
  number = {2},
  pages = {163--173},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X17738515},
  urldate = {2022-12-05},
  abstract = {Background. The Expected Value of Sample Information (EVSI) is used to calculate the economic value of a new research strategy. Although this value would be important to both researchers and funders, there are very few practical applications of the EVSI. This is due to computational difficulties associated with calculating the EVSI in practical health economic models using nested simulations. Methods. We present an approximation method for the EVSI that is framed in a Bayesian setting and is based on estimating the distribution of the posterior mean of the incremental net benefit across all possible future samples, known as the distribution of the preposterior mean. Specifically, this distribution is estimated using moment matching coupled with simulations that are available for probabilistic sensitivity analysis, which is typically mandatory in health economic evaluations. Results. This novel approximation method is applied to a health economic model that has previously been used to assess the performance of other EVSI estimators and accurately estimates the EVSI. The computational time for this method is competitive with other methods. Conclusion. We have developed a new calculation method for the EVSI which is computationally efficient and accurate. Limitations. This novel method relies on some additional simulation so can be expensive in models with a large computational cost.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/EBZ32NXW/Heath et al. - 2018 - Efficient Monte Carlo Estimation of the Expected V.pdf}
}

@article{heathSimulatingStudyData2022,
  title = {Simulating Study Data to Support Expected Value of Sample Information Calculations: A Tutorial},
  shorttitle = {Simulating Study Data to Support Expected Value of Sample Information Calculations},
  author = {Heath, Anna and Strong, Mark and Glynn, David and Kunst, Natalia and Welton, Nicky J. and {Goldhaber-Fiebert}, Jeremy D.},
  year = {2022},
  journal = {Medical Decision Making},
  volume = {42},
  number = {2},
  pages = {143--155},
  publisher = {{SAGE Publications Sage CA: Los Angeles, CA}},
  file = {/Users/johngraves/Zotero/storage/TX4KZXBY/Heath et al. - 2022 - Simulating study data to support expected value of.pdf;/Users/johngraves/Zotero/storage/82B37SQK/0272989X211026292.html}
}

@article{heckmanMakingMostOut1997,
  title = {Making the {{Most Out}} of {{Programme Evaluations}} and {{Social Experiments}}: {{Accounting}} for {{Heterogeneity}} in {{Programme Impacts}}},
  shorttitle = {Making the {{Most Out}} of {{Programme Evaluations}} and {{Social Experiments}}},
  author = {Heckman, James J. and Smith, Jeffrey and Clements, Nancy},
  year = {1997},
  journal = {The Review of Economic Studies},
  volume = {64},
  number = {4},
  eprint = {2971729},
  eprinttype = {jstor},
  pages = {487--535},
  publisher = {{[Oxford University Press, Review of Economic Studies, Ltd.]}},
  issn = {0034-6527},
  doi = {10.2307/2971729},
  urldate = {2023-03-30},
  abstract = {The conventional approach to social programme evaluation focuses on estimating mean impacts of programmes. Yet many interesting questions regarding the political economy of programmes, the distribution of programme benefits and the option values conferred on programme participants require knowledge of the distribution of impacts, or features of it. This paper presents evidence that heterogeneity in response to programmes is empirically important and that classical probability inequalities are not very informative in producing estimates or bounds on the distribution of programme impacts. We explore two methods for supplementing the information in these inequalities based on assumptions about participant decision-making processes and about the strength in dependence between outcomes in the participation and non-participation states. Dependence is produced as a consequence of rational choice by participants. We test for stochastic rationality among programme participants and present and implement methods for estimating the option values of social programmes.},
  file = {/Users/johngraves/Zotero/storage/GHA38XNN/Heckman et al. - 1997 - Making the Most Out of Programme Evaluations and S.pdf}
}

@techreport{hendrenCaseUsingMVPF2022,
  title = {The {{Case}} for {{Using}} the {{MVPF}} in {{Empirical Welfare Analysis}}},
  author = {Hendren, Nathaniel and {Sprung-Keyser}, Ben},
  year = {2022},
  institution = {{National Bureau of Economic Research}},
  file = {/Users/johngraves/Zotero/storage/B2X42TAN/Hendren and Sprung-Keyser - 2022 - The Case for Using the MVPF in Empirical Welfare A.pdf;/Users/johngraves/Zotero/storage/7LZMY4NB/w30029.html}
}

@misc{hendrenCaseUsingMVPF2022a,
  type = {Working {{Paper}}},
  title = {The {{Case}} for {{Using}} the {{MVPF}} in {{Empirical Welfare Analysis}}},
  author = {Hendren, Nathaniel and {Sprung-Keyser}, Ben},
  year = {2022},
  month = may,
  series = {Working {{Paper Series}}},
  number = {30029},
  eprint = {30029},
  publisher = {{National Bureau of Economic Research}},
  doi = {10.3386/w30029},
  urldate = {2022-12-22},
  abstract = {This paper outlines the case for using the Marginal Value of Public Funds (MVPF) in empirical welfare analysis. It compares the MVPF approach with more traditional welfare metrics such as the Cost-Benefit Ratio and the Net Social Benefits criterion. It outlines the advantages of the MVPF approach relative to these metrics. In building the case for the MVPF, this paper also addresses several misconceptions about the MVPF that appear in recent literature.},
  archiveprefix = {National Bureau of Economic Research},
  file = {/Users/johngraves/Zotero/storage/VAXKQI8J/Hendren and Sprung-Keyser - 2022 - The Case for Using the MVPF in Empirical Welfare A.pdf}
}

@article{hendrenMeasuringEconomicEfficiency2020,
  title = {Measuring Economic Efficiency Using Inverse-Optimum Weights},
  author = {Hendren, Nathaniel},
  year = {2020},
  month = jul,
  journal = {Journal of Public Economics},
  volume = {187},
  pages = {104198},
  issn = {0047-2727},
  doi = {10.1016/j.jpubeco.2020.104198},
  urldate = {2022-12-05},
  abstract = {This paper provides a method to measure the traditional Kaldor-Hicks notion of ``economic efficiency'' when taxes affect behavior. In contrast to traditional unweighted surplus, measuring efficiency requires weighting individual benefits (or surplus) by the marginal cost to the government of providing a \$1 transfer at each income level. These weights correspond to the solution to the ``inverse-optimum'' program in the optimal tax literature: they are the social planning weights that would rationalize the status quo tax schedule as optimal. I estimate the weights using the universe of US income tax returns from 2012. The results suggest that measuring economic efficiency requires weighting surplus accruing to the poor roughly 1.5\textendash 2 times more than surplus accruing to the rich. This is because \$1 of surplus to the poor can be turned into roughly \$1.5\textendash\$2 of surplus to the rich by reducing the progressivity of the tax schedule. Following Kaldor and Hicks' original applications, I compare income distributions over time in the US and across countries. The results suggest US economic growth is 15\textendash 20\% lower due to increased inequality than is suggested by changes in GDP. Because of its higher inequality, the U.S. is unable to replicate the income distribution of countries like Austria and the Netherlands, despite having higher national income per capita.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/EBUTL8Q6/Hendren - 2020 - Measuring economic efficiency using inverse-optimu.pdf;/Users/johngraves/Zotero/storage/AM37K73E/S0047272720300621.html}
}

@article{hendrenPolicyElasticity2016,
  title = {The Policy Elasticity},
  author = {Hendren, Nathaniel},
  year = {2016},
  journal = {Tax Policy and the Economy},
  volume = {30},
  number = {1},
  pages = {51--89},
  publisher = {{University of Chicago Press Chicago, IL}},
  file = {/Users/johngraves/Zotero/storage/MK9FZ8RZ/Hendren - 2016 - The policy elasticity.pdf;/Users/johngraves/Zotero/storage/IDFMZQTQ/685593.html}
}

@article{hendrenUnifiedWelfareAnalysis2020,
  title = {A Unified Welfare Analysis of Government Policies},
  author = {Hendren, Nathaniel and {Sprung-Keyser}, Ben},
  year = {2020},
  journal = {The Quarterly Journal of Economics},
  volume = {135},
  number = {3},
  pages = {1209--1318},
  publisher = {{Oxford University Press}},
  file = {/Users/johngraves/Zotero/storage/BEC7R58A/5781614.html;/Users/johngraves/Zotero/storage/VU2LMBMB/5781614.html}
}

@book{highamFunctionsMatricesTheory2008,
  title = {Functions of Matrices: Theory and Computation},
  shorttitle = {Functions of Matrices},
  author = {Higham, Nicholas J.},
  year = {2008},
  publisher = {{SIAM}},
  file = {/Users/johngraves/Zotero/storage/4LUHMMXP/Higham - 2008 - Functions of matrices theory and computation.pdf}
}

@book{imbensCausalInferenceStatistics2015,
  title = {Causal Inference in Statistics, Social, and Biomedical Sciences},
  author = {Imbens, Guido W. and Rubin, Donald B.},
  year = {2015},
  publisher = {{Cambridge University Press}},
  file = {/Users/johngraves/Zotero/storage/X4P8HNMW/Imbens and Rubin - 2015 - Causal inference in statistics, social, and biomed.pdf;/Users/johngraves/Zotero/storage/Y39YDLUR/books.html}
}

@article{iosifescuFiniteMarkovProcesses1980,
  title = {Finite {{Markov Processes}} and {{Their Applications}}. {{Wiley}}},
  author = {Iosifescu, M.},
  year = {1980},
  journal = {New York}
}

@article{jacksonValueInformationAnalysis2022,
  title = {Value of {{Information Analysis}} in {{Models}} to {{Inform Health Policy}}},
  author = {Jackson, Christopher H. and Baio, Gianluca and Heath, Anna and Strong, Mark and Welton, Nicky J. and Wilson, Edward C.F.},
  year = {2022},
  month = mar,
  journal = {Annual review of statistics and its application},
  volume = {9},
  pages = {95--118},
  issn = {2326-8298},
  doi = {10.1146/annurev-statistics-040120-010730},
  urldate = {2022-12-05},
  abstract = {Value of information (VoI) is a decision-theoretic approach to estimating the expected benefits from collecting further information of different kinds, in scientific problems based on combining one or more sources of data. VoI methods can assess the sensitivity of models to different sources of uncertainty and help to set priorities for further data collection. They have been widely applied in healthcare policy making, but the ideas are general to a range of evidence synthesis and decision problems. This article gives a broad overview of VoI methods, explaining the principles behind them, the range of problems that can be tackled with them, and how they can be implemented, and discusses the ongoing challenges in the area.},
  pmcid = {PMC7612603},
  pmid = {35415193},
  file = {/Users/johngraves/Zotero/storage/5E4QAJX8/Jackson et al. - 2022 - Value of Information Analysis in Models to Inform .pdf}
}

@article{krijkampMultidimensionalArrayRepresentation2020,
  title = {A Multidimensional Array Representation of State-Transition Model Dynamics},
  author = {Krijkamp, Eline M. and {Alarid-Escudero}, Fernando and Enns, Eva A. and Pechlivanoglou, Petros and Hunink, MG Myriam and Yang, Alan and Jalal, Hawre J.},
  year = {2020},
  journal = {Medical Decision Making},
  volume = {40},
  number = {2},
  pages = {242--248},
  publisher = {{SAGE Publications Sage CA: Los Angeles, CA}},
  file = {/Users/johngraves/Zotero/storage/UINU44J4/Krijkamp et al. - 2020 - A multidimensional array representation of state-t.pdf}
}

@article{kunstComputingExpectedValue2020,
  title = {Computing the {{Expected Value}} of {{Sample Information Efficiently}}: {{Practical Guidance}} and {{Recommendations}} for {{Four Model-Based Methods}}},
  shorttitle = {Computing the {{Expected Value}} of {{Sample Information Efficiently}}},
  author = {Kunst, Natalia and Wilson, Edward C. F. and Glynn, David and {Alarid-Escudero}, Fernando and Baio, Gianluca and Brennan, Alan and Fairley, Michael and {Goldhaber-Fiebert}, Jeremy D. and Jackson, Chris and Jalal, Hawre and Menzies, Nicolas A. and Strong, Mark and Thom, Howard and Heath, Anna},
  year = {2020},
  month = jun,
  journal = {Value in Health},
  volume = {23},
  number = {6},
  pages = {734--742},
  issn = {1098-3015},
  doi = {10.1016/j.jval.2020.02.010},
  urldate = {2022-12-05},
  abstract = {Value of information (VOI) analyses can help policy makers make informed decisions about whether to conduct and how to design future studies. Historically a computationally expensive method to compute the expected value of sample information (EVSI) restricted the use of VOI to simple decision models and study designs. Recently, 4 EVSI approximation methods have made such analyses more feasible and accessible. Members of the Collaborative Network for Value of Information (ConVOI) compared the inputs, the analyst's expertise and skills, and the software required for the 4 recently developed EVSI approximation methods. Our report provides practical guidance and recommendations to help inform the choice between the 4 efficient EVSI estimation methods. More specifically, this report provides: (1) a step-by-step guide to the methods' use, (2) the expertise and skills required to implement the methods, and (3) method recommendations based on the features of decision-analytic problems.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/88DXKIGY/Kunst et al. - 2020 - Computing the Expected Value of Sample Information.pdf;/Users/johngraves/Zotero/storage/BTL5IHPQ/S1098301520301492.html}
}

@article{kunstComputingExpectedValue2020a,
  title = {Computing the {{Expected Value}} of {{Sample Information Efficiently}}: {{Practical Guidance}} and {{Recommendations}} for {{Four Model-Based Methods}}},
  shorttitle = {Computing the {{Expected Value}} of {{Sample Information Efficiently}}},
  author = {Kunst, Natalia and Wilson, Edward C. F. and Glynn, David and {Alarid-Escudero}, Fernando and Baio, Gianluca and Brennan, Alan and Fairley, Michael and {Goldhaber-Fiebert}, Jeremy D. and Jackson, Chris and Jalal, Hawre and Menzies, Nicolas A. and Strong, Mark and Thom, Howard and Heath, Anna and {Collaborative Network for Value of Information}},
  year = {2020},
  month = jun,
  journal = {Value in Health: The Journal of the International Society for Pharmacoeconomics and Outcomes Research},
  volume = {23},
  number = {6},
  pages = {734--742},
  issn = {1524-4733},
  doi = {10.1016/j.jval.2020.02.010},
  abstract = {Value of information (VOI) analyses can help policy makers make informed decisions about whether to conduct and how to design future studies. Historically a computationally expensive method to compute the expected value of sample information (EVSI) restricted the use of VOI to simple decision models and study designs. Recently, 4 EVSI approximation methods have made such analyses more feasible and accessible. Members of the Collaborative Network for Value of Information (ConVOI) compared the inputs, the analyst's expertise and skills, and the software required for the 4 recently developed EVSI approximation methods. Our report provides practical guidance and recommendations to help inform the choice between the 4 efficient EVSI estimation methods. More specifically, this report provides: (1) a step-by-step guide to the methods' use, (2) the expertise and skills required to implement the methods, and (3) method recommendations based on the features of decision-analytic problems.},
  langid = {english},
  pmcid = {PMC8183576},
  pmid = {32540231},
  keywords = {Decision Making,Decision Support Techniques,Humans,Policy Making,Research,Research Design,Software},
  file = {/Users/johngraves/Zotero/storage/BLYJ4BXN/Kunst et al. - 2020 - Computing the Expected Value of Sample Information.pdf}
}

@article{larsonCalculatingDisabilityadjustedlifeyearsLost2013,
  title = {Calculating Disability-Adjusted-Life-Years Lost ({{DALYs}}) in Discrete-Time},
  author = {Larson, Bruce A},
  year = {2013},
  month = aug,
  journal = {Cost Effectiveness and Resource Allocation : C/E},
  volume = {11},
  pages = {18},
  issn = {1478-7547},
  doi = {10.1186/1478-7547-11-18},
  urldate = {2023-06-28},
  abstract = {Disability-adjusted-life-years lost (DALYs) is a common outcome metric for cost-effectiveness analyses, and the equations used for such calculations have been presented previously by Fox-Rushby and Hanson (see, e.g., ``Health Policy and Planning 16:326\textendash 331, 2001''). While the equations are clear, the logic behind them is opaque at best for a large share of public health practitioners and students. The objective of this paper is to show how to calculate DALYs using a discrete time formulation that is easy to teach to students and public health practitioners, is easy to apply for those with basic discounting skills, and is consistent with the discounting methods typically included on the costing side of cost-effectiveness analysis. A continuous-time adjustment factor is derived that can be used to ensure exact consistency between the continuous and discrete time approaches, but this level of precision is typically unnecessary for cost-effectiveness analyses. To illustrate the approach, both a new, simple example and the same example presented in Fox-Rushby and Hanson are used throughout the paper.},
  pmcid = {PMC3776440},
  pmid = {23927817},
  file = {/Users/johngraves/Zotero/storage/AH6J6C8B/Larson - 2013 - Calculating disability-adjusted-life-years lost (D.pdf}
}

@article{linRegressionAnalysisIncomplete2003,
  title = {Regression Analysis of Incomplete Medical Cost Data},
  author = {Lin, D. Y.},
  year = {2003},
  journal = {Statistics in Medicine},
  volume = {22},
  number = {7},
  pages = {1181--1200},
  issn = {1097-0258},
  doi = {10.1002/sim.1377},
  urldate = {2022-12-09},
  abstract = {The accumulation of medical cost over time for each subject is an increasing stochastic process defined up to the instant of death. The stochastic structure of this process is complex. In most applications, the process can only be observed at a limited number of time points. Furthermore, the process is subject to right censoring so that it is unobservable after the censoring time. These special features of the medical cost data, especially the presence of death and censoring, pose major challenges in the construction of plausible statistical models and the development of the corresponding inference procedures. In this paper, we propose several classes of regression models which formulate the effects of possibly time-dependent covariates on the marginal mean of cost accumulation in the presence of death or on the conditional means of cost accumulation given specific survival patterns. We then develop estimating equations for these models by combining the approach of generalized estimating equations for longitudinal data with the inverse probability of censoring weighting technique. The resultant estimators are shown to be consistent and asymptotically normal with simple variance estimators. Simulation studies indicate that the proposed inference procedures behave well in practical situations. An application to data taken from a large cancer study reveals that the Medicare enrollees who are diagnosed with less aggressive ovarian cancer tend to accumulate medical cost at lower rates than those with more aggressive disease, but tend to have higher lifetime costs because they live longer. Copyright \textcopyright{} 2003 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {censoring,economic evaluation,generalized estimating equations,health care,inverse probability of censoring weighting,pattern-mixture models},
  file = {/Users/johngraves/Zotero/storage/4UPW65YQ/Lin - 2003 - Regression analysis of incomplete medical cost dat.pdf;/Users/johngraves/Zotero/storage/SKUDK2I7/sim.html}
}

@article{manskiMixingProblemProgramme1997,
  title = {The {{Mixing Problem}} in {{Programme Evaluation}}},
  author = {Manski, Charles F.},
  year = {1997},
  journal = {The Review of Economic Studies},
  volume = {64},
  number = {4},
  eprint = {2971730},
  eprinttype = {jstor},
  pages = {537--553},
  publisher = {{[Oxford University Press, Review of Economic Studies, Ltd.]}},
  issn = {0034-6527},
  doi = {10.2307/2971730},
  urldate = {2023-03-30},
  abstract = {A common concern of evaluation studies is to learn the distribution of outcomes when a specified treatment policy, or assignment rule, determines the treatment received by each member of a specified population. Recent studies have emphasized evaluation of policies providing the same treatment to all members of the population. In particular, experiments with randomized treatments have this objective. Social programmes mandating homogeneous treatment of the population are of interest, but so are ones in which treatment varies across the population. This paper examines the use of empirical evidence on programmes with homogeneous treatments to infer the outcomes that would occur if treatment were to vary across the population. Experimental evidence from the Perry Pre-school Project is used to illustrate the inferential problem and the main findings of the analysis.},
  file = {/Users/johngraves/Zotero/storage/VKM9DHPN/Manski - 1997 - The Mixing Problem in Programme Evaluation.pdf}
}

@article{mcfowlandiiiCommentaryCausalDecision2022,
  title = {Commentary on ``{{Causal Decision Making}} and {{Causal Effect Estimation Are Not}} the {{Same}}\ldots{} and {{Why It Matters}}''},
  author = {McFowland III, Edward},
  year = {2022},
  journal = {INFORMS Journal on Data Science},
  publisher = {{INFORMS}},
  file = {/Users/johngraves/Zotero/storage/L3WNC7YX/McFowland III - 2022 - Commentary on “Causal Decision Making and Causal E.pdf}
}

@misc{miratrixBoundingAccessibleMethod2017,
  title = {Bounding, an Accessible Method for Estimating Principal Causal Effects, Examined and Explained},
  author = {Miratrix, Luke and Furey, Jane and Feller, Avi and Grindal, Todd and Page, Lindsay C.},
  year = {2017},
  month = aug,
  number = {arXiv:1701.03139},
  eprint = {1701.03139},
  primaryclass = {stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1701.03139},
  urldate = {2023-03-30},
  abstract = {Estimating treatment effects for subgroups defined by post-treatment behavior (i.e., estimating causal effects in a principal stratification framework) can be technically challenging and heavily reliant on strong assumptions. We investigate an alternative path: using bounds to identify ranges of possible effects that are consistent with the data. This simple approach relies on fewer assumptions and yet can result in policy-relevant findings. As we show, covariates can be used to substantially tighten bounds in a straightforward manner. Via simulation, we demonstrate which types of covariates are maximally beneficial. We conclude with an analysis of a multi-site experimental study of Early College High Schools. When examining the program's impact on students completing the ninth grade "on-track" for college, we find little impact for ECHS students who would otherwise attend a high quality high school, but substantial effects for those who would not. This suggests potential benefit in expanding these programs in areas primarily served by lower quality schools.},
  archiveprefix = {arxiv},
  keywords = {Statistics - Applications,Statistics - Methodology},
  file = {/Users/johngraves/Zotero/storage/HK7DY9YS/Miratrix et al. - 2017 - Bounding, an accessible method for estimating prin.pdf;/Users/johngraves/Zotero/storage/WC8TBDVW/1701.html}
}

@article{miratrixBoundingAccessibleMethod2018,
  title = {Bounding, {{An Accessible Method}} for {{Estimating Principal Causal Effects}}, {{Examined}} and {{Explained}}},
  author = {Miratrix, Luke and Furey, Jane and Feller, Avi and Grindal, Todd and Page, Lindsay C.},
  year = {2018},
  month = jan,
  journal = {Journal of Research on Educational Effectiveness},
  volume = {11},
  number = {1},
  pages = {133--162},
  publisher = {{Routledge}},
  issn = {1934-5747},
  doi = {10.1080/19345747.2017.1379576},
  urldate = {2023-01-02},
  abstract = {Estimating treatment effects for subgroups defined by posttreatment behavior (i.e., estimating causal effects in a principal stratification framework) can be technically challenging and heavily reliant on strong assumptions. We investigate an alternative path: using bounds to identify ranges of possible effects that are consistent with the data. This simple approach relies on fewer assumptions and yet can result in policy-relevant findings. As we show, even moderately predictive covariates can be used to substantially tighten bounds in a straightforward manner. Via simulation, we demonstrate which types of covariates are maximally beneficial. We conclude with an analysis of a multisite experimental study of Early College High Schools. When examining the program's impact on students completing the ninth grade ``on-track'' for college, we find little impact for ECHS students who would otherwise attend a high-quality high school, but substantial effects for those who would not. This suggests a potential benefit in expanding these programs in areas primarily served by lower quality schools.},
  keywords = {Early College High Schools,Manski bounds,multisite randomized trials,noncompliance,principal stratification},
  file = {/Users/johngraves/Zotero/storage/SN4VPJTE/Miratrix et al. - 2018 - Bounding, An Accessible Method for Estimating Prin.pdf}
}

@article{molerNineteenDubiousWays2003,
  title = {Nineteen {{Dubious Ways}} to {{Compute}} the {{Exponential}} of a {{Matrix}}, {{Twenty-Five Years Later}}},
  author = {Moler, Cleve and Van Loan, Charles},
  year = {2003},
  month = jan,
  journal = {SIAM Review},
  volume = {45},
  number = {1},
  pages = {3--49},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/S00361445024180},
  urldate = {2023-06-21},
  langid = {english}
}

@book{murrayGlobalBurdenDisease1996,
  title = {The Global Burden of Disease: A Comprehensive Assessment of Mortality and Disability from Diseases, Injuries, and Risk Factors in 1990 and Projected to 2020: Summary},
  shorttitle = {The Global Burden of Disease},
  author = {Murray, Christopher JL and Lopez, Alan D. and Organization, World Health},
  year = {1996},
  publisher = {{World Health Organization}},
  file = {/Users/johngraves/Zotero/storage/AHR7JFAP/Murray et al. - 1996 - The global burden of disease a comprehensive asse.pdf}
}

@article{murrayRethinkingDALYs1996,
  title = {Rethinking {{DALYs}}},
  author = {Murray, Christopher JL},
  year = {1996},
  journal = {The global burden of disease},
  pages = {1--96},
  publisher = {{Harvard University Press}},
  file = {/Users/johngraves/Zotero/storage/425LSPWJ/1571417124535478528.html}
}

@article{oostvogelsUseDALYsEconomic2015,
  title = {Use of {{DALYs}} in Economic Analyses on Interventions for Infectious Diseases: A Systematic Review},
  shorttitle = {Use of {{DALYs}} in Economic Analyses on Interventions for Infectious Diseases},
  author = {Oostvogels, A. J. J. M. and De Wit, G. A. and Jahn, B. and Cassini, A. and Colzani, E. and De Waure, C. and Kretzschmar, M. E. E. and Siebert, U. and M{\"u}hlberger, N. and Mangen, M.-J. J.},
  year = {2015},
  month = jul,
  journal = {Epidemiology and Infection},
  volume = {143},
  number = {9},
  pages = {1791--1802},
  issn = {0950-2688, 1469-4409},
  doi = {10.1017/S0950268814001940},
  urldate = {2023-06-30},
  abstract = {SUMMARY             A systematic literature review was performed on full economic evaluations of infectious disease interventions using disability-adjusted life years (DALY) as outcome measure. The search was limited to the period between 1994 and September 2011 and conducted in Medline, SciSearch and EMBASE databases. We included 154 studies, mostly targeting HIV/AIDS and malaria with most conducted for African countries (40\%) and {$<$}10\% in high-income countries. Third-payer perspective was applied in 29\% of the studies, 25\% used the societal perspective and 12\% used both. Only 16\% of the studies took indirect effects (i.e. herd immunity) of interventions into account. Intervention, direct healthcare and indirect non-healthcare costs were taken into account in respectively 100\%, 81\% and 36\% of the studies. The majority of the studies followed the Global Burden of Disease method for DALY estimations, but most studies deviated from WHO cost-effectiveness guidelines. Better adherence to freely accessible guidelines will improve generalizability between full economic evaluations.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/9VCYZ2PR/Oostvogels et al. - 2015 - Use of DALYs in economic analyses on interventions.pdf}
}

@article{pauldenCalculatingInterpretingICERs2020,
  title = {Calculating and {{Interpreting ICERs}} and {{Net Benefit}}},
  author = {Paulden, Mike},
  year = {2020},
  month = aug,
  journal = {PharmacoEconomics},
  volume = {38},
  number = {8},
  pages = {785--807},
  issn = {1179-2027},
  doi = {10.1007/s40273-020-00914-6},
  urldate = {2022-12-29},
  abstract = {For several decades, the incremental cost-effectiveness ratio has been routinely used by health technology assessment agencies around the world to summarise the results of economic evaluations of health interventions. Yet reporting and considering incremental cost-effectiveness ratios is unnecessary. Alternative summary measures exist, based on the concept of `net benefit'. The incremental cost-effectiveness ratio and measures of net benefit share several commonalities but some important distinctions. As a result, different methods are required to calculate and interpret incremental cost-effectiveness ratios compared to measures of net benefit. The aim of this practical application is to introduce readers to these methods, using a hypothetical example to illustrate key issues. First, the methods used to calculate each measure are described. Next, for each measure, consideration is made of whether and how each measure may be interpreted to perform the following tasks, each of which may be of interest to health technology assessment agencies: (1) identifying the single most cost-effective strategy; (2) ranking strategies from `most' to `least' cost-effective (on an ordinal scale); (3) determining the magnitude to which a strategy is more or less cost-effective than another strategy (on a cardinal scale); and (4) determining whether a strategy is more or less cost-effective following a sensitivity or scenario analysis. This practical application also introduces a novel approach for visually interpreting measures of net benefit using the cost-effectiveness plane, which addresses a number of limitations of the conventional cost-effectiveness `efficiency frontier'. By the end of this practical application, readers should have an understanding of how to calculate and interpret each measure, as well as the relative strengths and limitations of each.},
  langid = {english}
}

@article{raiffaAppliedStatisticalDecision1961,
  title = {Applied Statistical Decision Theory},
  author = {Raiffa, Howard and Schlaifer, Robert},
  year = {1961},
  publisher = {{Wiley New York}},
  file = {/Users/johngraves/Zotero/storage/EU43TN5I/493564.html}
}

@article{rotheryValueInformationAnalytical2020,
  title = {Value of {{Information Analytical Methods}}: {{Report}} 2 of the {{ISPOR Value}} of {{Information Analysis Emerging Good Practices Task Force}}},
  shorttitle = {Value of {{Information Analytical Methods}}},
  author = {Rothery, Claire and Strong, Mark and Koffijberg, Hendrik Erik and Basu, Anirban and Ghabri, Salah and Knies, Saskia and Murray, James F. and Sanders Schmidler, Gillian D. and Steuten, Lotte and Fenwick, Elisabeth},
  year = {2020},
  month = mar,
  journal = {Value in Health: The Journal of the International Society for Pharmacoeconomics and Outcomes Research},
  volume = {23},
  number = {3},
  pages = {277--286},
  issn = {1524-4733},
  doi = {10.1016/j.jval.2020.01.004},
  abstract = {The allocation of healthcare resources among competing priorities requires an assessment of the expected costs and health effects of investing resources in the activities and of the opportunity cost of the expenditure. To date, much effort has been devoted to assessing the expected costs and health effects, but there remains an important need to also reflect the consequences of uncertainty in resource allocation decisions and the value of further research to reduce uncertainty. Decision making with uncertainty may turn out to be suboptimal, resulting in health loss. Consequently, there may be value in reducing uncertainty, through the collection of new evidence, to better inform resource decisions. This value can be quantified using value of information (VOI) analysis. This report from the ISPOR VOI Task Force describes methods for computing 4 VOI measures: the expected value of perfect information, expected value of partial perfect information (EVPPI), expected value of sample information (EVSI), and expected net benefit of sampling (ENBS). Several methods exist for computing EVPPI and EVSI, and this report provides guidance on selecting the most appropriate method based on the features of the decision problem. The report provides a number of recommendations for good practice when planning, undertaking, or reviewing VOI analyses. The software needed to compute VOI is discussed, and areas for future research are highlighted.},
  langid = {english},
  pmcid = {PMC7373630},
  pmid = {32197720},
  keywords = {Consensus,Cost-Benefit Analysis,decision making,Decision Support Techniques,ENBS,EVPI,EVPPI,EVSI,Health Care Costs,Health Care Rationing,Health Priorities,Health Services Needs and Demand,Humans,{Models, Statistical},Needs Assessment,Probability,study design,{Technology Assessment, Biomedical},Uncertainty,value of information,value of research},
  file = {/Users/johngraves/Zotero/storage/K2D5VHZU/Rothery et al. - 2020 - Value of Information Analytical Methods Report 2 .pdf}
}

@article{rothWhenParallelTrends2023,
  title = {When Is Parallel Trends Sensitive to Functional Form?},
  author = {Roth, Jonathan and Sant'Anna, Pedro HC},
  year = {2023},
  journal = {Econometrica},
  volume = {91},
  number = {2},
  pages = {737--747},
  publisher = {{Wiley Online Library}},
  file = {/Users/johngraves/Zotero/storage/4HQJE2NH/Roth and Sant'Anna - 2023 - When is parallel trends sensitive to functional fo.pdf;/Users/johngraves/Zotero/storage/9KS8R7MF/ECTA19402.html}
}

@article{rubinTeachingStatisticalInference2004,
  title = {Teaching Statistical Inference for Causal Effects in Experiments and Observational Studies},
  author = {Rubin, Donald B.},
  year = {2004},
  journal = {Journal of Educational and Behavioral Statistics},
  volume = {29},
  number = {3},
  pages = {343--367},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  file = {/Users/johngraves/Zotero/storage/2KYN5ES3/Rubin - 2004 - Teaching statistical inference for causal effects .pdf}
}

@article{sassiCalculatingQALYsComparing2006,
  title = {Calculating {{QALYs}}, Comparing {{QALY}} and {{DALY}} Calculations},
  author = {Sassi, F.},
  year = {2006},
  month = jul,
  journal = {Health Policy and Planning},
  volume = {21},
  number = {5},
  pages = {402--408},
  issn = {0268-1080, 1460-2237},
  doi = {10.1093/heapol/czl018},
  urldate = {2023-06-03},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/K43N9HVK/Sassi - 2006 - Calculating QALYs, comparing QALY and DALY calcula.pdf}
}

@book{schlaiferAppliedStatisticalDecision1961,
  title = {Applied Statistical Decision Theory},
  author = {Schlaifer, Robert and Raiffa, Howard},
  year = {1961},
  file = {/Users/johngraves/Zotero/storage/ZL26RQ4Q/28468.html}
}

@article{shalitCommentaryCausalDecision2022,
  title = {Commentary on ``{{Causal Decision Making}} and {{Causal Effect Estimation Are Not}} the {{Same}}\ldots{} and {{Why It Matters}}''},
  author = {Shalit, Uri},
  year = {2022},
  journal = {INFORMS Journal on Data Science},
  publisher = {{INFORMS}},
  file = {/Users/johngraves/Zotero/storage/HC6WLJ7C/Shalit - 2022 - Commentary on “Causal Decision Making and Causal E.pdf}
}

@misc{SimulatingStudyData,
  title = {Simulating {{Study Data}} to {{Support Expected Value}} of {{Sample Information Calculations}}: {{A Tutorial}} - {{Anna Heath}}, {{Mark Strong}}, {{David Glynn}}, {{Natalia Kunst}}, {{Nicky J}}. {{Welton}}, {{Jeremy D}}. {{Goldhaber-Fiebert}}, 2022},
  urldate = {2023-01-10},
  howpublished = {https://journals.sagepub.com/doi/full/10.1177/0272989X211026292},
  file = {/Users/johngraves/Zotero/storage/3VJXJFLJ/0272989X211026292.html}
}

@misc{SimulatingStudyDataa,
  title = {Simulating {{Study Data}} to {{Support Expected Value}} of {{Sample Information Calculations}}: {{A Tutorial}}},
  shorttitle = {Simulating {{Study Data}} to {{Support Expected Value}} of {{Sample Information Calculations}}},
  doi = {10.1177/0272989X211026292},
  urldate = {2023-01-10},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/0272989X211026292},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/43SA6ZXN/Simulating Study Data to Support Expected Value of.pdf;/Users/johngraves/Zotero/storage/UBQNPA9Q/0272989X211026292.html}
}

@article{strongEstimatingExpectedValue2015,
  title = {Estimating the Expected Value of Sample Information Using the Probabilistic Sensitivity Analysis Sample: A Fast, Nonparametric Regression-Based Method},
  shorttitle = {Estimating the Expected Value of Sample Information Using the Probabilistic Sensitivity Analysis Sample},
  author = {Strong, Mark and Oakley, Jeremy E. and Brennan, Alan and Breeze, Penny},
  year = {2015},
  journal = {Medical Decision Making},
  volume = {35},
  number = {5},
  pages = {570--583},
  publisher = {{SAGE Publications Sage CA: Los Angeles, CA}},
  file = {/Users/johngraves/Zotero/storage/X8ANCIW9/Strong et al. - 2015 - Estimating the expected value of sample informatio.pdf;/Users/johngraves/Zotero/storage/C4N72PUN/0272989X15575286.html}
}

@article{strongEstimatingMultiparameterPartial2014,
  title = {Estimating Multiparameter Partial Expected Value of Perfect Information from a Probabilistic Sensitivity Analysis Sample: A Nonparametric Regression Approach},
  shorttitle = {Estimating Multiparameter Partial Expected Value of Perfect Information from a Probabilistic Sensitivity Analysis Sample},
  author = {Strong, Mark and Oakley, Jeremy E. and Brennan, Alan},
  year = {2014},
  journal = {Medical Decision Making},
  volume = {34},
  number = {3},
  pages = {311--326},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}}
}

@misc{TeachingStatisticalInference,
  title = {Teaching {{Statistical Inference}} for {{Causal Effects}} in {{Experiments}} and {{Observational Studies}} on {{JSTOR}}},
  eprint = {3701358},
  eprinttype = {jstor},
  urldate = {2023-03-28},
  howpublished = {https://www.jstor.org/stable/3701358},
  file = {/Users/johngraves/Zotero/storage/PEV98FWD/3701358.html}
}

@article{weinsteinCriticalRatiosEfficient1973,
  title = {Critical Ratios and Efficient Allocation},
  author = {Weinstein, Milton and Zeckhauser, Richard},
  year = {1973},
  month = apr,
  journal = {Journal of Public Economics},
  volume = {2},
  number = {2},
  pages = {147--157},
  issn = {00472727},
  doi = {10.1016/0047-2727(73)90002-9},
  urldate = {2022-12-29},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/BC2HU6PG/Weinstein and Zeckhauser - 1973 - Critical ratios and efficient allocation.pdf}
}

@article{weltonExpectedValueSample2014,
  title = {Expected Value of Sample Information for Multi-Arm Cluster Randomized Trials with Binary Outcomes},
  author = {Welton, Nicky J. and Madan, Jason J. and Caldwell, Deborah M. and Peters, Tim J. and Ades, Anthony E.},
  year = {2014},
  month = apr,
  journal = {Medical Decision Making: An International Journal of the Society for Medical Decision Making},
  volume = {34},
  number = {3},
  pages = {352--365},
  issn = {1552-681X},
  doi = {10.1177/0272989X13501229},
  abstract = {Expected value of sample information (EVSI) measures the anticipated net benefit gained from conducting new research with a specific design to add to the evidence on which reimbursement decisions are made. Cluster randomized trials raise specific issues for EVSI calculations because 1) a hierarchical model is necessary to account for between-cluster variability when incorporating new evidence and 2) heterogeneity between clusters needs to be carefully characterized in the cost-effectiveness analysis model. Multi-arm trials provide parameter estimates that are correlated, which needs to be accounted for in EVSI calculations. Furthermore, EVSI is computationally intensive when the net benefit function is nonlinear, due to the need for an inner-simulation step. We develop a method for the computation of EVSI that avoids the inner simulation step for cluster randomized multi-arm trials with a binary outcome, where the net benefit function is linear in the probability of an event but nonlinear in the log-odds ratio parameters. We motivate and illustrate the method with an example of a cluster randomized 2 \texttimes{} 2 factorial trial for interventions to increase attendance at breast screening in the UK, using a previously reported cost-effectiveness model. We highlight assumptions made in our approach, extensions to individually randomized trials and inclusion of covariates, and areas for further developments. We discuss computation time, the research-design space, and the ethical implications of an EVSI approach. We suggest that EVSI is a practical and appropriate tool for the design of cluster randomized trials.},
  langid = {english},
  pmid = {24085289},
  keywords = {Bayesian inference,Cluster Analysis,Cost-Benefit Analysis,heterogeneity,optimal trial design,Randomized Controlled Trials as Topic,sample size determination,value of information}
}

@article{williamsonProbabilisticArithmeticNumerical1990,
  title = {Probabilistic Arithmetic. {{I}}. {{Numerical}} Methods for Calculating Convolutions and Dependency Bounds},
  author = {Williamson, Robert C. and Downs, Tom},
  year = {1990},
  journal = {International journal of approximate reasoning},
  volume = {4},
  number = {2},
  pages = {89--158},
  publisher = {{Elsevier}},
  file = {/Users/johngraves/Zotero/storage/7I8P6Q8N/Williamson and Downs - 1990 - Probabilistic arithmetic. I. Numerical methods for.pdf;/Users/johngraves/Zotero/storage/MWTF8YWQ/0888613X9090022T.html}
}

@article{wilsonPracticalGuideValue2015,
  title = {A {{Practical Guide}} to {{Value}} of {{Information Analysis}}},
  author = {Wilson, Edward C. F.},
  year = {2015},
  month = feb,
  journal = {PharmacoEconomics},
  volume = {33},
  number = {2},
  pages = {105--121},
  issn = {1170-7690, 1179-2027},
  doi = {10.1007/s40273-014-0219-x},
  urldate = {2022-12-05},
  abstract = {Value of information analysis is a quantitative method to estimate the return on investment in proposed research projects. It can be used in a number of ways. Funders of research may find it useful to rank projects in terms of the expected return on investment from a variety of competing projects. Alternatively, trialists can use the principles to identify the efficient sample size of a proposed study as an alternative to traditional power calculations, and finally, a value of information analysis can be conducted alongside an economic evaluation as a quantitative adjunct to the `future research' or `next steps' section of a study write up. The purpose of this paper is to present a brief introduction to the methods, a step-by-step guide to calculation and a discussion of issues that arise in their application to healthcare decision making. Worked examples are provided in the accompanying online appendices as Microsoft Excel spreadsheets.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/RMSPMYBZ/Wilson - 2015 - A Practical Guide to Value of Information Analysis.pdf;/Users/johngraves/Zotero/storage/Q4VRI5IU/s40273-014-0219-x.html}
}

@article{wuCosteffectivenessAnalysisColorectal2006,
  title = {Cost-Effectiveness Analysis of Colorectal Cancer Screening with Stool {{DNA}} Testing in Intermediate-Incidence Countries},
  author = {Wu, Grace Hui-Min and Wang, Yi-Ming and Yen, Amy Ming-Fang and Wong, Jau-Min and Lai, Hsin-Chih and Warwick, Jane and Chen, Tony Hsiu-Hsi},
  year = {2006},
  journal = {BMC cancer},
  volume = {6},
  number = {1},
  pages = {1--12},
  publisher = {{BioMed Central}},
  file = {/Users/johngraves/Zotero/storage/7FRMNE68/1471-2407-6-136.html}
}

@misc{cookDeterminingDistributionParameters2010,
  title = {Determining Distribution Parameters from Quantiles},
  author = {Cook,, John D.},
  year = {2010},
  month = jan,
  publisher = {{Working paper}},
  urldate = {2023-05-18},
  abstract = {Bayesian statistics often requires eliciting prior probabilities from subject matter experts who are unfamiliar with statistics. While most people an intuitive understanding of the mean of a probability distribution, fewer people understand variance as well, particularly in the context of asymmetric distributions. Prior beliefs may be more accurately captured by asking experts for quantiles rather than for means and variances. This note will explain how to solve for parameters so that common distributions satisfy two quantile conditions. We present algorithms for computing these parameters and point to corresponding software. The distributions discussed are normal, log normal, Cauchy, Weibull, gamma, and inverse gamma. The method given for the normal and Cauchy distributions applies more generally to any location-scale family}
}


@book{neumann2016,
	title = {Cost-effectiveness in health and medicine},
	author = {Neumann, Peter J. and Sanders, Gillian D. and Russell, Louise B. and Siegel, Joanna E. and Ganiats, Theodore G.},
	year = {2016},
	date = {2016},
	publisher = {Oxford University Press}
}

@book{caro2015,
	title = {Discrete event simulation for health technology assessment},
	author = {Caro, J. Jaime and {Möller}, {Jörgen} and Karnon, Jonathan and Stahl, James and Ishak, Jack},
	year = {2015},
	date = {2015},
	publisher = {CRC press}
}

@book{drummond2015,
	title = {Methods for the economic evaluation of health care programmes},
	author = {Drummond, Michael F. and Sculpher, Mark J. and Claxton, Karl and Stoddart, Greg L. and Torrance, George W.},
	year = {2015},
	date = {2015},
	publisher = {Oxford university press}
}

@book{drummond2015a,
	title = {Methods for the economic evaluation of health care programmes},
	author = {Drummond, Michael F. and Sculpher, Mark J. and Claxton, Karl and Stoddart, Greg L. and Torrance, George W.},
	year = {2015},
	date = {2015},
	publisher = {Oxford university press}
}


@article{gidwaniEstimatingTransitionProbabilities2020,
  title = {Estimating {{Transition Probabilities}} from {{Published Evidence}}: {{A Tutorial}} for {{Decision Modelers}}},
  shorttitle = {Estimating {{Transition Probabilities}} from {{Published Evidence}}},
  author = {Gidwani, Risha and Russell, Louise B.},
  year = {2020},
  month = nov,
  journal = {PharmacoEconomics},
  volume = {38},
  number = {11},
  pages = {1153--1164},
  issn = {1179-2027},
  doi = {10.1007/s40273-020-00937-z},
  abstract = {This tutorial presents practical guidance on transforming various typesof information published in journals, or available online from government and other sources, into transition probabilities for use in state-transition models, including cost-effectiveness models. Much, but not all, of the guidance has been previously published in peer-reviewed journals. Our purpose is to collect it in one location to serve as a stand-alone resource for decision modelers who draw most or all of their information from the published literature. Our focus is on the technical aspects of manipulating data to derive transition probabilities. We explain how to derive model transition probabilities from the following types of statistics: relative risks, odds, odds ratios, and rates. We then review the well-known approach for converting probabilities to match the model's cycle length when there are two health-state transitions and how to handle the case of three or more health-state transitions, for which the two-state approach is not appropriate. Other topics discussed include transition probabilities for population subgroups, issues to keep in mind when using data from different sources in the derivation process, and sensitivity analyses, including the use of sensitivity analysis to allocate analyst effort in refining transition probabilities and ways to handle sources of uncertainty that are not routinely formalized in models. The paper concludes with recommendations to help modelers make the best use of the published literature.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/JZ2D79KF/Gidwani and Russell - 2020 - Estimating Transition Probabilities from Published.pdf}
}


@article{briggsModelParameterEstimation2012a,
  title = {Model {{Parameter Estimation}} and {{Uncertainty Analysis}}: {{A Report}} of the {{ISPOR-SMDM Modeling Good Research Practices Task Force Working Group}}\textendash 6},
  shorttitle = {Model {{Parameter Estimation}} and {{Uncertainty Analysis}}},
  author = {Briggs, Andrew H. and Weinstein, Milton C. and Fenwick, Elisabeth A. L. and Karnon, Jonathan and Sculpher, Mark J. and Paltiel, A. David},
  year = {2012},
  month = sep,
  journal = {Medical Decision Making},
  volume = {32},
  number = {5},
  pages = {722--732},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X12458348},
  abstract = {A model?s purpose is to inform medical decisions and health care resource allocation. Modelers employ quantitative methods to structure the clinical, epidemiological, and economic evidence base and gain qualitative insight to assist decision makers in making better decisions. From a policy perspective, the value of a model-based analysis lies not simply in its ability to generate a precise point estimate for a specific outcome but also in the systematic examination and responsible reporting of uncertainty surrounding this outcome and the ultimate decision being addressed. Different concepts relating to uncertainty in decision modeling are explored. Stochastic (first-order) uncertainty is distinguished from both parameter (second-order) uncertainty and from heterogeneity, with structural uncertainty relating to the model itself forming another level of uncertainty to consider. The article argues that the estimation of point estimates and uncertainty in parameters is part of a single process and explores the link between parameter uncertainty through to decision uncertainty and the relationship to value-of-information analysis. The article also makes extensive recommendations around the reporting of uncertainty, both in terms of deterministic sensitivity analysis techniques and probabilistic methods. Expected value of perfect information is argued to be the most appropriate presentational technique, alongside cost-effectiveness acceptability curves, for representing decision uncertainty from probabilistic analysis.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/YPSTPVPG/Briggs et al. - 2012 - Model Parameter Estimation and Uncertainty Analysi.pdf}
}



@article{siebertStateTransitionModelingReport2012,
  title = {State-{{Transition Modeling}}: {{A Report}} of the {{ISPOR-SMDM Modeling Good Research Practices Task Force-3}}},
  shorttitle = {State-{{Transition Modeling}}},
  author = {Siebert, Uwe and Alagoz, Oguzhan and Bayoumi, Ahmed M. and Jahn, Beate and Owens, Douglas K. and Cohen, David J. and Kuntz, Karen M.},
  year = {2012},
  month = sep,
  journal = {Value in Health},
  volume = {15},
  number = {6},
  pages = {812--820},
  publisher = {{Elsevier}},
  issn = {1098-3015, 1524-4733},
  doi = {10.1016/j.jval.2012.06.014},
  langid = {english},
  pmid = {22999130},
  keywords = {decision-analytic modeling,guidelines,Markov models,state-transition modeling},
  file = {/Users/johngraves/Zotero/storage/BCRH53NE/Siebert et al. - 2012 - State-Transition Modeling A Report of the ISPOR-S.pdf;/Users/johngraves/Zotero/storage/HXDLRX8D/fulltext.html}
}



@article{zhangWhatRelativeRisk1998,
  title = {What's the {{Relative Risk}}?{{A Method}} of {{Correcting}} the {{Odds Ratio}} in {{Cohort Studies}} of {{Common Outcomes}}},
  shorttitle = {What's the {{Relative Risk}}?},
  author = {Zhang, Jun and Yu, Kai F.},
  year = {1998},
  month = nov,
  journal = {JAMA},
  volume = {280},
  number = {19},
  pages = {1690--1691},
  issn = {0098-7484},
  doi = {10.1001/jama.280.19.1690},
  abstract = {Logistic regression is used frequently in cohort studies and clinical trials. When the incidence of an outcome of interest is common in the study population (\&gt;10\%), the adjusted odds ratio derived from the logistic regression can no longer approximate the risk ratio. The more frequent the outcome, the more the odds ratio overestimates the risk ratio when it is more than 1 or underestimates it when it is less than 1. We propose a simple method to approximate a risk ratio from the adjusted odds ratio and derive an estimate of an association or treatment effect that better represents the true relative risk.},
  file = {/Users/johngraves/Zotero/storage/CSKZCMGU/Zhang and Yu - 1998 - What's the Relative RiskA Method of Correcting th.pdf;/Users/johngraves/Zotero/storage/2I74SJJ8/188182.html}
}


@article{russellWhatPertussisMortality2016,
  title = {What Pertussis Mortality Rates Make Maternal Acellular Pertussis Immunization Cost-Effective in Low-and Middle-Income Countries? A Decision Analysis},
  shorttitle = {What Pertussis Mortality Rates Make Maternal Acellular Pertussis Immunization Cost-Effective in Low-and Middle-Income Countries?},
  author = {Russell, Louise B. and Pentakota, Sri Ram and Toscano, Cristiana Maria and Cosgriff, Ben and Sinha, Anushua},
  year = {2016},
  journal = {Clinical Infectious Diseases},
  volume = {63},
  number = {suppl\_4},
  pages = {S227--S235},
  publisher = {{Oxford University Press}}
}

@article{green2023health,
  title={Health Economic Evaluation Using Markov Models in R for Microsoft Excel Users: A Tutorial},
  author={Green, Nathan and Lamrock, Felicity and Naylor, Nichola and Williams, Jack and Briggs, Andrew},
  journal={PharmacoEconomics},
  volume={41},
  number={1},
  pages={5--19},
  year={2023},
  publisher={Springer}
}

@article{krijkamp2020multidimensional,
  title={A multidimensional array representation of state-transition model dynamics},
  author={Krijkamp, Eline M and Alarid-Escudero, Fernando and Enns, Eva A and Pechlivanoglou, Petros and Hunink, MG Myriam and Yang, Alan and Jalal, Hawre J},
  journal={Medical Decision Making},
  volume={40},
  number={2},
  pages={242--248},
  year={2020},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@book{highamFunctionsMatricesTheory2008,
  title = {Functions of Matrices: Theory and Computation},
  shorttitle = {Functions of Matrices},
  author = {Higham, Nicholas J.},
  year = {2008},
  publisher = {{SIAM}},
  file = {/Users/johngraves/Zotero/storage/4LUHMMXP/Higham - 2008 - Functions of matrices theory and computation.pdf}
}

@article{chhatwalChangingCycleLengths2016,
  title = {Changing {{Cycle Lengths}} in {{State-Transition Models}}: {{Challenges}} and {{Solutions}}},
  shorttitle = {Changing {{Cycle Lengths}} in {{State-Transition Models}}},
  author = {Chhatwal, Jagpreet and Jayasuriya, Suren and Elbasha, Elamin H.},
  year = {2016},
  month = nov,
  journal = {Medical Decision Making},
  volume = {36},
  number = {8},
  pages = {952--964},
  publisher = {{SAGE Publications Inc STM}},
  issn = {0272-989X},
  doi = {10.1177/0272989X16656165},
  urldate = {2023-05-17},
  abstract = {The choice of a cycle length in state-transition models should be determined by the frequency of clinical events and interventions. Sometimes there is need to decrease the cycle length of an existing state-transition model to reduce error in outcomes resulting from discretization of the underlying continuous-time phenomena or to increase the cycle length to gain computational efficiency. Cycle length conversion is also frequently required if a new state-transition model is built using observational data that have a different measurement interval than the model's cycle length. We show that a commonly used method of converting transition probabilities to different cycle lengths is incorrect and can provide imprecise estimates of model outcomes. We present an accurate approach that is based on finding the root of a transition probability matrix using eigendecomposition. We present underlying mathematical challenges of converting cycle length in state-transition models and provide numerical approximation methods when the eigendecomposition method fails. Several examples and analytical proofs show that our approach is more general and leads to more accurate estimates of model outcomes than the commonly used approach. MATLAB codes and a user-friendly online toolkit are made available for the implementation of the proposed methods.},
  langid = {english},
  file = {/Users/johngraves/Zotero/storage/ZPACGMKL/Chhatwal et al. - 2016 - Changing Cycle Lengths in State-Transition Models.pdf}
}



